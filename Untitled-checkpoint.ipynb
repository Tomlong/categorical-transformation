{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import time\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.svm import SVC\n",
    "from collections import Counter\n",
    "from numpy.linalg.linalg import LinAlgError\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix as confu\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "def normalization(training_numpy, testing_numpy):\n",
    "    min_max = preprocessing.MinMaxScaler()\n",
    "    min_max.fit(training_numpy)\n",
    "    x_scaled = min_max.fit_transform(training_numpy)\n",
    "    testing_x_scaled = min_max.transform(testing_numpy)\n",
    "    #training_norm = pd.DataFrame(x_scaled, columns = columns)\n",
    "    #testing_norm = pd.DataFrame(testting_x_scaled, columns = columns)\n",
    "    return (x_scaled, testing_x_scaled)\n",
    "\n",
    "def pca_function(rate, data):\n",
    "    pca = PCA()\n",
    "    pca.fit(data)\n",
    "    for thres_n in xrange(1,len(data)):\n",
    "        if sum(pca.explained_variance_ratio_[:thres_n])>rate:\n",
    "            pca_n = thres_n\n",
    "            break\n",
    "    \n",
    "    pca = PCA(n_components=pca_n)\n",
    "    pca_data = pca.fit_transform(data)\n",
    "    return (pca_data, pca)\n",
    "\n",
    "def lda_function(X, y):\n",
    "    n_cluster = 4\n",
    "    #lda = LDA()\n",
    "    #lda_data = lda.fit_transform(X, y)\n",
    "    original_y = y.copy() \n",
    "    #normal_index = np.where(y == 0)[0]\n",
    "    anomaly_index = np.where(y == 1)[0]\n",
    "    #print len(normal_index), len(anomaly_index)\n",
    "    \n",
    "    #km_normal = KMeans(n_clusters=2)\n",
    "    #km_normal.fit(X.iloc[normal_index], y[normal_index])\n",
    "    km_anomaly = KMeans(n_clusters=n_cluster)\n",
    "    km_anomaly.fit(X.iloc[anomaly_index], y[anomaly_index])\n",
    "    \n",
    "   \n",
    "    #normal_label = km_normal.labels_    \n",
    "    #normal_label[np.where(normal_label == 0)[0]] = 0\n",
    "    #normal_label[np.where(normal_label == 1)[0]] = 1\n",
    "    \n",
    "    anomaly_label = km_anomaly.labels_\n",
    "    #print 'before label:',np.unique(anomaly_label)\n",
    "    for i in range(len(np.unique(anomaly_label)), 0, -1):\n",
    "        #print i, np.unique(anomaly_label)\n",
    "        anomaly_label[np.where(anomaly_label == (i-1))[0]] = i\n",
    "    #print 'label:',np.unique(anomaly_label)\n",
    "\n",
    "    #y[normal_index] = normal_label\n",
    "    y[anomaly_index] = anomaly_label\n",
    "    \n",
    "    #print len(np.where(normal_label == 0)[0]),len(np.where(normal_label == 1)[0]), len(np.where(anomaly_label == 2)[0]), len(np.where(anomaly_label == 3)[0])\n",
    "    #print np.unique(y)\n",
    "    #return (X,y)\n",
    "    \n",
    "    #print lda.n_components\n",
    "    try:\n",
    "        lda = LDA()\n",
    "        lda_data = lda.fit_transform(X, y)\n",
    "    except ValueError:\n",
    "        lda = LDA()\n",
    "        lda_data = lda.fit_transform(X, original_y)\n",
    "    except LinAlgError:\n",
    "        lda = LDA()\n",
    "        lda_data = lda.fit_transform(X, original_y)\n",
    "        \n",
    "    #print lda_data.shape\n",
    "    return (lda_data, lda)\n",
    "\n",
    "\n",
    "'''\n",
    "def pca_function(n, data):\n",
    "    pca = PCA(n_components=n)\n",
    "    pca_data = pca.fit_transform(data)\n",
    "    return (pca_data.flatten(), pca)\n",
    "\n",
    "def lda_function(X, y):\n",
    "    lda = LDA()\n",
    "    lda_data = lda.fit_transform(X, y)\n",
    "    return (lda_data.flatten(), lda)\n",
    "'''\n",
    "def replace_value(training_normal_numpy, key, loc):  \n",
    "    training_normal_numpy[loc][key] = 1\n",
    "    \n",
    "def del_zero_column(df_train, df_test):\n",
    "    df_train = df_train.loc[:, (df_train != 0).any(axis=0)]\n",
    "    df_test = df_test[df_train.columns]\n",
    "    return (df_train, df_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key_str = {'Normal':0, 'Botnet':1, 'Background':2}\n",
    "column_unuse = ['StartTime', 'SrcAddr', 'DstAddr', 'Sport']\n",
    "column_str = ['Proto', 'State','Dir','Dport']\n",
    "score_list = {}\n",
    "fscore_list = {}\n",
    "#output_fscore = pd.DataFrame()\n",
    "output_fscore = pd.DataFrame(columns=['lda_2_class', '0.9_pca', '1_dim_pca'])\n",
    "#output_fscore = pd.DataFrame(columns=['Numeric_proto', 'Numeric_state', 'Numeric_dir', 'Numeric_dport', 'Binary_proto', 'Binary_state', 'Binary_dir','Binary_dport'])\n",
    "\n",
    "pca_rate = 0.9\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "train = pd.read_csv('2014-06-06_capture-win8.binetflow.labeled')\n",
    "\n",
    "# Fill 0 to missing value\n",
    "train = train.fillna(0)    \n",
    "train = train[train['State'] != 0]\n",
    "\n",
    "# Drop unuse columns and row with missing value\n",
    "missing_state = []\n",
    "map(lambda word: missing_state.append(word) if word[-1]=='_' else None, np.unique(train['State']))\n",
    "\n",
    "for column in column_unuse:\n",
    "    del train[column]\n",
    "\n",
    "for state in missing_state:\n",
    "    train = train[train['State'] != state]\n",
    "\n",
    "\n",
    "# Transfer str label to int lable\n",
    "label_num = []\n",
    "\n",
    "map(lambda label: map(lambda key: label_num.append(key_str[key]) if key in label else None,key_str.keys()), train['Label'])\n",
    "train['Label'] = label_num\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# training & testing index\n",
    "train_index = np.array(np.where(train['Label'] == 0)[0].tolist() + np.where(train['Label'] == 1)[0].tolist())\n",
    "print  'training length:', len(train_index)\n",
    "\n",
    "now_lda_fscore = []\n",
    "\n",
    "all_score_lda = []\n",
    "\n",
    "skf = StratifiedKFold(np.array(label_num)[train_index], n_folds=10)\n",
    "val_label = np.array(label_num)[train_index]\n",
    "\n",
    "print np.unique(np.array(label_num)[train_index])\n",
    "\n",
    "train_binary_proto = pd.get_dummies(train.iloc[train_index]['Proto'])\n",
    "train_binary_state = pd.get_dummies(train.iloc[train_index]['State'])\n",
    "train_binary_dir = pd.get_dummies(train.iloc[train_index]['Dir'])\n",
    "train_binary_dport= pd.get_dummies(train.iloc[train_index]['Dport'])\n",
    "\n",
    "train_copy_lda = pd.DataFrame()\n",
    "train_copy_pca = pd.DataFrame()\n",
    "#for column in column_str:\n",
    "#    del train_copy_lda[column]\n",
    "#del train_copy_lda['Label']\n",
    "\n",
    "val_label = np.array(label_num)[train_index]\n",
    "clf_lda = knn(n_neighbors=1, algorithm='kd_tree')\n",
    "clf_pca = knn(n_neighbors=1, algorithm='kd_tree')\n",
    "#clf_numeric = SVC(C=10,kernel='linear', class_weight='balanced')\n",
    "#clf_lda = SVC(C=10,kernel='linear',class_weight='balanced')\n",
    "for iteration in range(2):\n",
    "    #print iteration\n",
    "    #ten_fold = 0\n",
    "    for train_val_index, test_val_index in skf:    \n",
    "        #print ten_fold\n",
    "        #ten_fold = ten_fold+1\n",
    "        ''' \n",
    "        train_binary_proto = pd.get_dummies(train.iloc[train_index[train_val_index]]['Proto'])\n",
    "        train_binary_state = pd.get_dummies(train.iloc[train_index[train_val_index]]['State'])\n",
    "        train_binary_dir = pd.get_dummies(train.iloc[train_index[train_val_index]]['Dir'])\n",
    "        train_binary_dport= pd.get_dummies(train.iloc[train_index[train_val_index]]['Dport'])\n",
    "        test_binary_proto = np.zeros([len(test_val_index), len(train_binary_proto.columns)])\n",
    "        test_binary_proto = np.zeros([len(test_val_index), len(train_binary_proto.columns)])\n",
    "        test_binary_proto = np.zeros([len(test_val_index), len(train_binary_proto.columns)])\n",
    "        test_binary_proto = np.zeros([len(test_val_index), len(train_binary_proto.columns)])\n",
    "\n",
    "        (train_proto_lda, proto_lda) = lda_function(train_binary_proto, val_label[train_val_index])\n",
    "        (train_state_lda, state_lda) = lda_function(train_binary_state, val_label[train_val_index])\n",
    "        (train_dir_lda, dir_lda) = lda_function(train_binary_dir, val_label[train_val_index])\n",
    "        (train_dport_lda, dport_lda) = lda_function(train_binary_dport, val_label[train_val_index])\n",
    "        train_lda_np = np.append(train_proto_lda, train_state_lda, 1)\n",
    "        train_lda_np = np.append(train_lda_np, train_dir_lda, 1)\n",
    "        train_lda_np = np.append(train_lda_np, train_dport_lda, 1)\n",
    "\n",
    "        '''\n",
    "        #print \"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\"\n",
    "\n",
    "        (now_train_binary_proto,now_test_binary_proto) = del_zero_column(train_binary_proto.iloc[train_val_index],train_binary_proto.iloc[test_val_index])\n",
    "        (now_train_binary_state,now_test_binary_state) = del_zero_column(train_binary_state.iloc[train_val_index], train_binary_state.iloc[test_val_index])\n",
    "        (now_train_binary_dir,now_test_binary_dir) = del_zero_column(train_binary_dir.iloc[train_val_index], train_binary_dir.iloc[test_val_index])\n",
    "        (now_train_binary_dport,now_test_binary_dport) = del_zero_column(train_binary_dport.iloc[train_val_index], train_binary_dport.iloc[test_val_index])\n",
    "        (train_proto_lda, proto_lda) = lda_function(now_train_binary_proto, val_label[train_val_index])\n",
    "        (train_state_lda, state_lda) = lda_function(now_train_binary_state, val_label[train_val_index])\n",
    "        (train_dir_lda, dir_lda) = lda_function(now_train_binary_dir, val_label[train_val_index])\n",
    "        (train_dport_lda, dport_lda) = lda_function(now_train_binary_dport, val_label[train_val_index])\n",
    "        train_lda_np = np.append(train_proto_lda, train_state_lda, 1)\n",
    "        train_lda_np = np.append(train_lda_np, train_dir_lda, 1)\n",
    "        train_lda_np = np.append(train_lda_np, train_dport_lda, 1)\n",
    "\n",
    "\n",
    "        test_proto_lda = proto_lda.transform(now_test_binary_proto)\n",
    "        test_state_lda = state_lda.transform(now_test_binary_state)            \n",
    "        test_dir_lda = dir_lda.transform(now_test_binary_dir)\n",
    "        test_dport_lda = dport_lda.transform(now_test_binary_dport)\n",
    "        test_lda_np = np.append(test_proto_lda, test_state_lda, 1)\n",
    "        test_lda_np = np.append(test_lda_np, test_dir_lda, 1)\n",
    "        test_lda_np = np.append(test_lda_np, test_dport_lda, 1)\n",
    "\n",
    "\n",
    "\n",
    "        #train_numpy_pca = train_copy_pca.values\n",
    "        #(train_numpy_pca_norm, test_numpy_pca_norm) = normalization(train_copy_pca.iloc[train_val_index],train_copy_pca.iloc[test_val_index], train_copy_pca.columns)\n",
    "        (train_numpy_lda_norm, test_numpy_lda_norm) = normalization(train_lda_np,test_lda_np)\n",
    "\n",
    "        #----Here--- continue\n",
    "        clf_lda.fit(train_numpy_lda_norm, val_label[train_val_index])\n",
    "        all_score_lda.append(f1_score(clf_lda.predict(test_numpy_lda_norm), val_label[test_val_index]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    lda_fscore = np.average(all_score_lda)\n",
    "    now_lda_fscore.append(lda_fscore)\n",
    "\n",
    "output_fscore.loc[0] = [np.max(now_lda_fscore), np.min(now_lda_fscore), np.average(now_lda_fscore)]\n",
    "#print 'numeric:', numeric_fscore, 'lda:', lda_fscore \n",
    "\n",
    "\n",
    "\n",
    "#print output_fscore.loc[str(index_train_dataset)]\n",
    "output_fscore.to_csv('new_1_lda_3class.csv')\n",
    "#output_fscore.loc[str(index_train_dataset)] = [numeric_fscore, lda_fscore]\n",
    "#output_fscore.to_csv('4_string_numeric_vs_lda_no_norm.csv')\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key_str = {'Normal':0, 'Botnet':1, 'Background':2}\n",
    "column_unuse = ['StartTime', 'SrcAddr', 'DstAddr', 'Sport']\n",
    "column_str = ['Proto', 'State','Dir','Dport']\n",
    "score_list = {}\n",
    "fscore_list = {}\n",
    "#output_fscore = pd.DataFrame()\n",
    "output_fscore = pd.DataFrame(columns=['max', 'min','average'])\n",
    "#output_fscore = pd.DataFrame(columns=['Numeric_proto', 'Numeric_state', 'Numeric_dir', 'Numeric_dport', 'Binary_proto', 'Binary_state', 'Binary_dir','Binary_dport'])\n",
    "\n",
    "pca_rate = 0.9\n",
    "\n",
    "\n",
    "for index_train_dataset in xrange(1,14): \n",
    "   \n",
    "    train = pd.read_csv('botnet_'+str(index_train_dataset)+'.binetflow')\n",
    "\n",
    "    # Fill 0 to missing value\n",
    "    train = train.fillna(0)    \n",
    "    train = train[train['State'] != 0]\n",
    "\n",
    "    # Drop unuse columns and row with missing value\n",
    "    missing_state = []\n",
    "    map(lambda word: missing_state.append(word) if word[-1]=='_' else None, np.unique(train['State']))\n",
    "\n",
    "    for column in column_unuse:\n",
    "        del train[column]\n",
    "\n",
    "    for state in missing_state:\n",
    "        train = train[train['State'] != state]\n",
    "\n",
    "\n",
    "    # Transfer str label to int lable\n",
    "    label_num = []\n",
    "\n",
    "    map(lambda label: map(lambda key: label_num.append(key_str[key]) if key in label else None,key_str.keys()), train['Label'])\n",
    "    train['Label'] = label_num\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # training & testing index\n",
    "    train_index = np.array(np.where(train['Label'] == 0)[0].tolist() + np.where(train['Label'] == 1)[0].tolist())\n",
    "    print 'Dataset:',index_train_dataset, 'training length:', len(train_index)\n",
    "    \n",
    "    now_lda_fscore = []\n",
    "    \n",
    "    all_score_lda = []\n",
    "    \n",
    "    skf = StratifiedKFold(np.array(label_num)[train_index], n_folds=5)\n",
    "    val_label = np.array(label_num)[train_index]\n",
    "\n",
    "    train_binary_proto = pd.get_dummies(train.iloc[train_index]['Proto'])\n",
    "    train_binary_state = pd.get_dummies(train.iloc[train_index]['State'])\n",
    "    train_binary_dir = pd.get_dummies(train.iloc[train_index]['Dir'])\n",
    "    train_binary_dport= pd.get_dummies(train.iloc[train_index]['Dport'])\n",
    "\n",
    "    train_copy_lda = pd.DataFrame()\n",
    "    train_copy_pca = pd.DataFrame()\n",
    "    #for column in column_str:\n",
    "    #    del train_copy_lda[column]\n",
    "    #del train_copy_lda['Label']\n",
    "    \n",
    "    val_label = np.array(label_num)[train_index]\n",
    "    clf_lda = SVC(C=1, gamma=0.1, class_weight='balanced')\n",
    "    clf_pca = knn(n_neighbors=1, algorithm='kd_tree')\n",
    "    #clf_numeric = SVC(C=10,kernel='linear', class_weight='balanced')\n",
    "    #clf_lda = SVC(C=10,kernel='linear',class_weight='balanced')\n",
    "    for iteration in range(10):\n",
    "        #print iteration\n",
    "        #ten_fold = 0\n",
    "        for train_val_index, test_val_index in skf:    \n",
    "            #print ten_fold\n",
    "            #ten_fold = ten_fold+1\n",
    "            ''' \n",
    "            train_binary_proto = pd.get_dummies(train.iloc[train_index[train_val_index]]['Proto'])\n",
    "            train_binary_state = pd.get_dummies(train.iloc[train_index[train_val_index]]['State'])\n",
    "            train_binary_dir = pd.get_dummies(train.iloc[train_index[train_val_index]]['Dir'])\n",
    "            train_binary_dport= pd.get_dummies(train.iloc[train_index[train_val_index]]['Dport'])\n",
    "            test_binary_proto = np.zeros([len(test_val_index), len(train_binary_proto.columns)])\n",
    "            test_binary_proto = np.zeros([len(test_val_index), len(train_binary_proto.columns)])\n",
    "            test_binary_proto = np.zeros([len(test_val_index), len(train_binary_proto.columns)])\n",
    "            test_binary_proto = np.zeros([len(test_val_index), len(train_binary_proto.columns)])\n",
    "\n",
    "            (train_proto_lda, proto_lda) = lda_function(train_binary_proto, val_label[train_val_index])\n",
    "            (train_state_lda, state_lda) = lda_function(train_binary_state, val_label[train_val_index])\n",
    "            (train_dir_lda, dir_lda) = lda_function(train_binary_dir, val_label[train_val_index])\n",
    "            (train_dport_lda, dport_lda) = lda_function(train_binary_dport, val_label[train_val_index])\n",
    "            train_lda_np = np.append(train_proto_lda, train_state_lda, 1)\n",
    "            train_lda_np = np.append(train_lda_np, train_dir_lda, 1)\n",
    "            train_lda_np = np.append(train_lda_np, train_dport_lda, 1)\n",
    "            \n",
    "            '''\n",
    "            #print \"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\"\n",
    "            \n",
    "            (now_train_binary_proto,now_test_binary_proto) = del_zero_column(train_binary_proto.iloc[train_val_index],train_binary_proto.iloc[test_val_index])\n",
    "            (now_train_binary_state,now_test_binary_state) = del_zero_column(train_binary_state.iloc[train_val_index], train_binary_state.iloc[test_val_index])\n",
    "            (now_train_binary_dir,now_test_binary_dir) = del_zero_column(train_binary_dir.iloc[train_val_index], train_binary_dir.iloc[test_val_index])\n",
    "            (now_train_binary_dport,now_test_binary_dport) = del_zero_column(train_binary_dport.iloc[train_val_index], train_binary_dport.iloc[test_val_index])\n",
    "            (train_proto_lda, proto_lda) = lda_function(now_train_binary_proto, val_label[train_val_index])\n",
    "            (train_state_lda, state_lda) = lda_function(now_train_binary_state, val_label[train_val_index])\n",
    "            (train_dir_lda, dir_lda) = lda_function(now_train_binary_dir, val_label[train_val_index])\n",
    "            (train_dport_lda, dport_lda) = lda_function(now_train_binary_dport, val_label[train_val_index])\n",
    "            train_lda_np = np.append(train_proto_lda, train_state_lda, 1)\n",
    "            train_lda_np = np.append(train_lda_np, train_dir_lda, 1)\n",
    "            train_lda_np = np.append(train_lda_np, train_dport_lda, 1)\n",
    "\n",
    "\n",
    "            test_proto_lda = proto_lda.transform(now_test_binary_proto)\n",
    "            test_state_lda = state_lda.transform(now_test_binary_state)            \n",
    "            test_dir_lda = dir_lda.transform(now_test_binary_dir)\n",
    "            test_dport_lda = dport_lda.transform(now_test_binary_dport)\n",
    "            test_lda_np = np.append(test_proto_lda, test_state_lda, 1)\n",
    "            test_lda_np = np.append(test_lda_np, test_dir_lda, 1)\n",
    "            test_lda_np = np.append(test_lda_np, test_dport_lda, 1)\n",
    "            \n",
    "            \n",
    "\n",
    "            #train_numpy_pca = train_copy_pca.values\n",
    "            #(train_numpy_pca_norm, test_numpy_pca_norm) = normalization(train_copy_pca.iloc[train_val_index],train_copy_pca.iloc[test_val_index], train_copy_pca.columns)\n",
    "            (train_numpy_lda_norm, test_numpy_lda_norm) = normalization(train_lda_np,test_lda_np)\n",
    "\n",
    "            #----Here--- continue\n",
    "            clf_lda.fit(train_numpy_lda_norm, val_label[train_val_index])\n",
    "            all_score_lda.append(f1_score(clf_lda.predict(test_numpy_lda_norm), val_label[test_val_index]))\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "        lda_fscore = np.average(all_score_lda)\n",
    "        now_lda_fscore.append(lda_fscore)\n",
    "    print 'max:',np.max(now_lda_fscore),  'min:', np.min(now_lda_fscore),'avg:',np.average(now_lda_fscore)\n",
    "    output_fscore.loc[str(index_train_dataset)] = [np.max(now_lda_fscore), np.min(now_lda_fscore), np.average(now_lda_fscore)]\n",
    "    #print 'numeric:', numeric_fscore, 'lda:', lda_fscore \n",
    "\n",
    "\n",
    "    \n",
    "    #print output_fscore.loc[str(index_train_dataset)]\n",
    "    output_fscore.to_csv('lda_tine_5class(anomoly)_svc.csv')\n",
    "    #output_fscore.loc[str(index_train_dataset)] = [numeric_fscore, lda_fscore]\n",
    "    #output_fscore.to_csv('4_string_numeric_vs_lda_no_norm.csv')\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attack_list = open('training_attack_types.txt')\n",
    "attack_dic = {}\n",
    "\n",
    "for line in attack_list.readlines():    \n",
    "    detail = line.split(' ')\n",
    "    if len(detail) == 1:\n",
    "        break\n",
    "    attack_type = detail[1][:-1]\n",
    "    attack_name = detail[0]\n",
    "    \n",
    "    if attack_dic.has_key(attack_type):\n",
    "        attack_dic[attack_type].append(attack_name)\n",
    "    else:\n",
    "        attack_dic[attack_type] = []\n",
    "        attack_dic[attack_type].append(attack_name)\n",
    "\n",
    "test_attack_dic = {}\n",
    "test_attack_dic[\"apache2.\"] = 2 \n",
    "test_attack_dic[\"back.\"] = 2 \n",
    "test_attack_dic[\"buffer_overflow.\"] = 3 \n",
    "test_attack_dic[\"ftp_write.\"] = 4 \n",
    "test_attack_dic[\"guess_passwd.\"] = 4 \n",
    "#test_attack_dic[\"httptunnel.\"] = 4 \n",
    "test_attack_dic[\"httptunnel.\"] = 3 \n",
    "test_attack_dic[\"imap.\"] = 4 \n",
    "test_attack_dic[\"ipsweep.\"] = 1 \n",
    "test_attack_dic[\"land.\"] = 2 \n",
    "test_attack_dic[\"loadmodule.\"] = 3 \n",
    "test_attack_dic[\"mailbomb.\"] = 2 \n",
    "test_attack_dic[\"mscan.\"] = 1 \n",
    "test_attack_dic[\"multihop.\"] = 4 \n",
    "#test_attack_dic[\"multihop.\"] = 3 # note that this is a duplicate \n",
    "test_attack_dic[\"named.\"] = 4 \n",
    "test_attack_dic[\"neptune.\"] = 2 \n",
    "test_attack_dic[\"nmap.\"] = 1 \n",
    "test_attack_dic[\"perl.\"] = 3 \n",
    "test_attack_dic[\"phf.\"] = 4 \n",
    "test_attack_dic[\"pod.\"] = 2 \n",
    "test_attack_dic[\"portsweep.\"] = 1 \n",
    "test_attack_dic[\"processtable.\"] = 2 \n",
    "test_attack_dic[\"ps.\"] = 3 \n",
    "test_attack_dic[\"rootkit.\"] = 3 \n",
    "test_attack_dic[\"saint.\"] = 1 \n",
    "test_attack_dic[\"satan.\"] = 1 \n",
    "test_attack_dic[\"sendmail.\"] = 4 \n",
    "test_attack_dic[\"smurf.\"] = 2 \n",
    "test_attack_dic[\"snmpgetattack.\"] = 4 \n",
    "test_attack_dic[\"snmpguess.\"] = 4 \n",
    "test_attack_dic[\"sqlattack.\"] = 3 \n",
    "test_attack_dic[\"teardrop.\"] = 2 \n",
    "test_attack_dic[\"udpstorm.\"] = 2 \n",
    "test_attack_dic[\"warezmaster.\"] = 4 \n",
    "test_attack_dic[\"worm.\"] = 4 \n",
    "test_attack_dic[\"xlock.\"] = 4 \n",
    "test_attack_dic[\"xsnoop.\"] = 4 \n",
    "test_attack_dic[\"xterm.\"] = 3\n",
    "test_attack_dic['normal.'] = 0\n",
    "attack_dic_num = {}\n",
    "attack_dic_num[0] = ['normal']\n",
    "attack_dic_num[2] = attack_dic['dos']\n",
    "attack_dic_num[4] = attack_dic['r2l']\n",
    "attack_dic_num[3] = attack_dic['u2r']\n",
    "attack_dic_num[1] = attack_dic['probe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def del_zero_column(df_train, df_test):\n",
    "    new_df_test = pd.DataFrame(np.zeros([df_test.shape[0], df_train.shape[1]]),columns=df_train.columns)\n",
    "    new_df_test[list(set(df_train.columns) & set(df_test.columns))] = df_test[list(set(df_train.columns) & set(df_test.columns))]\n",
    "    #df_test = df_test[df_train.columns]\n",
    "    return (df_train, new_df_test)\n",
    "def lda_function(X, y):\n",
    "    n_cluster = 2\n",
    "    \n",
    "    original_y = y.copy()\n",
    "    anomaly_index = []\n",
    "    print \"y:\", np.unique(original_y)\n",
    "    \n",
    "    for uni_label in np.unique(y)[1:]:\n",
    "        print uni_label       \n",
    "        anomaly_index.append(np.where(y == uni_label)[0])\n",
    "\n",
    "    km_anomaly = KMeans(n_clusters=n_cluster)\n",
    "    km_anomaly_model = []\n",
    "    anomaly_label = []\n",
    "    for i in range(len(anomaly_index)):\n",
    "        km_anomaly_model.append(km_anomaly.fit(X.iloc[anomaly_index[i]], y[anomaly_index[i]]))\n",
    "        anomaly_label.append(km_anomaly.labels_)\n",
    "       \n",
    "    for i in range(len(anomaly_index)):\n",
    "        for (j,now_label) in zip(range(2*(i+1), 2*(i+1)-n_cluster, -1), range(n_cluster-1,0,-1)):\n",
    "            print \"i\",i,\"j:\",j\n",
    "            anomaly_label[i][np.where(anomaly_label == (now_label))[0]] = j\n",
    "        y[anomaly_index[i]] = anomaly_label[i]\n",
    "    print np.unique(y)\n",
    "    #print len(np.where(normal_label == 0)[0]),len(np.where(normal_label == 1)[0]), len(np.where(anomaly_label == 2)[0]), len(np.where(anomaly_label == 3)[0])\n",
    "    #print np.unique(y)\n",
    "    #return (X,y)\n",
    "    \n",
    "    #print lda.n_components\n",
    "    try:\n",
    "        lda = LDA()\n",
    "        lda_data = lda.fit_transform(X, y)\n",
    "    except ValueError:\n",
    "        lda = LDA()\n",
    "        lda_data = lda.fit_transform(X, original_y)\n",
    "    except LinAlgError:\n",
    "        lda = LDA()\n",
    "        lda_data = lda.fit_transform(X, original_y)\n",
    "        \n",
    "    #print lda_data.shape\n",
    "    return (lda_data, lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_str = ['protocol_type', 'service','flag']\n",
    "score_list = {}\n",
    "fscore_list = {}\n",
    "\n",
    "output_fscore = pd.DataFrame(columns=['max', 'min','average'])\n",
    "\n",
    "\n",
    "train = pd.read_csv('kdd_10_per.csv', nrows=30000)\n",
    "test= pd.read_csv('corrected', header=None, nrows=1000)\n",
    "test.columns = train.columns\n",
    "\n",
    "category_label_binary = []\n",
    "map(lambda label: map(lambda cate: category_label_binary.append(cate) if label in attack_dic_num[cate] else None,attack_dic_num.keys()),train['label'])\n",
    "category_label_binary = np.array(category_label_binary)\n",
    "#category_label_binary[np.where((category_label_binary != 0))] = 1\n",
    "\n",
    "print 'done'\n",
    "test_category_label_binary = []\n",
    "map(lambda label: test_category_label_binary.append(test_attack_dic[label]),test['label'])\n",
    "test_category_label_binary = np.array(test_category_label_binary)\n",
    "#test_category_label_binary[np.where((test_category_label_binary != 0))] = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print 'training length:', len(train)\n",
    "\n",
    "now_lda_fscore = []\n",
    "\n",
    "all_score_lda = []\n",
    "\n",
    "skf = StratifiedKFold(train['label'], n_folds=10)\n",
    "val_label = train['label']\n",
    "\n",
    "train_binary_proto = pd.get_dummies(train['protocol_type'])\n",
    "train_binary_state = pd.get_dummies(train['service'])\n",
    "train_binary_flag = pd.get_dummies(train['flag'])\n",
    "#train_binary_dport= pd.get_dummies(train.iloc[train_index]['Dport'])\n",
    "\n",
    "test_binary_proto = pd.get_dummies(test['protocol_type'])\n",
    "test_binary_state = pd.get_dummies(test['service'])\n",
    "test_binary_flag = pd.get_dummies(test['flag'])\n",
    "\n",
    "del train['label']\n",
    "del test['label']\n",
    "train_copy_lda = pd.DataFrame()\n",
    "train_copy_pca = pd.DataFrame()\n",
    "#for column in column_str:\n",
    "#    del train_copy_lda[column]\n",
    "#del train_copy_lda['Label']\n",
    "\n",
    "#val_label = np.array(label_num)[train_index]\n",
    "clf_lda = knn(n_neighbors=1, algorithm='kd_tree', n_jobs=-1)\n",
    "clf_pca = knn(n_neighbors=1, algorithm='kd_tree')\n",
    "#clf_numeric = SVC(C=10,kernel='linear', class_weight='balanced')\n",
    "#clf_lda = SVC(C=10,kernel='linear',class_weight='balanced')\n",
    "\n",
    "        \n",
    "        #print \"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\"\n",
    "\n",
    "(now_train_binary_proto,now_test_binary_proto) = del_zero_column(train_binary_proto, test_binary_proto)\n",
    "(now_train_binary_state,now_test_binary_state) = del_zero_column(train_binary_state, test_binary_state)\n",
    "(now_train_binary_flag,now_test_binary_flag) = del_zero_column(train_binary_flag, test_binary_flag)\n",
    "print \"del column finish\"\n",
    "#(now_train_binary_dport,now_test_binary_dport) = del_zero_column(train_binary_dport.iloc[train_val_index], train_binary_dport.iloc[test_val_index])\n",
    "#print np.unique(category_label_binary)\n",
    "(train_proto_lda, proto_lda) = lda_function(now_train_binary_proto, category_label_binary)\n",
    "(train_state_lda, state_lda) = lda_function(now_train_binary_state, category_label_binary)\n",
    "(train_flag_lda, flag_lda) = lda_function(now_train_binary_flag, category_label_binary)\n",
    "print \"train lda finish\"\n",
    "#(train_dport_lda, dport_lda) = lda_function(now_train_binary_dport, val_label[train_val_index])\n",
    "train_lda_np = np.append(train_proto_lda, train_state_lda, 1)\n",
    "train_lda_np = np.append(train_lda_np, train_flag_lda, 1)\n",
    "#train_lda_np = np.append(train_lda_np, train_dport_lda, 1)\n",
    "\n",
    "\n",
    "test_proto_lda = proto_lda.transform(now_test_binary_proto)\n",
    "test_state_lda = state_lda.transform(now_test_binary_state)            \n",
    "test_flag_lda = flag_lda.transform(now_test_binary_dir)\n",
    "print \"test lda finish\"\n",
    "#test_dport_lda = dport_lda.transform(now_test_binary_dport)\n",
    "test_lda_np = np.append(test_proto_lda, test_state_lda, 1)\n",
    "test_lda_np = np.append(test_lda_np, test_flag_lda, 1)\n",
    "#test_lda_np = np.append(test_lda_np, test_dport_lda, 1)\n",
    "\n",
    "\n",
    "\n",
    "#train_numpy_pca = train_copy_pca.values\n",
    "#(train_numpy_pca_norm, test_numpy_pca_norm) = normalization(train_copy_pca.iloc[train_val_index],train_copy_pca.iloc[test_val_index], train_copy_pca.columns)\n",
    "(train_numpy_lda_norm, test_numpy_lda_norm) = normalization(train_lda_np,test_lda_np)\n",
    "\n",
    "#----Here--- continue\n",
    "clf_lda.fit(train_numpy_lda_norm, category_label_binary)\n",
    "\n",
    "f_score = f1_score(clf_lda.predict(test_numpy_lda_norm), test_category_label_binary)\n",
    "\n",
    "print f_score\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
