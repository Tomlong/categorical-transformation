{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import time\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.svm import SVC\n",
    "from collections import Counter\n",
    "from numpy.linalg.linalg import LinAlgError\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix as confu\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = [[1,2,3,1,2],[0,2,1,1,1],[1,2,0,1,5],[2,1,4,1,1],[2,1,1,1,4]]\n",
    "km = KMeans(n_clusters=2)\n",
    "km.fit(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 405 1103   37   17]\n",
      "[370 370 416 406]\n",
      "(1562, 2)\n"
     ]
    }
   ],
   "source": [
    "a = np.random.rand(1562,5)\n",
    "b = np.random.randint(0,4,1562)\n",
    "lda = LDA()\n",
    "#lda_data = lda.fit_transform(a, y)\n",
    "#lda_data = lda.fit_transform(train_binary_proto, y)\n",
    "print np.bincount(y)\n",
    "print np.bincount(b)\n",
    "lda_data = lda.fit_transform(train_binary_proto, b)\n",
    "print lda_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(train_dport_lda, y) = lda_function(now_train_binary_dport, val_label[train_val_index])\n",
    "train_copy = now_train_binary_dport.copy()\n",
    "train_copy['label'] = y\n",
    "train_copy.to_csv('data_svd_not_converge.csv', index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lda_test_function(X, y):\n",
    "    \n",
    "    normal_index = np.where(y == 0)[0]\n",
    "    anomaly_index = np.where(y == 1)[0]\n",
    "    print len(normal_index), len(anomaly_index)\n",
    "    \n",
    "    km_normal = KMeans(n_clusters=2)\n",
    "    km_normal.fit(X.iloc[normal_index], y[normal_index])\n",
    "    km_anomaly = KMeans(n_clusters=2)\n",
    "    km_anomaly.fit(X.iloc[anomaly_index], y[anomaly_index])\n",
    "    \n",
    "   \n",
    "    normal_label = km_normal.labels_    \n",
    "    normal_label[np.where(normal_label == 0)[0]] = 0\n",
    "    normal_label[np.where(normal_label == 1)[0]] = 1\n",
    "    \n",
    "    anomaly_label = km_anomaly.labels_\n",
    "    anomaly_label[np.where(anomaly_label == 0)[0]] = 2\n",
    "    anomaly_label[np.where(anomaly_label == 1)[0]] = 3\n",
    "\n",
    "    y[normal_index] = normal_label\n",
    "    y[anomaly_index] = anomaly_label\n",
    "    \n",
    "    \n",
    "    print len(np.where(normal_label == 0)[0]),len(np.where(normal_label == 1)[0]), len(np.where(anomaly_label == 2)[0]), len(np.where(anomaly_label == 3)[0])\n",
    "    print np.unique(y)\n",
    "    return (X,y)\n",
    "    lda = LDA()\n",
    "    print 'shape;',X.shape\n",
    "    lda_data = lda.fit_transform(X, y)\n",
    "    print lda_data.shape\n",
    "    #return (lda_data, lda, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6167 8055 94512 100\n"
     ]
    }
   ],
   "source": [
    "(train_dport_lda, dport_lda) = lda_function(now_train_binary_dport, val_label[train_val_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "def normalization(training_numpy, testing_numpy):\n",
    "    min_max = preprocessing.MinMaxScaler()\n",
    "    min_max.fit(training_numpy)\n",
    "    x_scaled = min_max.fit_transform(training_numpy)\n",
    "    testing_x_scaled = min_max.transform(testing_numpy)\n",
    "    #training_norm = pd.DataFrame(x_scaled, columns = columns)\n",
    "    #testing_norm = pd.DataFrame(testting_x_scaled, columns = columns)\n",
    "    return (x_scaled, testing_x_scaled)\n",
    "\n",
    "def pca_function(rate, data):\n",
    "    pca = PCA()\n",
    "    pca.fit(data)\n",
    "    for thres_n in xrange(1,len(data)):\n",
    "        if sum(pca.explained_variance_ratio_[:thres_n])>rate:\n",
    "            pca_n = thres_n\n",
    "            break\n",
    "    \n",
    "    pca = PCA(n_components=pca_n)\n",
    "    pca_data = pca.fit_transform(data)\n",
    "    return (pca_data, pca)\n",
    "\n",
    "def lda_function(X, y):\n",
    "    \n",
    "    #lda = LDA()\n",
    "    #lda_data = lda.fit_transform(X, y)\n",
    "    original_y = y.copy() \n",
    "    #normal_index = np.where(y == 0)[0]\n",
    "    anomaly_index = np.where(y == 1)[0]\n",
    "    #print len(normal_index), len(anomaly_index)\n",
    "    \n",
    "    #km_normal = KMeans(n_clusters=2)\n",
    "    #km_normal.fit(X.iloc[normal_index], y[normal_index])\n",
    "    km_anomaly = KMeans(n_clusters=2)\n",
    "    km_anomaly.fit(X.iloc[anomaly_index], y[anomaly_index])\n",
    "    \n",
    "   \n",
    "    #normal_label = km_normal.labels_    \n",
    "    #normal_label[np.where(normal_label == 0)[0]] = 0\n",
    "    #normal_label[np.where(normal_label == 1)[0]] = 1\n",
    "    \n",
    "    anomaly_label = km_anomaly.labels_\n",
    "    anomaly_label[np.where(anomaly_label == 0)[0]] = 1\n",
    "    anomaly_label[np.where(anomaly_label == 1)[0]] = 2\n",
    "\n",
    "    #y[normal_index] = normal_label\n",
    "    y[anomaly_index] = anomaly_label\n",
    "    \n",
    "    #print len(np.where(normal_label == 0)[0]),len(np.where(normal_label == 1)[0]), len(np.where(anomaly_label == 2)[0]), len(np.where(anomaly_label == 3)[0])\n",
    "    #rint np.unique(y)\n",
    "    #return (X,y)\n",
    "    \n",
    "    #print lda.n_components\n",
    "    try:\n",
    "        lda = LDA()\n",
    "        lda_data = lda.fit_transform(X, y)\n",
    "    except ValueError:\n",
    "        lda = LDA()\n",
    "        lda_data = lda.fit_transform(X, original_y)\n",
    "    #except LinAlgError:\n",
    "    #    lda = LDA()\n",
    "    #    lda_data = lda.fit_transform(X, original_y)\n",
    "        \n",
    "    #print lda_data.shape\n",
    "    return (lda_data, lda)\n",
    "\n",
    "\n",
    "'''\n",
    "def pca_function(n, data):\n",
    "    pca = PCA(n_components=n)\n",
    "    pca_data = pca.fit_transform(data)\n",
    "    return (pca_data.flatten(), pca)\n",
    "\n",
    "def lda_function(X, y):\n",
    "    lda = LDA()\n",
    "    lda_data = lda.fit_transform(X, y)\n",
    "    return (lda_data.flatten(), lda)\n",
    "'''\n",
    "def replace_value(training_normal_numpy, key, loc):  \n",
    "    training_normal_numpy[loc][key] = 1\n",
    "    \n",
    "def del_zero_column(df_train, df_test):\n",
    "    df_train = df_train.loc[:, (df_train != 0).any(axis=0)]\n",
    "    df_test = df_test[df_train.columns]\n",
    "    return (df_train, df_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key_str = {'Normal':0, 'Botnet':1, 'Background':2}\n",
    "column_unuse = ['StartTime', 'SrcAddr', 'DstAddr', 'Sport']\n",
    "column_str = ['Proto', 'State','Dir','Dport']\n",
    "score_list = {}\n",
    "fscore_list = {}\n",
    "#output_fscore = pd.DataFrame()\n",
    "output_fscore = pd.DataFrame(columns=['max', 'min','average'])\n",
    "#output_fscore = pd.DataFrame(columns=['Numeric_proto', 'Numeric_state', 'Numeric_dir', 'Numeric_dport', 'Binary_proto', 'Binary_state', 'Binary_dir','Binary_dport'])\n",
    "\n",
    "pca_rate = 0.9\n",
    "\n",
    "\n",
    "for index_train_dataset in xrange(1,14): \n",
    "   \n",
    "    train = pd.read_csv('botnet_'+str(index_train_dataset)+'.binetflow')\n",
    "\n",
    "    # Fill 0 to missing value\n",
    "    train = train.fillna(0)    \n",
    "    train = train[train['State'] != 0]\n",
    "\n",
    "    # Drop unuse columns and row with missing value\n",
    "    missing_state = []\n",
    "    map(lambda word: missing_state.append(word) if word[-1]=='_' else None, np.unique(train['State']))\n",
    "\n",
    "    for column in column_unuse:\n",
    "        del train[column]\n",
    "\n",
    "    for state in missing_state:\n",
    "        train = train[train['State'] != state]\n",
    "\n",
    "\n",
    "    # Transfer str label to int lable\n",
    "    label_num = []\n",
    "\n",
    "    map(lambda label: map(lambda key: label_num.append(key_str[key]) if key in label else None,key_str.keys()), train['Label'])\n",
    "    train['Label'] = label_num\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # training & testing index\n",
    "    train_index = np.array(np.where(train['Label'] == 0)[0].tolist() + np.where(train['Label'] == 1)[0].tolist())\n",
    "    print 'Dataset:',index_train_dataset, 'training length:', len(train_index)\n",
    "    \n",
    "    now_lda_fscore = []\n",
    "    \n",
    "    all_score_lda = []\n",
    "    \n",
    "    skf = StratifiedKFold(np.array(label_num)[train_index], n_folds=10)\n",
    "    val_label = np.array(label_num)[train_index]\n",
    "\n",
    "    train_binary_proto = pd.get_dummies(train.iloc[train_index]['Proto'])\n",
    "    train_binary_state = pd.get_dummies(train.iloc[train_index]['State'])\n",
    "    train_binary_dir = pd.get_dummies(train.iloc[train_index]['Dir'])\n",
    "    train_binary_dport= pd.get_dummies(train.iloc[train_index]['Dport'])\n",
    "\n",
    "    train_copy_lda = pd.DataFrame()\n",
    "    train_copy_pca = pd.DataFrame()\n",
    "    #for column in column_str:\n",
    "    #    del train_copy_lda[column]\n",
    "    #del train_copy_lda['Label']\n",
    "    \n",
    "    val_label = np.array(label_num)[train_index]\n",
    "    clf_lda = knn(n_neighbors=1, algorithm='kd_tree')\n",
    "    clf_pca = knn(n_neighbors=1, algorithm='kd_tree')\n",
    "    #clf_numeric = SVC(C=10,kernel='linear', class_weight='balanced')\n",
    "    #clf_lda = SVC(C=10,kernel='linear',class_weight='balanced')\n",
    "    for iteration in range(10):\n",
    "        #print iteration\n",
    "        #ten_fold = 0\n",
    "        for train_val_index, test_val_index in skf:    \n",
    "            #print ten_fold\n",
    "            ten_fold = ten_fold+1\n",
    "            ''' \n",
    "            train_binary_proto = pd.get_dummies(train.iloc[train_index[train_val_index]]['Proto'])\n",
    "            train_binary_state = pd.get_dummies(train.iloc[train_index[train_val_index]]['State'])\n",
    "            train_binary_dir = pd.get_dummies(train.iloc[train_index[train_val_index]]['Dir'])\n",
    "            train_binary_dport= pd.get_dummies(train.iloc[train_index[train_val_index]]['Dport'])\n",
    "            test_binary_proto = np.zeros([len(test_val_index), len(train_binary_proto.columns)])\n",
    "            test_binary_proto = np.zeros([len(test_val_index), len(train_binary_proto.columns)])\n",
    "            test_binary_proto = np.zeros([len(test_val_index), len(train_binary_proto.columns)])\n",
    "            test_binary_proto = np.zeros([len(test_val_index), len(train_binary_proto.columns)])\n",
    "\n",
    "            (train_proto_lda, proto_lda) = lda_function(train_binary_proto, val_label[train_val_index])\n",
    "            (train_state_lda, state_lda) = lda_function(train_binary_state, val_label[train_val_index])\n",
    "            (train_dir_lda, dir_lda) = lda_function(train_binary_dir, val_label[train_val_index])\n",
    "            (train_dport_lda, dport_lda) = lda_function(train_binary_dport, val_label[train_val_index])\n",
    "            train_lda_np = np.append(train_proto_lda, train_state_lda, 1)\n",
    "            train_lda_np = np.append(train_lda_np, train_dir_lda, 1)\n",
    "            train_lda_np = np.append(train_lda_np, train_dport_lda, 1)\n",
    "            \n",
    "            '''\n",
    "            #print \"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\"\n",
    "            \n",
    "            (now_train_binary_proto,now_test_binary_proto) = del_zero_column(train_binary_proto.iloc[train_val_index],train_binary_proto.iloc[test_val_index])\n",
    "            (now_train_binary_state,now_test_binary_state) = del_zero_column(train_binary_state.iloc[train_val_index], train_binary_state.iloc[test_val_index])\n",
    "            (now_train_binary_dir,now_test_binary_dir) = del_zero_column(train_binary_dir.iloc[train_val_index], train_binary_dir.iloc[test_val_index])\n",
    "            (now_train_binary_dport,now_test_binary_dport) = del_zero_column(train_binary_dport.iloc[train_val_index], train_binary_dport.iloc[test_val_index])\n",
    "            (train_proto_lda, proto_lda) = lda_function(now_train_binary_proto, val_label[train_val_index])\n",
    "            (train_state_lda, state_lda) = lda_function(now_train_binary_state, val_label[train_val_index])\n",
    "            (train_dir_lda, dir_lda) = lda_function(now_train_binary_dir, val_label[train_val_index])\n",
    "            (train_dport_lda, dport_lda) = lda_function(now_train_binary_dport, val_label[train_val_index])\n",
    "            train_lda_np = np.append(train_proto_lda, train_state_lda, 1)\n",
    "            train_lda_np = np.append(train_lda_np, train_dir_lda, 1)\n",
    "            train_lda_np = np.append(train_lda_np, train_dport_lda, 1)\n",
    "\n",
    "\n",
    "            test_proto_lda = proto_lda.transform(now_test_binary_proto)\n",
    "            test_state_lda = state_lda.transform(now_test_binary_state)            \n",
    "            test_dir_lda = dir_lda.transform(now_test_binary_dir)\n",
    "            test_dport_lda = dport_lda.transform(now_test_binary_dport)\n",
    "            test_lda_np = np.append(test_proto_lda, test_state_lda, 1)\n",
    "            test_lda_np = np.append(test_lda_np, test_dir_lda, 1)\n",
    "            test_lda_np = np.append(test_lda_np, test_dport_lda, 1)\n",
    "            \n",
    "            \n",
    "\n",
    "            #train_numpy_pca = train_copy_pca.values\n",
    "            #(train_numpy_pca_norm, test_numpy_pca_norm) = normalization(train_copy_pca.iloc[train_val_index],train_copy_pca.iloc[test_val_index], train_copy_pca.columns)\n",
    "            (train_numpy_lda_norm, test_numpy_lda_norm) = normalization(train_lda_np,test_lda_np)\n",
    "\n",
    "            #----Here--- continue\n",
    "            clf_lda.fit(train_numpy_lda_norm, val_label[train_val_index])\n",
    "            all_score_lda.append(f1_score(clf_lda.predict(test_numpy_lda_norm), val_label[test_val_index]))\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "        lda_fscore = np.average(all_score_lda)\n",
    "        now_lda_fscore.append(lda_fscore)\n",
    "    print 'max:',np.max(now_lda_fscore),  'min:', np.min(now_lda_fscore),'avg:',np.average(now_lda_fscore)\n",
    "    output_fscore.loc[str(index_train_dataset)] = [np.max(now_lda_fscore), np.min(now_lda_fscore), np.average(now_lda_fscore)]\n",
    "    #print 'numeric:', numeric_fscore, 'lda:', lda_fscore \n",
    "\n",
    "\n",
    "    \n",
    "    #print output_fscore.loc[str(index_train_dataset)]\n",
    "    output_fscore.to_csv('lda_tine_3class.csv')\n",
    "    #output_fscore.loc[str(index_train_dataset)] = [numeric_fscore, lda_fscore]\n",
    "    #output_fscore.to_csv('4_string_numeric_vs_lda_no_norm.csv')\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#(train_proto_lda, proto_lda) = lda_function(now_train_binary_proto, val_label[train_val_index])\n",
    "#(train_state_lda, state_lda) = lda_function(now_train_binary_state, val_label[train_val_index])\n",
    "#(train_dir_lda, dir_lda) = lda_function(now_train_binary_dir, val_label[train_val_index])\n",
    "(train_dport_lda, dport_lda) = lda_function(now_train_binary_dport, val_label[train_val_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(train_dport_lda, dport_lda) = lda_function(now_train_binary_dport, val_label[train_val_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda_data = lda.fit_transform(test, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.50847761],\n",
       "       [ 0.67120974],\n",
       "       [ 0.67120974],\n",
       "       ..., \n",
       "       [-1.50847761],\n",
       "       [-1.50847761],\n",
       "       [-1.50847761]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LDA()\n",
    "lda.fit_transform(train_binary_proto.iloc[train_val_index], val_label[train_val_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1508 54\n",
      "1059 449 22 32\n",
      "[0 1 2 3]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "On entry to DGESDD parameter number 10 had an illegal value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-edb6af6c6715>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mtrain_proto_lda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto_lda\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlda_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_binary_proto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_val_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_val_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-71-356d0017d876>\u001b[0m in \u001b[0;36mlda_function\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormal_label\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormal_label\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manomaly_label\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manomaly_label\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mlda_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mlda_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlda_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/anaconda2/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    495\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, store_covariance, tol)\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshrinkage\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'shrinkage not supported'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_solve_svd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'lsqr'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_solve_lsqr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshrinkage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshrinkage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.pyc\u001b[0m in \u001b[0;36m_solve_svd\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[1;31m# Use SVD to find projection in the space spanned by the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m         \u001b[1;31m# (n_classes) centers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m         self.explained_variance_ratio_ = (S**2 / np.sum(\n",
      "\u001b[1;32m/usr/anaconda2/lib/python2.7/site-packages/scipy/linalg/decomp_svd.pyc\u001b[0m in \u001b[0;36msvd\u001b[1;34m(a, full_matrices, compute_uv, overwrite_a, check_finite, lapack_driver)\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# compute optimal lwork\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m     lwork = _compute_lwork(gesXd_lwork, a1.shape[0], a1.shape[1],\n\u001b[1;32m--> 112\u001b[1;33m                            compute_uv=compute_uv, full_matrices=full_matrices)\n\u001b[0m\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[1;31m# perform decomposition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/anaconda2/lib/python2.7/site-packages/scipy/linalg/lapack.pyc\u001b[0m in \u001b[0;36m_compute_lwork\u001b[1;34m(routine, *args, **kwargs)\u001b[0m\n\u001b[0;32m    468\u001b[0m     \u001b[0msome\u001b[0m \u001b[0mcases\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0msmaller\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mrequired\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m     \"\"\"\n\u001b[1;32m--> 470\u001b[1;33m     \u001b[0mwi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroutine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    471\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: On entry to DGESDD parameter number 10 had an illegal value"
     ]
    }
   ],
   "source": [
    "(train_proto_lda, proto_lda) = lda_function(train_binary_proto.iloc[train_val_index], val_label[train_val_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1562, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dport_lda.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arp</th>\n",
       "      <th>tcp</th>\n",
       "      <th>udp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8968</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8969</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8970</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8971</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8972</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      arp  tcp  udp\n",
       "8968  0.0  1.0  0.0\n",
       "8969  0.0  0.0  1.0\n",
       "8970  0.0  1.0  0.0\n",
       "8971  0.0  1.0  0.0\n",
       "8972  0.0  1.0  0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47803030303030303"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
