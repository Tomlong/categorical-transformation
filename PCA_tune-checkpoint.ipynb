{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/anaconda2/lib/python2.7/site-packages/sklearn/lda.py:4: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import time\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.svm import SVC\n",
    "from collections import Counter\n",
    "from sklearn.lda import LDA\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix as confu\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "def normalization(training_numpy, testing_numpy, columns):\n",
    "    min_max = preprocessing.MinMaxScaler()\n",
    "    min_max.fit(training_numpy)\n",
    "    x_scaled = min_max.fit_transform(training_numpy)\n",
    "    testting_x_scaled = min_max.transform(testing_numpy)\n",
    "    training_norm = pd.DataFrame(x_scaled, columns = columns)\n",
    "    testing_norm = pd.DataFrame(testting_x_scaled, columns = columns)\n",
    "    return (training_norm.values, testing_norm.values)\n",
    "\n",
    "def pca_function(n, data):\n",
    "    pca = PCA(n_components=n)\n",
    "    pca_data = pca.fit_transform(data)\n",
    "    return (pca_data.flatten(), pca)\n",
    "\n",
    "def lda_function(X, y):\n",
    "    lda = LDA()\n",
    "    lda_data = lda.fit_transform(X, y)\n",
    "    return (lda_data.flatten(), lda)\n",
    "\n",
    "def replace_value(training_normal_numpy, key, loc):  \n",
    "    training_normal_numpy[loc][key] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key_str = {'Normal':0, 'Botnet':1, 'Background':2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5Times 4 strings normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "1 2\n",
      "training length: 61531 testing length: 16733\n",
      "2 2\n",
      "training length: 16733 testing length: 16733\n",
      "3 2\n",
      "training length: 119454 testing length: 16733\n",
      "4 2\n",
      "training length: 26701 testing length: 16733\n",
      "5 2\n",
      "training length: 5430 testing length: 16733\n",
      "6 2\n",
      "training length: 7720 testing length: 16733\n",
      "7 2\n",
      "training length: 1736 testing length: 16733\n",
      "8 2\n",
      "training length: 74206 testing length: 16733\n",
      "9 2\n",
      "training length: 166826 testing length: 16733\n",
      "10 2\n",
      "training length: 120928 testing length: 16733\n",
      "11 2\n",
      "training length: 10791 testing length: 16733\n",
      "12 2\n",
      "training length: 9788 testing length: 16733\n",
      "13 2\n",
      "training length: 64411 testing length: 16733\n",
      "1 3\n",
      "training length: 61531 testing length: 119454\n",
      "2 3\n",
      "training length: 16733 testing length: 119454\n",
      "3 3\n",
      "training length: 119454 testing length: 119454\n",
      "4 3\n",
      "training length: 26701 testing length: 119454\n",
      "5 3\n",
      "training length: 5430 testing length: 119454\n",
      "6 3\n",
      "training length: 7720 testing length: 119454\n",
      "7 3\n",
      "training length: 1736 testing length: 119454\n",
      "8 3\n",
      "training length: 74206 testing length: 119454\n",
      "9 3\n",
      "training length: 166826 testing length: 119454\n",
      "10 3\n",
      "training length: 120928 testing length: 119454\n",
      "11 3\n",
      "training length: 10791 testing length: 119454\n",
      "12 3\n",
      "training length: 9788 testing length: 119454\n",
      "13 3\n",
      "training length: 64411 testing length: 119454\n",
      "1 4\n",
      "training length: 61531 testing length: 26701\n",
      "2 4\n",
      "training length: 16733 testing length: 26701\n",
      "3 4\n",
      "training length: 119454 testing length: 26701\n",
      "4 4\n",
      "training length: 26701 testing length: 26701\n",
      "5 4\n",
      "training length: 5430 testing length: 26701\n",
      "6 4\n",
      "training length: 7720 testing length: 26701\n",
      "7 4\n",
      "training length: 1736 testing length: 26701\n",
      "8 4\n",
      "training length: 74206 testing length: 26701\n",
      "9 4\n",
      "training length: 166826 testing length: 26701\n",
      "10 4\n",
      "training length: 120928 testing length: 26701\n",
      "11 4\n",
      "training length: 10791 testing length: 26701\n",
      "12 4\n",
      "training length: 9788 testing length: 26701\n",
      "13 4\n",
      "training length: 64411 testing length: 26701\n",
      "1 5\n",
      "training length: 61531 testing length: 5430\n",
      "2 5\n",
      "training length: 16733 testing length: 5430\n",
      "3 5\n",
      "training length: 119454 testing length: 5430\n",
      "4 5\n",
      "training length: 26701 testing length: 5430\n",
      "5 5\n",
      "training length: 5430 testing length: 5430\n",
      "6 5\n",
      "training length: 7720 testing length: 5430\n",
      "7 5\n",
      "training length: 1736 testing length: 5430\n",
      "8 5\n",
      "training length: 74206 testing length: 5430\n",
      "9 5\n",
      "training length: 166826 testing length: 5430\n",
      "10 5\n",
      "training length: 120928 testing length: 5430\n",
      "11 5\n",
      "training length: 10791 testing length: 5430\n",
      "12 5\n",
      "training length: 9788 testing length: 5430\n",
      "13 5\n",
      "training length: 64411 testing length: 5430\n",
      "1 6\n",
      "training length: 61531 testing length: 7720\n",
      "2 6\n",
      "training length: 16733 testing length: 7720\n",
      "3 6\n",
      "training length: 119454 testing length: 7720\n",
      "4 6\n",
      "training length: 26701 testing length: 7720\n",
      "5 6\n",
      "training length: 5430 testing length: 7720\n",
      "6 6\n",
      "training length: 7720 testing length: 7720\n",
      "7 6\n",
      "training length: 1736 testing length: 7720\n",
      "8 6\n",
      "training length: 74206 testing length: 7720\n",
      "9 6\n",
      "training length: 166826 testing length: 7720\n",
      "10 6\n",
      "training length: 120928 testing length: 7720\n",
      "11 6\n",
      "training length: 10791 testing length: 7720\n",
      "12 6\n",
      "training length: 9788 testing length: 7720\n",
      "13 6\n",
      "training length: 64411 testing length: 7720\n",
      "1 7\n",
      "training length: 61531 testing length: 1736\n",
      "2 7\n",
      "training length: 16733 testing length: 1736\n",
      "3 7\n",
      "training length: 119454 testing length: 1736\n",
      "4 7\n",
      "training length: 26701 testing length: 1736\n",
      "5 7\n",
      "training length: 5430 testing length: 1736\n",
      "6 7\n",
      "training length: 7720 testing length: 1736\n",
      "7 7\n",
      "training length: 1736 testing length: 1736\n",
      "8 7\n",
      "training length: 74206 testing length: 1736\n",
      "9 7\n",
      "training length: 166826 testing length: 1736\n",
      "10 7\n",
      "training length: 120928 testing length: 1736\n",
      "11 7\n",
      "training length: 10791 testing length: 1736\n",
      "12 7\n",
      "training length: 9788 testing length: 1736\n",
      "13 7\n",
      "training length: 64411 testing length: 1736\n",
      "1 8\n",
      "training length: 61531 testing length: 74206\n",
      "2 8\n",
      "training length: 16733 testing length: 74206\n",
      "3 8\n",
      "training length: 119454 testing length: 74206\n",
      "4 8\n",
      "training length: 26701 testing length: 74206\n",
      "5 8\n",
      "training length: 5430 testing length: 74206\n",
      "6 8\n",
      "training length: 7720 testing length: 74206\n",
      "7 8\n",
      "training length: 1736 testing length: 74206\n",
      "8 8\n",
      "training length: 74206 testing length: 74206\n",
      "9 8\n",
      "training length: 166826 testing length: 74206\n",
      "10 8\n",
      "training length: 120928 testing length: 74206\n",
      "11 8\n",
      "training length: 10791 testing length: 74206\n",
      "12 8\n",
      "training length: 9788 testing length: 74206\n",
      "13 8\n",
      "training length: 64411 testing length: 74206\n",
      "1 9\n",
      "training length: 61531 testing length: 166826\n",
      "2 9\n",
      "training length: 16733 testing length: 166826\n",
      "3 9\n",
      "training length: 119454 testing length: 166826\n",
      "4 9\n",
      "training length: 26701 testing length: 166826\n",
      "5 9\n",
      "training length: 5430 testing length: 166826\n",
      "6 9\n",
      "training length: 7720 testing length: 166826\n",
      "7 9\n",
      "training length: 1736 testing length: 166826\n",
      "8 9\n",
      "training length: 74206 testing length: 166826\n",
      "9 9\n",
      "training length: 166826 testing length: 166826\n",
      "10 9\n",
      "training length: 120928 testing length: 166826\n",
      "11 9\n",
      "training length: 10791 testing length: 166826\n",
      "12 9\n",
      "training length: 9788 testing length: 166826\n",
      "13 9\n",
      "training length: 64411 testing length: 166826\n",
      "1 10\n",
      "training length: 61531 testing length: 120928\n",
      "2 10\n",
      "training length: 16733 testing length: 120928\n",
      "3 10\n",
      "training length: 119454 testing length: 120928\n",
      "4 10\n",
      "training length: 26701 testing length: 120928\n",
      "5 10\n",
      "training length: 5430 testing length: 120928\n",
      "6 10\n",
      "training length: 7720 testing length: 120928\n",
      "7 10\n",
      "training length: 1736 testing length: 120928\n",
      "8 10\n",
      "training length: 74206 testing length: 120928\n",
      "9 10\n",
      "training length: 166826 testing length: 120928\n",
      "10 10\n",
      "training length: 120928 testing length: 120928\n",
      "11 10\n",
      "training length: 10791 testing length: 120928\n",
      "12 10\n",
      "training length: 9788 testing length: 120928\n",
      "13 10\n",
      "training length: 64411 testing length: 120928\n",
      "1 11\n",
      "training length: 61531 testing length: 10791\n",
      "2 11\n",
      "training length: 16733 testing length: 10791\n",
      "3 11\n",
      "training length: 119454 testing length: 10791\n",
      "4 11\n",
      "training length: 26701 testing length: 10791\n",
      "5 11\n",
      "training length: 5430 testing length: 10791\n",
      "6 11\n",
      "training length: 7720 testing length: 10791\n",
      "7 11\n",
      "training length: 1736 testing length: 10791\n",
      "8 11\n",
      "training length: 74206 testing length: 10791\n",
      "9 11\n",
      "training length: 166826 testing length: 10791\n",
      "10 11\n",
      "training length: 120928 testing length: 10791\n",
      "11 11\n",
      "training length: 10791 testing length: 10791\n",
      "12 11\n",
      "training length: 9788 testing length: 10791\n",
      "13 11\n",
      "training length: 64411 testing length: 10791\n",
      "1 12\n",
      "training length: 61531 testing length: 9788\n",
      "2 12\n",
      "training length: 16733 testing length: 9788\n",
      "3 12\n",
      "training length: 119454 testing length: 9788\n",
      "4 12\n",
      "training length: 26701 testing length: 9788\n",
      "5 12\n",
      "training length: 5430 testing length: 9788\n",
      "6 12\n",
      "training length: 7720 testing length: 9788\n",
      "7 12\n",
      "training length: 1736 testing length: 9788\n",
      "8 12\n",
      "training length: 74206 testing length: 9788\n",
      "9 12\n",
      "training length: 166826 testing length: 9788\n",
      "10 12\n",
      "training length: 120928 testing length: 9788\n",
      "11 12\n",
      "training length: 10791 testing length: 9788\n",
      "12 12\n",
      "training length: 9788 testing length: 9788\n",
      "13 12\n",
      "training length: 64411 testing length: 9788\n",
      "1 13\n",
      "training length: 61531 testing length: 64411\n",
      "2 13\n",
      "training length: 16733 testing length: 64411\n",
      "3 13\n",
      "training length: 119454 testing length: 64411\n",
      "4 13\n",
      "training length: 26701 testing length: 64411\n",
      "5 13\n",
      "training length: 5430 testing length: 64411\n",
      "6 13\n",
      "training length: 7720 testing length: 64411\n",
      "7 13\n",
      "training length: 1736 testing length: 64411\n",
      "8 13\n",
      "training length: 74206 testing length: 64411\n",
      "9 13\n",
      "training length: 166826 testing length: 64411\n",
      "10 13\n",
      "training length: 120928 testing length: 64411\n",
      "11 13\n",
      "training length: 10791 testing length: 64411\n",
      "12 13\n",
      "training length: 9788 testing length: 64411\n",
      "13 13\n",
      "training length: 64411 testing length: 64411\n"
     ]
    }
   ],
   "source": [
    "#output_fscore = pd.DataFrame(columns=['numeric','pca','lda'])\n",
    "'''\n",
    "output_fscore = pd.DataFrame(columns=['numeric_avg','numeric_max','numeric_min',\\\n",
    "                                      'pca_avg','pca_max','pca_min',\\\n",
    "                                      'lda_avg','lda_max','lda_min'])\n",
    "'''\n",
    "#output_fscore = pd.DataFrame(columns=['pca','lda'])\n",
    "validation_list=[[1,2,9], [3,4], [5,13,7],[10,11],[6,8]]\n",
    "#validation_list=[[1,2,9], [3,4]]\n",
    "column_unuse = ['StartTime', 'SrcAddr', 'DstAddr', 'Sport']\n",
    "column_str = ['Proto', 'State','Dir','Dport']\n",
    "for now_validation_candicate in range(1):\n",
    "    print 'start'\n",
    "    for index_test_dataset in range(2,14):\n",
    "        output_fscore = pd.DataFrame(columns=['pca','lda'])\n",
    "        for index_train_dataset in range(1,14):\n",
    "            #print index_train_dataset, index_test_dataset\n",
    "            #if index_train_dataset == index_test_dataset:\n",
    "                #None\n",
    "            print index_train_dataset, index_test_dataset\n",
    "            train = pd.read_csv('botnet_'+str(index_train_dataset)+'.binetflow')\n",
    "            test = pd.read_csv('botnet_'+str(index_test_dataset)+'.binetflow')\n",
    "\n",
    "            # Fill 0 to missing value\n",
    "            # Fill 0 to missing value\n",
    "            train = train.fillna(0)\n",
    "            test = test.fillna(0)\n",
    "            train = train[train['State'] != 0]\n",
    "            test = test[test['State'] != 0]\n",
    "\n",
    "            # Drop unuse columns and row with missing value\n",
    "\n",
    "            missing_state = []\n",
    "            map(lambda word: missing_state.append(word) if word[-1]=='_' else None, np.unique(train['State']))\n",
    "            map(lambda word: missing_state.append(word) if word[-1]=='_' else None, np.unique(test['State']))\n",
    "\n",
    "            for column in column_unuse:\n",
    "                del train[column]\n",
    "                del test[column]\n",
    "\n",
    "            for state in missing_state:\n",
    "                train = train[train['State'] != state]\n",
    "                test = test[test['State'] != state]\n",
    "\n",
    "            # Transfer str label to int lable\n",
    "            label_num = []\n",
    "            label_num_test = []\n",
    "            map(lambda label: map(lambda key: label_num.append(key_str[key]) if key in label else None,key_str.keys()), train['Label'])\n",
    "            map(lambda label: map(lambda key: label_num_test.append(key_str[key]) if key in label else None,key_str.keys()), test['Label'])\n",
    "            train['Label'] = label_num\n",
    "            test['Label'] = label_num_test\n",
    "\n",
    "            # training & testing index\n",
    "            train_index = np.where(train['Label'] == 0)[0].tolist() + np.where(train['Label'] == 1)[0].tolist()\n",
    "            test_index = np.where(test['Label'] == 0)[0].tolist() + np.where(test['Label'] == 1)[0].tolist()\n",
    "            print 'training length:', len(train_index), 'testing length:', len(test_index)\n",
    "\n",
    "            val_label = np.array(label_num)[train_index]\n",
    "            val_label_test = np.array(label_num_test)[test_index]\n",
    "\n",
    "            all_num_fscore = []\n",
    "            all_pca_fscore = []\n",
    "            all_lda_fscore = []\n",
    "            for exp_iteration in range(1):\n",
    "                '''\n",
    "                state_numeric_dic = {}\n",
    "                proto_numeric_dic = {}\n",
    "                dir_numeric_dic = {}\n",
    "                dport_numeric_dic = {}\n",
    "                unique_state = Counter(train.iloc[train_index]['State'])\n",
    "                unique_proto = Counter(train.iloc[train_index]['Proto'])\n",
    "                unique_dir = Counter(train.iloc[train_index]['Dir'])\n",
    "                unique_dport = Counter(train.iloc[train_index]['Dport'])\n",
    "\n",
    "                for i,key in zip((np.random.choice(len(unique_state),len(unique_state),replace=False) + 1), unique_state.keys()):\n",
    "                    state_numeric_dic[key] = float(i)\n",
    "                for i,key in zip((np.random.choice(len(unique_proto),len(unique_proto),replace=False) + 1), unique_proto.keys()):\n",
    "                    proto_numeric_dic[key] = float(i)\n",
    "                for i,key in zip((np.random.choice(len(unique_dir),len(unique_dir),replace=False) + 1), unique_dir.keys()):\n",
    "                    dir_numeric_dic[key] = float(i)\n",
    "                for i,key in zip((np.random.choice(len(unique_dport),len(unique_dport),replace=False) + 1), unique_dport.keys()):\n",
    "                    dport_numeric_dic[key] = float(i)\n",
    "\n",
    "                state_numeric_array = []\n",
    "                proto_numeric_array = []\n",
    "                dir_numeric_array = []\n",
    "                dport_numeric_array = []\n",
    "\n",
    "                state_numeric_array_test = []\n",
    "                proto_numeric_array_test = []\n",
    "                dir_numeric_array_test = []\n",
    "                dport_numeric_array_test = []\n",
    "\n",
    "                map(lambda value: state_numeric_array.append(state_numeric_dic[value]) if value in state_numeric_dic.keys() else state_numeric_array.append(0), train.iloc[train_index]['State'])\n",
    "                map(lambda value: proto_numeric_array.append(proto_numeric_dic[value]) if value in proto_numeric_dic.keys() else proto_numeric_array.append(0), train.iloc[train_index]['Proto'])\n",
    "                map(lambda value: dir_numeric_array.append(dir_numeric_dic[value]) if value in dir_numeric_dic.keys() else dir_numeric_array.append(0), train.iloc[train_index]['Dir'])\n",
    "                map(lambda value: dport_numeric_array.append(dport_numeric_dic[value]) if value in dport_numeric_dic.keys() else dport_numeric_array.append(0), train.iloc[train_index]['Dport'])\n",
    "\n",
    "                map(lambda value: state_numeric_array_test.append(state_numeric_dic[value]) if value in state_numeric_dic.keys() else state_numeric_array_test.append(0), test.iloc[test_index]['State'])\n",
    "                map(lambda value: proto_numeric_array_test.append(proto_numeric_dic[value]) if value in proto_numeric_dic.keys() else proto_numeric_array_test.append(0), test.iloc[test_index]['Proto'])\n",
    "                map(lambda value: dir_numeric_array_test.append(dir_numeric_dic[value]) if value in dir_numeric_dic.keys() else dir_numeric_array_test.append(0), test.iloc[test_index]['Dir'])\n",
    "                map(lambda value: dport_numeric_array_test.append(dport_numeric_dic[value]) if value in dport_numeric_dic.keys() else dport_numeric_array_test.append(0), test.iloc[test_index]['Dport'])\n",
    "\n",
    "                #Start processing numeric feature\n",
    "                train_copy_numeric = pd.DataFrame()\n",
    "                test_copy_numeric = pd.DataFrame()\n",
    "\n",
    "                state_numeric_array = np.array(state_numeric_array)\n",
    "                proto_numeric_array = np.array(proto_numeric_array)\n",
    "                dir_numeric_array = np.array(dir_numeric_array)\n",
    "                dport_numeric_array = np.array(dport_numeric_array)\n",
    "\n",
    "                train_copy_numeric['state_numeric'] = state_numeric_array\n",
    "                train_copy_numeric['proto_numeric'] = proto_numeric_array\n",
    "                train_copy_numeric['dir_numeric'] = dir_numeric_array\n",
    "                train_copy_numeric['dport_numeric'] = dport_numeric_array\n",
    "\n",
    "                state_numeric_array_test = np.array(state_numeric_array_test)\n",
    "                proto_numeric_array_test = np.array(proto_numeric_array_test)\n",
    "                dir_numeric_array_test = np.array(dir_numeric_array_test)\n",
    "                dport_numeric_array_test = np.array(dport_numeric_array_test)\n",
    "\n",
    "                test_copy_numeric['state_numeric'] = state_numeric_array_test\n",
    "                test_copy_numeric['proto_numeric'] = proto_numeric_array_test\n",
    "                test_copy_numeric['dir_numeric'] = dir_numeric_array_test\n",
    "                test_copy_numeric['dport_numeric'] = dport_numeric_array_test\n",
    "\n",
    "                train_numpy_numeric = train_copy_numeric.values\n",
    "                test_numpy_numeric = test_copy_numeric.values\n",
    "                '''\n",
    "                train_binary_proto = pd.get_dummies(train.iloc[train_index]['Proto'])\n",
    "                train_binary_state = pd.get_dummies(train.iloc[train_index]['State'])\n",
    "                train_binary_dir = pd.get_dummies(train.iloc[train_index]['Dir'])\n",
    "                train_binary_dport= pd.get_dummies(train.iloc[train_index]['Dport'])\n",
    "                train_columns = [train_binary_proto.columns, train_binary_state.columns, train_binary_dir.columns, train_binary_dport.columns]\n",
    "\n",
    "                test_binary_proto = pd.DataFrame(columns=train_binary_proto.columns)\n",
    "                test_binary_state = pd.DataFrame(columns=train_binary_state.columns)\n",
    "                test_binary_dir = pd.DataFrame(columns=train_binary_dir.columns)\n",
    "                test_binary_dport = pd.DataFrame(columns=train_binary_dport.columns)\n",
    "                test_binary_list = [test_binary_proto, test_binary_state, test_binary_dir, test_binary_dport]\n",
    "\n",
    "                for str_col_array, str_col_name, test_binary in zip(train_columns, column_str, test_binary_list):\n",
    "                    for now_str_col in str_col_array:\n",
    "                        test_binary[now_str_col] = (test.iloc[test_index][str_col_name] == now_str_col).astype('float')\n",
    "\n",
    "                train_copy_lda = pd.DataFrame()\n",
    "                train_copy_pca = pd.DataFrame()\n",
    "                test_copy_lda = pd.DataFrame()\n",
    "                test_copy_pca = pd.DataFrame()\n",
    "\n",
    "                clf_numeric = knn(n_neighbors=1, algorithm='kd_tree')\n",
    "                clf_lda = knn(n_neighbors=1, algorithm='kd_tree')\n",
    "                clf_pca = knn(n_neighbors=1, algorithm='kd_tree')\n",
    "\n",
    "                train_copy_pca['state_pca'] = np.zeros(len(train_index))\n",
    "                train_copy_pca['proto_pca'] = np.zeros(len(train_index))\n",
    "                train_copy_pca['dir_pca'] = np.zeros(len(train_index))\n",
    "                train_copy_pca['dport_pca'] = np.zeros(len(train_index))\n",
    "                test_copy_pca['state_pca'] = np.zeros(len(test_index))\n",
    "                test_copy_pca['proto_pca'] = np.zeros(len(test_index))\n",
    "                test_copy_pca['dir_pca'] = np.zeros(len(test_index))\n",
    "                test_copy_pca['dport_pca'] = np.zeros(len(test_index))\n",
    "\n",
    "\n",
    "                (train_copy_pca.iloc[:, train_copy_pca.columns.get_loc('proto_pca')], proto_pca) = pca_function(1, train_binary_proto)\n",
    "                (train_copy_pca.iloc[:, train_copy_pca.columns.get_loc('state_pca')], state_pca) = pca_function(1, train_binary_state)\n",
    "                (train_copy_pca.iloc[:, train_copy_pca.columns.get_loc('dir_pca')], dir_pca) = pca_function(1, train_binary_dir)\n",
    "                (train_copy_pca.iloc[:, train_copy_pca.columns.get_loc('dport_pca')], dport_pca) = pca_function(1, train_binary_dport)\n",
    "\n",
    "                test_copy_pca.iloc[:, test_copy_pca.columns.get_loc('proto_pca')] = proto_pca.transform(test_binary_proto).flatten()\n",
    "                test_copy_pca.iloc[:, test_copy_pca.columns.get_loc('state_pca')] = state_pca.transform(test_binary_state).flatten()            \n",
    "                test_copy_pca.iloc[:, test_copy_pca.columns.get_loc('dir_pca')] = dir_pca.transform(test_binary_dir).flatten()\n",
    "                test_copy_pca.iloc[:, test_copy_pca.columns.get_loc('dport_pca')] = dport_pca.transform(test_binary_dport).flatten()\n",
    "\n",
    "\n",
    "                train_copy_lda['state_lda'] = np.zeros(len(train_index))\n",
    "                train_copy_lda['proto_lda'] = np.zeros(len(train_index))\n",
    "                train_copy_lda['dir_lda'] = np.zeros(len(train_index))\n",
    "                train_copy_lda['dport_lda'] = np.zeros(len(train_index))\n",
    "                test_copy_lda['state_lda'] = np.zeros(len(test_index))\n",
    "                test_copy_lda['proto_lda'] = np.zeros(len(test_index))\n",
    "                test_copy_lda['dir_lda'] = np.zeros(len(test_index))\n",
    "                test_copy_lda['dport_lda'] = np.zeros(len(test_index))\n",
    "\n",
    "\n",
    "                (train_copy_lda.iloc[:, train_copy_lda.columns.get_loc('proto_lda')], proto_lda) = lda_function(train_binary_proto, val_label)\n",
    "                (train_copy_lda.iloc[:, train_copy_lda.columns.get_loc('state_lda')], state_lda) = lda_function(train_binary_state, val_label)\n",
    "                (train_copy_lda.iloc[:, train_copy_lda.columns.get_loc('dir_lda')], dir_lda) = lda_function(train_binary_dir, val_label)\n",
    "                (train_copy_lda.iloc[:, train_copy_lda.columns.get_loc('dport_lda')], dport_lda) = lda_function(train_binary_dport, val_label)\n",
    "\n",
    "                test_copy_lda.iloc[:, test_copy_lda.columns.get_loc('proto_lda')] = proto_lda.transform(test_binary_proto).flatten()\n",
    "                test_copy_lda.iloc[:, test_copy_lda.columns.get_loc('state_lda')] = state_lda.transform(test_binary_state).flatten()\n",
    "                test_copy_lda.iloc[:, test_copy_lda.columns.get_loc('dir_lda')] = dir_lda.transform(test_binary_dir).flatten()\n",
    "                test_copy_lda.iloc[:, test_copy_lda.columns.get_loc('dport_lda')] = dport_lda.transform(test_binary_dport).flatten()\n",
    "\n",
    "                (train_numpy_pca_norm, test_numpy_pca_norm) = normalization(train_copy_pca, test_copy_pca, train_copy_pca.columns)\n",
    "                clf_pca.fit(train_numpy_pca_norm, val_label)\n",
    "\n",
    "                (train_numpy_lda_norm, test_numpy_lda_norm) = normalization(train_copy_lda, test_copy_lda, train_copy_lda.columns)\n",
    "                clf_lda.fit(train_numpy_lda_norm, val_label)\n",
    "                #(train_numpy_numeric_norm, test_numpy_numeric_norm) = normalization(train_copy_numeric, test_copy_numeric, train_copy_numeric.columns)\n",
    "                #clf_numeric.fit(train_numpy_numeric_norm, val_label)\n",
    "                #numeric_fs = f1_score(clf_numeric.predict(test_numpy_numeric_norm), val_label_test)\n",
    "                pca_fs = f1_score(clf_pca.predict(test_numpy_pca_norm), val_label_test)\n",
    "                lda_fs = f1_score(clf_lda.predict(test_numpy_lda_norm), val_label_test)\n",
    "                #all_num_fscore.append(numeric_fs)\n",
    "                all_pca_fscore.append(pca_fs)\n",
    "                all_lda_fscore.append(lda_fs)\n",
    "\n",
    "            output_fscore.loc[str(index_train_dataset)+'->'+str(index_test_dataset)] = [np.max(all_pca_fscore),np.max(all_lda_fscore)]\n",
    "            output_fscore.to_csv('cross_experiment_all_to_'+str(index_test_dataset)+'.csv')\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training length: 5430 testing length: 1736\n",
      "0.176470588235 0.622222222222 0.133333333333\n"
     ]
    }
   ],
   "source": [
    "output_fscore = pd.DataFrame(columns=['numeric','pca','lda'])\n",
    "train = pd.read_csv('botnet_'+str(5)+'.binetflow')\n",
    "test = pd.read_csv('botnet_'+str(7)+'.binetflow')\n",
    "\n",
    "# Fill 0 to missing value\n",
    "# Fill 0 to missing value\n",
    "train = train.fillna(0)\n",
    "test = test.fillna(0)\n",
    "train = train[train['State'] != 0]\n",
    "test = test[test['State'] != 0]\n",
    "\n",
    "# Drop unuse columns and row with missing value\n",
    "\n",
    "missing_state = []\n",
    "map(lambda word: missing_state.append(word) if word[-1]=='_' else None, np.unique(train['State']))\n",
    "map(lambda word: missing_state.append(word) if word[-1]=='_' else None, np.unique(test['State']))\n",
    "\n",
    "for column in column_unuse:\n",
    "    del train[column]\n",
    "    del test[column]\n",
    "\n",
    "for state in missing_state:\n",
    "    train = train[train['State'] != state]\n",
    "    test = test[test['State'] != state]\n",
    "\n",
    "# Transfer str label to int lable\n",
    "label_num = []\n",
    "label_num_test = []\n",
    "map(lambda label: map(lambda key: label_num.append(key_str[key]) if key in label else None,key_str.keys()), train['Label'])\n",
    "map(lambda label: map(lambda key: label_num_test.append(key_str[key]) if key in label else None,key_str.keys()), test['Label'])\n",
    "train['Label'] = label_num\n",
    "test['Label'] = label_num_test\n",
    "\n",
    "# training & testing index\n",
    "train_index = np.where(train['Label'] == 0)[0].tolist() + np.where(train['Label'] == 1)[0].tolist()\n",
    "test_index = np.where(test['Label'] == 0)[0].tolist() + np.where(test['Label'] == 1)[0].tolist()\n",
    "print 'training length:', len(train_index), 'testing length:', len(test_index)\n",
    "\n",
    "val_label = np.array(label_num)[train_index]\n",
    "val_label_test = np.array(label_num_test)[test_index]\n",
    "\n",
    "state_numeric_dic = {}\n",
    "proto_numeric_dic = {}\n",
    "dir_numeric_dic = {}\n",
    "dport_numeric_dic = {}\n",
    "unique_state = Counter(train.iloc[train_index]['State'])\n",
    "unique_proto = Counter(train.iloc[train_index]['Proto'])\n",
    "unique_dir = Counter(train.iloc[train_index]['Dir'])\n",
    "unique_dport = Counter(train.iloc[train_index]['Dport'])\n",
    "\n",
    "for i,key in zip((np.random.choice(len(unique_state),len(unique_state),replace=False) + 1), unique_state.keys()):\n",
    "    state_numeric_dic[key] = float(i)\n",
    "for i,key in zip((np.random.choice(len(unique_proto),len(unique_proto),replace=False) + 1), unique_proto.keys()):\n",
    "    proto_numeric_dic[key] = float(i)\n",
    "for i,key in zip((np.random.choice(len(unique_dir),len(unique_dir),replace=False) + 1), unique_dir.keys()):\n",
    "    dir_numeric_dic[key] = float(i)\n",
    "for i,key in zip((np.random.choice(len(unique_dport),len(unique_dport),replace=False) + 1), unique_dport.keys()):\n",
    "    dport_numeric_dic[key] = float(i)\n",
    "\n",
    "state_numeric_array = []\n",
    "proto_numeric_array = []\n",
    "dir_numeric_array = []\n",
    "dport_numeric_array = []\n",
    "\n",
    "state_numeric_array_test = []\n",
    "proto_numeric_array_test = []\n",
    "dir_numeric_array_test = []\n",
    "dport_numeric_array_test = []\n",
    "\n",
    "map(lambda value: state_numeric_array.append(state_numeric_dic[value]) if value in state_numeric_dic.keys() else state_numeric_array.append(0), train.iloc[train_index]['State'])\n",
    "map(lambda value: proto_numeric_array.append(proto_numeric_dic[value]) if value in proto_numeric_dic.keys() else proto_numeric_array.append(0), train.iloc[train_index]['Proto'])\n",
    "map(lambda value: dir_numeric_array.append(dir_numeric_dic[value]) if value in dir_numeric_dic.keys() else dir_numeric_array.append(0), train.iloc[train_index]['Dir'])\n",
    "map(lambda value: dport_numeric_array.append(dport_numeric_dic[value]) if value in dport_numeric_dic.keys() else dport_numeric_array.append(0), train.iloc[train_index]['Dport'])\n",
    "\n",
    "map(lambda value: state_numeric_array_test.append(state_numeric_dic[value]) if value in state_numeric_dic.keys() else state_numeric_array_test.append(0), test.iloc[test_index]['State'])\n",
    "map(lambda value: proto_numeric_array_test.append(proto_numeric_dic[value]) if value in proto_numeric_dic.keys() else proto_numeric_array_test.append(0), test.iloc[test_index]['Proto'])\n",
    "map(lambda value: dir_numeric_array_test.append(dir_numeric_dic[value]) if value in dir_numeric_dic.keys() else dir_numeric_array_test.append(0), test.iloc[test_index]['Dir'])\n",
    "map(lambda value: dport_numeric_array_test.append(dport_numeric_dic[value]) if value in dport_numeric_dic.keys() else dport_numeric_array_test.append(0), test.iloc[test_index]['Dport'])\n",
    "\n",
    "#Start processing numeric feature\n",
    "train_copy_numeric = pd.DataFrame()\n",
    "test_copy_numeric = pd.DataFrame()\n",
    "\n",
    "state_numeric_array = np.array(state_numeric_array)\n",
    "proto_numeric_array = np.array(proto_numeric_array)\n",
    "dir_numeric_array = np.array(dir_numeric_array)\n",
    "dport_numeric_array = np.array(dport_numeric_array)\n",
    "\n",
    "train_copy_numeric['state_numeric'] = state_numeric_array\n",
    "train_copy_numeric['proto_numeric'] = proto_numeric_array\n",
    "train_copy_numeric['dir_numeric'] = dir_numeric_array\n",
    "train_copy_numeric['dport_numeric'] = dport_numeric_array\n",
    "\n",
    "state_numeric_array_test = np.array(state_numeric_array_test)\n",
    "proto_numeric_array_test = np.array(proto_numeric_array_test)\n",
    "dir_numeric_array_test = np.array(dir_numeric_array_test)\n",
    "dport_numeric_array_test = np.array(dport_numeric_array_test)\n",
    "\n",
    "test_copy_numeric['state_numeric'] = state_numeric_array_test\n",
    "test_copy_numeric['proto_numeric'] = proto_numeric_array_test\n",
    "test_copy_numeric['dir_numeric'] = dir_numeric_array_test\n",
    "test_copy_numeric['dport_numeric'] = dport_numeric_array_test\n",
    "\n",
    "train_numpy_numeric = train_copy_numeric.values\n",
    "test_numpy_numeric = test_copy_numeric.values\n",
    "\n",
    "train_binary_proto = pd.get_dummies(train.iloc[train_index]['Proto'])\n",
    "train_binary_state = pd.get_dummies(train.iloc[train_index]['State'])\n",
    "train_binary_dir = pd.get_dummies(train.iloc[train_index]['Dir'])\n",
    "train_binary_dport= pd.get_dummies(train.iloc[train_index]['Dport'])\n",
    "train_columns = [train_binary_proto.columns, train_binary_state.columns, train_binary_dir.columns, train_binary_dport.columns]\n",
    "\n",
    "test_binary_proto = pd.DataFrame(columns=train_binary_proto.columns)\n",
    "test_binary_state = pd.DataFrame(columns=train_binary_state.columns)\n",
    "test_binary_dir = pd.DataFrame(columns=train_binary_dir.columns)\n",
    "test_binary_dport = pd.DataFrame(columns=train_binary_dport.columns)\n",
    "test_binary_list = [test_binary_proto, test_binary_state, test_binary_dir, test_binary_dport]\n",
    "\n",
    "for str_col_array, str_col_name, test_binary in zip(train_columns, column_str, test_binary_list):\n",
    "    for now_str_col in str_col_array:\n",
    "        test_binary[now_str_col] = (test.iloc[test_index][str_col_name] == now_str_col).astype('float')\n",
    "\n",
    "train_copy_lda = pd.DataFrame()\n",
    "train_copy_pca = pd.DataFrame()\n",
    "test_copy_lda = pd.DataFrame()\n",
    "test_copy_pca = pd.DataFrame()\n",
    "\n",
    "clf_numeric = knn(n_neighbors=1, algorithm='kd_tree')\n",
    "clf_lda = knn(n_neighbors=1, algorithm='kd_tree')\n",
    "clf_pca = knn(n_neighbors=1, algorithm='kd_tree')\n",
    "\n",
    "train_copy_pca['state_pca'] = np.zeros(len(train_index))\n",
    "train_copy_pca['proto_pca'] = np.zeros(len(train_index))\n",
    "train_copy_pca['dir_pca'] = np.zeros(len(train_index))\n",
    "train_copy_pca['dport_pca'] = np.zeros(len(train_index))\n",
    "test_copy_pca['state_pca'] = np.zeros(len(test_index))\n",
    "test_copy_pca['proto_pca'] = np.zeros(len(test_index))\n",
    "test_copy_pca['dir_pca'] = np.zeros(len(test_index))\n",
    "test_copy_pca['dport_pca'] = np.zeros(len(test_index))\n",
    "\n",
    "\n",
    "(train_copy_pca.iloc[:, train_copy_pca.columns.get_loc('proto_pca')], proto_pca) = pca_function(1, train_binary_proto)\n",
    "(train_copy_pca.iloc[:, train_copy_pca.columns.get_loc('state_pca')], state_pca) = pca_function(1, train_binary_state)\n",
    "(train_copy_pca.iloc[:, train_copy_pca.columns.get_loc('dir_pca')], dir_pca) = pca_function(1, train_binary_dir)\n",
    "(train_copy_pca.iloc[:, train_copy_pca.columns.get_loc('dport_pca')], dport_pca) = pca_function(1, train_binary_dport)\n",
    "\n",
    "test_copy_pca.iloc[:, test_copy_pca.columns.get_loc('proto_pca')] = proto_pca.transform(test_binary_proto).flatten()\n",
    "test_copy_pca.iloc[:, test_copy_pca.columns.get_loc('state_pca')] = state_pca.transform(test_binary_state).flatten()            \n",
    "test_copy_pca.iloc[:, test_copy_pca.columns.get_loc('dir_pca')] = dir_pca.transform(test_binary_dir).flatten()\n",
    "test_copy_pca.iloc[:, test_copy_pca.columns.get_loc('dport_pca')] = dport_pca.transform(test_binary_dport).flatten()\n",
    "\n",
    "\n",
    "train_copy_lda['state_lda'] = np.zeros(len(train_index))\n",
    "train_copy_lda['proto_lda'] = np.zeros(len(train_index))\n",
    "train_copy_lda['dir_lda'] = np.zeros(len(train_index))\n",
    "train_copy_lda['dport_lda'] = np.zeros(len(train_index))\n",
    "test_copy_lda['state_lda'] = np.zeros(len(test_index))\n",
    "test_copy_lda['proto_lda'] = np.zeros(len(test_index))\n",
    "test_copy_lda['dir_lda'] = np.zeros(len(test_index))\n",
    "test_copy_lda['dport_lda'] = np.zeros(len(test_index))\n",
    "\n",
    "\n",
    "(train_copy_lda.iloc[:, train_copy_lda.columns.get_loc('proto_lda')], proto_lda) = lda_function(train_binary_proto, val_label)\n",
    "(train_copy_lda.iloc[:, train_copy_lda.columns.get_loc('state_lda')], state_lda) = lda_function(train_binary_state, val_label)\n",
    "(train_copy_lda.iloc[:, train_copy_lda.columns.get_loc('dir_lda')], dir_lda) = lda_function(train_binary_dir, val_label)\n",
    "(train_copy_lda.iloc[:, train_copy_lda.columns.get_loc('dport_lda')], dport_lda) = lda_function(train_binary_dport, val_label)\n",
    "\n",
    "test_copy_lda.iloc[:, test_copy_lda.columns.get_loc('proto_lda')] = proto_lda.transform(test_binary_proto).flatten()\n",
    "test_copy_lda.iloc[:, test_copy_lda.columns.get_loc('state_lda')] = state_lda.transform(test_binary_state).flatten()\n",
    "test_copy_lda.iloc[:, test_copy_lda.columns.get_loc('dir_lda')] = dir_lda.transform(test_binary_dir).flatten()\n",
    "test_copy_lda.iloc[:, test_copy_lda.columns.get_loc('dport_lda')] = dport_lda.transform(test_binary_dport).flatten()\n",
    "\n",
    "(train_numpy_pca_norm, test_numpy_pca_norm) = normalization(train_copy_pca, test_copy_pca, train_copy_pca.columns)\n",
    "clf_pca.fit(train_numpy_pca_norm, val_label)\n",
    "(train_numpy_lda_norm, test_numpy_lda_norm) = normalization(train_copy_lda, test_copy_lda, train_copy_lda.columns)\n",
    "clf_lda.fit(train_numpy_lda_norm, val_label)\n",
    "(train_numpy_numeric_norm, test_numpy_numeric_norm) = normalization(train_copy_numeric, test_copy_numeric, train_copy_numeric.columns)\n",
    "clf_numeric.fit(train_numpy_numeric_norm, val_label)\n",
    "numeric_fs = f1_score(clf_numeric.predict(test_numpy_numeric_norm), val_label_test)\n",
    "pca_fs = f1_score(clf_pca.predict(test_numpy_pca_norm), val_label_test)\n",
    "lda_fs = f1_score(clf_lda.predict(test_numpy_lda_norm), val_label_test)\n",
    "output_fscore.loc[str(index_train_dataset)+'->'+str(index_test_dataset)] = [numeric_fs, pca_fs, lda_fs]\n",
    "print numeric_fs, pca_fs, lda_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numeric</th>\n",
       "      <th>pca</th>\n",
       "      <th>lda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1-&gt;2</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       numeric       pca       lda\n",
       "1->2  0.176471  0.622222  0.133333"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_binary = pd.DataFrame(columns=train_binary.columns)\n",
    "for column in train_binary.columns:\n",
    "    print column\n",
    "    #(train.iloc[train_index[100:200]]['Proto'] == column).dtype('float')\n",
    "    test_binary[column] = (train.iloc[train_index[100:200]]['Proto'] == column).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 1 training length: 61531\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Dataset: 2 training length: 16733\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Dataset: 3 training length: 119454\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Dataset: 4 training length: 26701\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Dataset: 5 training length: 5430\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Dataset: 6 training length: 7720\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Dataset: 7 training length: 1736\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Dataset: 8 training length: 74206\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Dataset: 9 training length: 166826\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Dataset: 10 training length: 120928\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Dataset: 11 training length: 10791\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Dataset: 12 training length: 9788\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Dataset: 13 training length: 64411\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "column_unuse = ['StartTime', 'SrcAddr', 'DstAddr', 'Sport']\n",
    "column_str = ['Proto', 'State','Dir','Dport']\n",
    "score_list = {}\n",
    "fscore_list = {}\n",
    "output_fscore = pd.DataFrame(columns=['Numeric_fscore_avg','Numeric_fscore_max','Numeric_fscore_min',\\\n",
    "                                      'Lda_fscore_avg', 'Lda_fscore_max', 'Lda_fscore_min',\\\n",
    "                                      'Pca_fscore_avg', 'Pca_fscore_max', 'Pca_fscore_min'])\n",
    "#output_fscore = pd.DataFrame(columns=['Numeric_fscore', 'Lda_fscore'])\n",
    "#output_fscore = pd.DataFrame(columns=['Numeric_proto', 'Numeric_state', 'Numeric_dir', 'Numeric_dport', 'Binary_proto', 'Binary_state', 'Binary_dir','Binary_dport'])\n",
    "\n",
    "\n",
    "\n",
    "for index_train_dataset in xrange(1,14): \n",
    "   \n",
    "    train = pd.read_csv('botnet_'+str(index_train_dataset)+'.binetflow')\n",
    "\n",
    "    # Fill 0 to missing value\n",
    "    train = train.fillna(0)    \n",
    "    train = train[train['State'] != 0]\n",
    "\n",
    "    # Drop unuse columns and row with missing value\n",
    "    missing_state = []\n",
    "    map(lambda word: missing_state.append(word) if word[-1]=='_' else None, np.unique(train['State']))\n",
    "\n",
    "    for column in column_unuse:\n",
    "        del train[column]\n",
    "\n",
    "    for state in missing_state:\n",
    "        train = train[train['State'] != state]\n",
    "\n",
    "\n",
    "    # Transfer str label to int lable\n",
    "    label_num = []\n",
    "\n",
    "    map(lambda label: map(lambda key: label_num.append(key_str[key]) if key in label else None,key_str.keys()), train['Label'])\n",
    "    train['Label'] = label_num\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # training & testing index\n",
    "    train_index = np.where(train['Label'] == 0)[0].tolist() + np.where(train['Label'] == 1)[0].tolist()\n",
    "    print 'Dataset:',index_train_dataset, 'training length:', len(train_index)\n",
    "    \n",
    "    now_numeric_fscore = []\n",
    "    now_lda_fscore = []\n",
    "    now_pca_fscore = []\n",
    "    \n",
    "    for exp_interation in range(10):\n",
    "        print exp_interation\n",
    "        # Numeric method\n",
    "        state_numeric_dic = {}\n",
    "        proto_numeric_dic = {}\n",
    "        dir_numeric_dic = {}\n",
    "        dport_numeric_dic = {}\n",
    "        unique_state = Counter(train.iloc[train_index]['State'])\n",
    "        unique_proto = Counter(train.iloc[train_index]['Proto'])\n",
    "        unique_dir = Counter(train.iloc[train_index]['Dir'])\n",
    "        unique_dport = Counter(train.iloc[train_index]['Dport'])\n",
    "\n",
    "        for i,key in zip((np.random.choice(len(unique_state),len(unique_state),replace=False) + 1), unique_state.keys()):\n",
    "            state_numeric_dic[key] = float(i)\n",
    "        for i,key in zip((np.random.choice(len(unique_proto),len(unique_proto),replace=False) + 1), unique_proto.keys()):\n",
    "            proto_numeric_dic[key] = float(i)\n",
    "        for i,key in zip((np.random.choice(len(unique_dir),len(unique_dir),replace=False) + 1), unique_dir.keys()):\n",
    "            dir_numeric_dic[key] = float(i)\n",
    "        for i,key in zip((np.random.choice(len(unique_dport),len(unique_dport),replace=False) + 1), unique_dport.keys()):\n",
    "            dport_numeric_dic[key] = float(i)\n",
    "\n",
    "        state_numeric_array = []\n",
    "        proto_numeric_array = []\n",
    "        dir_numeric_array = []\n",
    "        dport_numeric_array = []\n",
    "        map(lambda value: state_numeric_array.append(state_numeric_dic[value]) if value in state_numeric_dic.keys() else state_numeric_array.append(0), train['State'])\n",
    "        map(lambda value: proto_numeric_array.append(proto_numeric_dic[value]) if value in proto_numeric_dic.keys() else proto_numeric_array.append(0), train['Proto'])\n",
    "        map(lambda value: dir_numeric_array.append(dir_numeric_dic[value]) if value in dir_numeric_dic.keys() else dir_numeric_array.append(0), train['Dir'])\n",
    "        map(lambda value: dport_numeric_array.append(dport_numeric_dic[value]) if value in dport_numeric_dic.keys() else dport_numeric_array.append(0), train['Dport'])\n",
    "\n",
    "        #Start processing numeric feature\n",
    "        #train_copy_numeric = train.iloc[train_index].copy()\n",
    "        train_copy_numeric = pd.DataFrame()\n",
    "\n",
    "        state_numeric_array = np.array(state_numeric_array)[train_index]\n",
    "        proto_numeric_array = np.array(proto_numeric_array)[train_index]\n",
    "        dir_numeric_array = np.array(dir_numeric_array)[train_index]\n",
    "        dport_numeric_array = np.array(dport_numeric_array)[train_index]\n",
    "\n",
    "\n",
    "        train_copy_numeric['state_numeric'] = state_numeric_array\n",
    "        train_copy_numeric['proto_numeric'] = proto_numeric_array\n",
    "        train_copy_numeric['dir_numeric'] = dir_numeric_array\n",
    "        train_copy_numeric['dport_numeric'] = dport_numeric_array\n",
    "\n",
    "        train_numpy_numeric = train_copy_numeric.values\n",
    "\n",
    "\n",
    "        all_score_numeric = []\n",
    "        all_score_lda = []\n",
    "        all_score_pca = []\n",
    "        skf = StratifiedKFold(np.array(label_num)[train_index], n_folds=10)\n",
    "        val_label = np.array(label_num)[train_index]\n",
    "\n",
    "        train_binary_proto = pd.get_dummies(train.iloc[train_index]['Proto'])\n",
    "        train_binary_state = pd.get_dummies(train.iloc[train_index]['State'])\n",
    "        train_binary_dir = pd.get_dummies(train.iloc[train_index]['Dir'])\n",
    "        train_binary_dport= pd.get_dummies(train.iloc[train_index]['Dport'])\n",
    "\n",
    "        train_copy_lda = pd.DataFrame()\n",
    "        train_copy_pca = pd.DataFrame()\n",
    "        #for column in column_str:\n",
    "        #    del train_copy_lda[column]\n",
    "        #del train_copy_lda['Label']\n",
    "\n",
    "        clf_numeric = knn(n_neighbors=1, algorithm='kd_tree')\n",
    "        clf_lda = knn(n_neighbors=1, algorithm='kd_tree')\n",
    "        clf_pca = knn(n_neighbors=1, algorithm='kd_tree')\n",
    "        #clf_numeric = SVC(C=10,kernel='linear', class_weight='balanced')\n",
    "        #clf_lda = SVC(C=10,kernel='linear',class_weight='balanced')\n",
    "\n",
    "        for train_val_index, test_val_index in skf:\n",
    "            (train_numpy_numeric_norm, test_numpy_numeric_norm) = normalization(train_copy_numeric.iloc[train_val_index],train_copy_numeric.iloc[test_val_index], train_copy_numeric.columns)\n",
    "            clf_numeric.fit(train_numpy_numeric_norm, val_label[train_val_index])        \n",
    "            all_score_numeric.append(f1_score(clf_numeric.predict(test_numpy_numeric_norm), val_label[test_val_index]))\n",
    "            #clf_numeric.fit(train_numpy_numeric[train_val_index], val_label[train_val_index])\n",
    "            #all_score_numeric.append(f1_score(clf_numeric.predict(train_numpy_numeric[test_val_index]), val_label[test_val_index]))\n",
    "            #all_score_numeric.append(clf_numeric.score(train_numpy_numeric[test_val_index], val_label[test_val_index]))\n",
    "            \n",
    "            train_copy_pca['state_pca'] = np.zeros(len(train_index))\n",
    "            train_copy_pca['proto_pca'] = np.zeros(len(train_index))\n",
    "            train_copy_pca['dir_pca'] = np.zeros(len(train_copy_pca))\n",
    "            train_copy_pca['dport_pca'] = np.zeros(len(train_copy_pca))\n",
    "            \n",
    "            (train_copy_pca.iloc[train_val_index, train_copy_pca.columns.get_loc('proto_pca')], proto_pca) = pca_function(1, train_binary_proto.iloc[train_val_index])\n",
    "            (train_copy_pca.iloc[train_val_index, train_copy_pca.columns.get_loc('state_pca')], state_pca) = pca_function(1, train_binary_state.iloc[train_val_index])\n",
    "            (train_copy_pca.iloc[train_val_index, train_copy_pca.columns.get_loc('dir_pca')], dir_pca) = pca_function(1, train_binary_dir.iloc[train_val_index])\n",
    "            (train_copy_pca.iloc[train_val_index, train_copy_pca.columns.get_loc('dport_pca')], dport_pca) = pca_function(1, train_binary_dport.iloc[train_val_index])\n",
    "            \n",
    "            train_copy_pca.iloc[test_val_index, train_copy_pca.columns.get_loc('proto_pca')] = proto_pca.transform(train_binary_proto.iloc[test_val_index]).flatten()\n",
    "            train_copy_pca.iloc[test_val_index, train_copy_pca.columns.get_loc('state_pca')] = state_pca.transform(train_binary_state.iloc[test_val_index]).flatten()            \n",
    "            train_copy_pca.iloc[test_val_index, train_copy_pca.columns.get_loc('dir_pca')] = dir_pca.transform(train_binary_dir.iloc[test_val_index]).flatten()\n",
    "            train_copy_pca.iloc[test_val_index, train_copy_pca.columns.get_loc('dport_pca')] = dport_pca.transform(train_binary_dport.iloc[test_val_index]).flatten()\n",
    "\n",
    "            train_numpy_pca = train_copy_pca.values\n",
    "            (train_numpy_pca_norm, test_numpy_pca_norm) = normalization(train_copy_pca.iloc[train_val_index],train_copy_pca.iloc[test_val_index], train_copy_pca.columns)\n",
    "            clf_pca.fit(train_numpy_pca_norm, val_label[train_val_index])\n",
    "            all_score_pca.append(f1_score(clf_pca.predict(test_numpy_pca_norm), val_label[test_val_index]))\n",
    "\n",
    "            train_copy_lda['state_lda'] = np.zeros(len(train_index))\n",
    "            train_copy_lda['proto_lda'] = np.zeros(len(train_index))\n",
    "            train_copy_lda['dir_lda'] = np.zeros(len(train_index))\n",
    "            train_copy_lda['dport_lda'] = np.zeros(len(train_index))\n",
    "\n",
    "            (train_copy_lda.iloc[train_val_index, train_copy_lda.columns.get_loc('proto_lda')], proto_lda) = lda_function(train_binary_proto.iloc[train_val_index], val_label[train_val_index])\n",
    "            (train_copy_lda.iloc[train_val_index, train_copy_lda.columns.get_loc('state_lda')], state_lda) = lda_function(train_binary_state.iloc[train_val_index], val_label[train_val_index])\n",
    "            (train_copy_lda.iloc[train_val_index, train_copy_lda.columns.get_loc('dir_lda')], dir_lda) = lda_function(train_binary_dir.iloc[train_val_index], val_label[train_val_index])\n",
    "            (train_copy_lda.iloc[train_val_index, train_copy_lda.columns.get_loc('dport_lda')], dport_lda) = lda_function(train_binary_dport.iloc[train_val_index], val_label[train_val_index])\n",
    "\n",
    "            train_copy_lda.iloc[test_val_index, train_copy_lda.columns.get_loc('proto_lda')] = proto_lda.transform(train_binary_proto.iloc[test_val_index]).flatten()\n",
    "            train_copy_lda.iloc[test_val_index, train_copy_lda.columns.get_loc('state_lda')] = state_lda.transform(train_binary_state.iloc[test_val_index]).flatten()\n",
    "            train_copy_lda.iloc[test_val_index, train_copy_lda.columns.get_loc('dir_lda')] = dir_lda.transform(train_binary_dir.iloc[test_val_index]).flatten()\n",
    "            train_copy_lda.iloc[test_val_index, train_copy_lda.columns.get_loc('dport_lda')] = dport_lda.transform(train_binary_dport.iloc[test_val_index]).flatten()\n",
    "\n",
    "            train_numpy_lda = train_copy_lda.values\n",
    "            (train_numpy_lda_norm, test_numpy_lda_norm) = normalization(train_copy_lda.iloc[train_val_index],train_copy_lda.iloc[test_val_index], train_copy_lda.columns)\n",
    "\n",
    "            \n",
    "            clf_lda.fit(train_numpy_lda_norm, val_label[train_val_index])\n",
    "            all_score_lda.append(f1_score(clf_lda.predict(test_numpy_lda_norm), val_label[test_val_index]))\n",
    "            #all_score_lda.append(clf_lda.score(train_numpy_lda[test_val_index], val_label[test_val_index]))       \n",
    "            #clf_lda.fit(train_numpy_lda[train_val_index], val_label[train_val_index])\n",
    "            #all_score_lda.append(f1_score(clf_lda.predict(train_numpy_lda[test_val_index]), val_label[test_val_index]))\n",
    "        numeric_fscore = np.average(all_score_numeric)\n",
    "        lda_fscore = np.average(all_score_lda)\n",
    "        pca_fscore = np.average(all_score_pca)\n",
    "        now_numeric_fscore.append(numeric_fscore)\n",
    "        now_lda_fscore.append(lda_fscore)     \n",
    "        now_pca_fscore.append(pca_fscore)\n",
    "        #print 'numeric:', numeric_fscore, 'lda:', lda_fscore \n",
    "\n",
    "\n",
    "    output_fscore.loc[str(index_train_dataset)] = [np.average(now_numeric_fscore),np.max(now_numeric_fscore),np.min(now_numeric_fscore),\\\n",
    "                                                   np.average(now_lda_fscore), np.max(now_lda_fscore), np.min(now_lda_fscore),\\\n",
    "                                                   np.average(now_pca_fscore), np.max(now_pca_fscore), np.min(now_pca_fscore),]\n",
    "    #print output_fscore.loc[str(index_train_dataset)]\n",
    "    output_fscore.to_csv('4_string_numeric_lda_pca_norm(10times).csv')\n",
    "    #output_fscore.loc[str(index_train_dataset)] = [numeric_fscore, lda_fscore]\n",
    "    #output_fscore.to_csv('4_string_numeric_vs_lda_no_norm.csv')\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#C:1\n",
    "Dataset: 12 training length: 9788\n",
    "Numeric_fscore_avg    0.638486\n",
    "Numeric_fscore_max    0.734450\n",
    "Numeric_fscore_min    0.559897\n",
    "Lda_fscor_avg         0.874845\n",
    "Lda_fscor_max         0.874845\n",
    "Lda_fscor_min         0.874845\n",
    "Name: 12, dtype: float64"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
