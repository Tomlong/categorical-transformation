{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import time\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import category_encoders\n",
    "from numpy.linalg.linalg import LinAlgError\n",
    "from collections import Counter\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression as lr\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix as confu\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "from sklearn.cluster import KMeans\n",
    "from itertools import combinations as Cb\n",
    "from sklearn.tree import ExtraTreeClassifier as ex_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "def normalization(training_numpy, testing_numpy):\n",
    "    min_max = preprocessing.MinMaxScaler()\n",
    "    min_max.fit(training_numpy)\n",
    "    x_scaled = min_max.fit_transform(training_numpy)\n",
    "    testing_x_scaled = min_max.transform(testing_numpy)\n",
    "    #training_norm = pd.DataFrame(x_scaled, columns = columns)\n",
    "    #testing_norm = pd.DataFrame(testting_x_scaled, columns = columns)\n",
    "    return (x_scaled, testing_x_scaled)\n",
    "\n",
    "def pca_function(rate, data):\n",
    "    pca = PCA()\n",
    "    pca.fit(data)\n",
    "    for thres_n in xrange(1,len(data)):\n",
    "        if sum(pca.explained_variance_ratio_[:thres_n])>rate:\n",
    "            pca_n = thres_n\n",
    "            break\n",
    "    \n",
    "    pca = PCA(n_components=pca_n)\n",
    "    pca_data = pca.fit_transform(data)\n",
    "    return (pca_data, pca)\n",
    "\n",
    "def lda_whole_function(X, y, n_cluster=2):\n",
    "    \n",
    "    original_y = y.copy()\n",
    "    anomaly_index = []\n",
    "    \n",
    "    \n",
    "    for uni_label in np.unique(y):\n",
    "        anomaly_index.append(np.where(y == uni_label)[0])\n",
    "\n",
    "    #km_anomaly = KMeans(n_clusters=n_cluster)\n",
    "    km_anomaly_model = []\n",
    "    anomaly_label = []\n",
    "    for i in range(len(anomaly_index)):\n",
    "        km_anomaly = KMeans(n_clusters=n_cluster)\n",
    "        km_anomaly_model.append(km_anomaly.fit(X.iloc[anomaly_index[i]], y[anomaly_index[i]]))\n",
    "        anomaly_label.append(km_anomaly.labels_)\n",
    "        \n",
    "    #print len(anomaly_label),np.unique(anomaly_label[0])\n",
    "    for i in range(len(anomaly_index)):\n",
    "        km_uni_len = len(np.unique(anomaly_label[i]))\n",
    "        for (j,now_label) in zip(range(n_cluster*(i+1), n_cluster*(i+1)-n_cluster, -1), range(n_cluster-1,-1,-1)):\n",
    "            #print \"i\",i,\"j:\",j, \"now_label:\", now_label\n",
    "            anomaly_label[i][np.where(anomaly_label[i] == now_label)[0]] = j\n",
    "        y[anomaly_index[i]] = anomaly_label[i]\n",
    "    #print np.unique(y)\n",
    "    #print len(np.where(normal_label == 0)[0]),len(np.where(normal_label == 1)[0]), len(np.where(anomaly_label == 2)[0]), len(np.where(anomaly_label == 3)[0])\n",
    "    #print np.unique(y)\n",
    "    #return (X,y)\n",
    "    #print np.unique(y)\n",
    "    #print lda.n_components\n",
    "    try:\n",
    "        lda = LDA()\n",
    "        lda_data = lda.fit_transform(X, y)\n",
    "    except ValueError:\n",
    "        lda = LDA()\n",
    "        lda_data = lda.fit_transform(X, original_y)\n",
    "    except LinAlgError:\n",
    "        lda = LDA()\n",
    "        lda_data = lda.fit_transform(X, original_y)\n",
    "        \n",
    "    #print lda_data.shape\n",
    "    return (lda_data, lda)\n",
    "\n",
    "\n",
    "def lda_function(X, y, n_cluster=2):\n",
    "    \n",
    "    original_y = y.copy()\n",
    "    anomaly_index = []\n",
    "    \n",
    "    \n",
    "    for uni_label in np.unique(y):\n",
    "        anomaly_index.append(np.where(y == uni_label)[0])\n",
    "\n",
    "    #km_anomaly = KMeans(n_clusters=n_cluster)\n",
    "    km_anomaly_model = []\n",
    "    anomaly_label = []\n",
    "    for i in range(len(anomaly_index)):\n",
    "        km_anomaly = KMeans(n_clusters=n_cluster)\n",
    "        km_anomaly_model.append(km_anomaly.fit(X.iloc[anomaly_index[i]], y[anomaly_index[i]]))\n",
    "        anomaly_label.append(km_anomaly.labels_)\n",
    "        \n",
    "    #print len(anomaly_label),np.unique(anomaly_label[0])\n",
    "    for i in range(len(anomaly_index)):\n",
    "        km_uni_len = len(np.unique(anomaly_label[i]))\n",
    "        for (j,now_label) in zip(range(n_cluster*(i+1), n_cluster*(i+1)-n_cluster, -1), range(n_cluster-1,-1,-1)):\n",
    "            #print \"i\",i,\"j:\",j, \"now_label:\", now_label\n",
    "            anomaly_label[i][np.where(anomaly_label[i] == now_label)[0]] = j\n",
    "        y[anomaly_index[i]] = anomaly_label[i]\n",
    "    #print np.unique(y)\n",
    "    #print len(np.where(normal_label == 0)[0]),len(np.where(normal_label == 1)[0]), len(np.where(anomaly_label == 2)[0]), len(np.where(anomaly_label == 3)[0])\n",
    "    #print np.unique(y)\n",
    "    #return (X,y)\n",
    "    #print np.unique(y)\n",
    "    \n",
    "    #print lda.n_components\n",
    "    try:\n",
    "        lda = LDA()\n",
    "        lda_data = lda.fit_transform(X, y)\n",
    "    except ValueError:\n",
    "        lda = LDA()\n",
    "        lda_data = lda.fit_transform(X, original_y)\n",
    "    except LinAlgError:\n",
    "        lda = LDA()\n",
    "        lda_data = lda.fit_transform(X, original_y)\n",
    "        \n",
    "    #print lda_data.shape\n",
    "    return (lda_data, lda)\n",
    "\n",
    "\n",
    "'''\n",
    "def pca_function(n, data):\n",
    "    pca = PCA(n_components=n)\n",
    "    pca_data = pca.fit_transform(data)\n",
    "    return (pca_data.flatten(), pca)\n",
    "\n",
    "def lda_function(X, y):\n",
    "    lda = LDA()\n",
    "    lda_data = lda.fit_transform(X, y)\n",
    "    return (lda_data.flatten(), lda)\n",
    "'''\n",
    "def replace_value(training_normal_numpy, key, loc):  \n",
    "    training_normal_numpy[loc][key] = 1\n",
    "    \n",
    "def del_zero_column(df_train, df_test):\n",
    "    new_df_test = pd.DataFrame(np.zeros([df_test.shape[0], df_train.shape[1]]),columns=df_train.columns)\n",
    "    new_df_test[list(set(df_train.columns) & set(df_test.columns))] = df_test[list(set(df_train.columns) & set(df_test.columns))]\n",
    "    #df_test = df_test[df_train.columns]\n",
    "    return (df_train, new_df_test)\n",
    "\n",
    "def combine_function(x):\n",
    "    new_x = ''\n",
    "    for i in range(len(x)):\n",
    "        new_x = new_x + str(x[i]) +'_'\n",
    "    return new_x[:-1]\n",
    "#def del_zero_column(df_train, df_test):\n",
    "#    df_train = df_train.loc[:, (df_train != 0).any(axis=0)]\n",
    "#    df_test = df_test[df_train.columns]\n",
    "#    return (df_train, df_test)\n",
    "\n",
    "def combine_function(x):\n",
    "    new_x = ''\n",
    "    for i in range(len(x)):\n",
    "        new_x = new_x + str(x[i]) +'_'\n",
    "    return new_x[:-1]\n",
    "\n",
    "def all_lda(train_combine, label_num, n_cluster = 2):\n",
    "    train_all_dummy = pd.get_dummies(train_combine)\n",
    "    #train_all_dummy = category_encoders.OneHotEncoder(cols=train_combine.columns.tolist()).fit_transform(train_combine)\n",
    "    (train_lda, lda) = lda_whole_function(train_all_dummy, np.array(label_num), n_cluster=n_cluster)\n",
    "    clf=BernoulliNB()\n",
    "    start = time.time()\n",
    "    \n",
    "    score = np.average(cross_val_score(clf, train_lda, label_num, cv=10))\n",
    "    return (score , time.time()-start)\n",
    "\n",
    "def divide_lda(train_combine, label_num, n_cluster = 2):\n",
    "    train_column= train_combine.columns\n",
    "    for col in train_combine.columns:\n",
    "        train_dummy.append(pd.get_dummies(train_combine[col]))\n",
    "        #train_dummy.append(category_encoders.OneHotEncoder(cols=[col]).fit_transform(train_combine[[col]]))\n",
    "    train_lda = pd.DataFrame(index=range(len(label_num)))\n",
    "    for i in range(len(train_combine.columns)):\n",
    "        #print train_dummy[i].shape\n",
    "        (now_train_lda, lda) = lda_whole_function(train_dummy[i], np.array(label_num), n_cluster=3)\n",
    "        now_lda_col_name = []\n",
    "        for j in range(len(now_train_lda[0])):\n",
    "            train_lda[train_column[i]+'_'+str(j+1)] = np.array(now_train_lda)[:,j]\n",
    "    start = time.time()\n",
    "    score = np.average(cross_val_score(clf, train_lda, label_num, cv=10))\n",
    "    return (score, time.time()-start)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do not run yet\n",
    "train=pd.read_csv('splice.data.txt', header=None)\n",
    "train.columns=['label', 'name', 'dna']\n",
    "key_str = {}\n",
    "for (i,label_name) in zip(range(len(np.unique(train['label']))), np.unique(train['label'])):\n",
    "    key_str[label_name] = i\n",
    "    \n",
    "label_num = []\n",
    "map(lambda label: map(lambda key: label_num.append(key_str[key]) if key == label else None,key_str.keys()), train['label'])\n",
    "train_dummy = []\n",
    "    \n",
    "train['dna'] = train['dna'].map(lambda x: list(str(x).strip()))\n",
    "for idx in xrange(60):\n",
    "    train['dna_%d'% (idx,)] = train['dna'].map(lambda x: x[idx])\n",
    "\n",
    "train_column = train.columns[3:]\n",
    "train = train[train_column]\n",
    "\n",
    "result = pd.DataFrame(columns=['combine_num','score', 'time'])\n",
    "\n",
    "\n",
    "\n",
    "total_score = []\n",
    "total_time = []\n",
    "clf = SVC(kernel='linear', C=1.0)\n",
    "\n",
    "skf = StratifiedKFold(np.array(label_num), n_folds=10)\n",
    "val_label = np.array(label_num)\n",
    "\n",
    "exp_num =0\n",
    "for combine_num in range(3,5):\n",
    "    \n",
    "    train_combine = pd.DataFrame(index=range(len(train)))\n",
    "    com_index = 0\n",
    "    for sub in Cb(train.columns,combine_num):\n",
    "        combine_list = []\n",
    "        map(lambda data: combine_list.append(combine_function(data)),train[list(sub)].values)\n",
    "        train_combine['combine_%d' % com_index] = combine_list\n",
    "        com_index = com_index + 1\n",
    "    #print \"combine_subset:\", com_index\n",
    "    train_dummy = pd.get_dummies(train_combine)\n",
    "\n",
    "    for iteration in range(1):\n",
    "        val_time = []\n",
    "        now_score = []\n",
    "        for train_val_index, test_val_index in skf:    \n",
    "            lda = LDA()\n",
    "            try:    \n",
    "                train_lda = lda.fit_transform(train_dummy.iloc[train_val_index], val_label[train_val_index])\n",
    "                test_lda = lda.transform(train_dummy.iloc[test_val_index])\n",
    "                (train_lda, test_lda) = normalization(train_lda, test_lda)\n",
    "                clf.fit(train_lda, val_label[train_val_index])\n",
    "\n",
    "                start = time.time()\n",
    "                now_score.append(accuracy_score(clf.predict(test_lda), val_label[test_val_index]))\n",
    "                val_time.append(time.time() - start)     \n",
    "            except LinAlgError:\n",
    "                None\n",
    "        exe_time = np.sum(val_time)\n",
    "        total_score.append(np.average(now_score))\n",
    "        total_time.append(exe_time)\n",
    "            \n",
    "    print \"combine_num\", combine_num\n",
    "    print \"score:\", np.average(total_score)\n",
    "    print \"time:\", np.average(total_time)\n",
    "    result.loc[exp_num] = [combine_num, np.average(total_score), np.average(total_time)]\n",
    "    exp_num = exp_num + 1\n",
    "    result.to_csv('dna_combine_lda_normal(3-4).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_selection(train_dummy, label):\n",
    "    columns = train_dummy.columns\n",
    "    feature_dic = {}\n",
    "    new_column = []\n",
    "    initial = 1\n",
    "    whole_train_dummy = pd.DataFrame()\n",
    "    for column, idx in zip(columns, range(len(columns))):     \n",
    "        now_column = []\n",
    "        each_train_dummy = pd.get_dummies(train_dummy[column])\n",
    "        \n",
    "        clf = ex_tree()\n",
    "        clf.fit(each_train_dummy, label)\n",
    "        \n",
    "        for key, value in zip(each_train_dummy.columns, clf.feature_importances_):\n",
    "            now_column.append(('combine%d_'+key) % idx)\n",
    "            new_column.append(('combine%d_'+key) % idx)\n",
    "            feature_dic[('combine%d_'+key) % idx] = value\n",
    "        each_train_dummy.columns = now_column\n",
    "        if initial == 1:\n",
    "            whole_train_dummy = whole_train_dummy.append(each_train_dummy)\n",
    "            initial = 0\n",
    "        else:\n",
    "            whole_train_dummy = whole_train_dummy.join(each_train_dummy)\n",
    "        \n",
    "    #print len(new_column)\n",
    "    sorted_dic = sorted(feature_dic.iteritems(), key=lambda (k,v): (v,k),reverse=True)\n",
    "    \n",
    "        \n",
    "    \n",
    "    return (sorted_dic, whole_train_dummy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_selection(train_dummy, label, test_dummy, threshold):\n",
    "    columns = train_dummy.columns\n",
    "    feature_dic = {}\n",
    "    new_column = []\n",
    "    initial = 1\n",
    "    whole_train_dummy = pd.DataFrame()\n",
    "    start = time.time()\n",
    "    for column, idx in zip(columns, range(len(columns))):\n",
    "    \n",
    "        now_column = []\n",
    "        each_train_dummy = pd.get_dummies(train_dummy[column])\n",
    "        \n",
    "        clf = ex_tree()\n",
    "        clf.fit(each_train_dummy, label)\n",
    "        \n",
    "        for key, value in zip(each_train_dummy.columns, clf.feature_importances_):\n",
    "            now_column.append(('combine%d_'+key) % idx)\n",
    "            new_column.append(('combine%d_'+key) % idx)\n",
    "            feature_dic[('combine%d_'+key) % idx] = value\n",
    "        each_train_dummy.columns = now_column\n",
    "        if initial == 1:\n",
    "            whole_train_dummy = whole_train_dummy.append(each_train_dummy)\n",
    "            initial = 0\n",
    "        else:\n",
    "            whole_train_dummy = whole_train_dummy.join(each_train_dummy)\n",
    "    print \"Information gain process time:\", time.time()-start\n",
    "    start = time.time()\n",
    "    #print len(new_column)\n",
    "    sorted_dic = sorted(feature_dic.iteritems(), key=lambda (k,v): (v,k),reverse=True)\n",
    "    sorted_feature = [i[0] for i in sorted_dic][:threshold]\n",
    "        \n",
    "    new_train_dummy = whole_train_dummy[sorted_feature]\n",
    "    new_test_dummy = pd.DataFrame(np.zeros([test_dummy.shape[0], len(sorted_feature)]),columns=sorted_feature, index=test_dummy.index)\n",
    "    test_dummy = pd.get_dummies(test_dummy)\n",
    "    \n",
    "    cross_column = list(set(sorted_feature) & set(test_dummy.columns))\n",
    "    new_test_dummy[cross_column] = test_dummy[cross_column]\n",
    "    print \"Feature selection process time:\", time.time()-start\n",
    "    #print sorted_dic\n",
    "    return (new_train_dummy, new_test_dummy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do not run yet\n",
    "train=pd.read_csv('splice.data.txt', header=None)\n",
    "train.columns=['label', 'name', 'dna']\n",
    "key_str = {}\n",
    "for (i,label_name) in zip(range(len(np.unique(train['label']))), np.unique(train['label'])):\n",
    "    key_str[label_name] = i\n",
    "    \n",
    "label_num = []\n",
    "map(lambda label: map(lambda key: label_num.append(key_str[key]) if key == label else None,key_str.keys()), train['label'])\n",
    "train_dummy = []\n",
    "    \n",
    "train['dna'] = train['dna'].map(lambda x: list(str(x).strip()))\n",
    "for idx in xrange(60):\n",
    "    train['dna_%d'% (idx,)] = train['dna'].map(lambda x: x[idx])\n",
    "\n",
    "train_column = train.columns[3:]\n",
    "train = train[train_column]\n",
    "\n",
    "result = pd.DataFrame(columns=['combine_num','c_cluster','score', 'time'])\n",
    "\n",
    "\n",
    "\n",
    "total_score = []\n",
    "total_time = []\n",
    "clf = SVC(kernel='linear', C=1.0)\n",
    "#clf = BernoulliNB()\n",
    "\n",
    "skf = StratifiedKFold(np.array(label_num), n_folds=10)\n",
    "val_label = np.array(label_num)\n",
    "\n",
    "exp_num = 0\n",
    "for combine_num in range(2,4):\n",
    "    \n",
    "    train_combine = pd.DataFrame(index=range(len(train)))\n",
    "    com_index = 0\n",
    "    for sub in Cb(train.columns,combine_num):\n",
    "        combine_list = []\n",
    "        map(lambda data: combine_list.append(combine_function(data)),train[list(sub)].values)\n",
    "        train_combine['combine%d' % com_index] = combine_list\n",
    "        com_index = com_index + 1\n",
    "    print \"combine_subset:\", com_index\n",
    "    #train_dummy_top = combine_selection(train_dummy)\n",
    "    #train_dummy = pd.get_dummies(train_combine)\n",
    "    total_score = []\n",
    "    total_time = []\n",
    "    (sorted_dic, whole_train_dummy) = combine_selection(train_combine.iloc[train_val_index],val_label[train_val_index])\n",
    "    test_dummy = pd.get_dummies(train_combine.iloc[test_val_index])\n",
    "    for threshold in xrange(100,520,20):\n",
    "        print \"top: \", threshold\n",
    "        val_time = []\n",
    "        now_score = []\n",
    "        for train_val_index, test_val_index in skf:    \n",
    "\n",
    "            lda = LDA()\n",
    "            sorted_feature = [i[0] for i in sorted_dic][:threshold]\n",
    "            train_dummy_top = whole_train_dummy[sorted_feature]\n",
    "            test_dummy_top = pd.DataFrame(np.zeros([test_dummy.shape[0], len(sorted_feature)]),columns=sorted_feature, index=test_dummy.index)\n",
    "            \n",
    "\n",
    "            cross_column = list(set(sorted_feature) & set(test_dummy.columns))\n",
    "            test_dummy[cross_column] = test_dummy[cross_column]\n",
    "            #print sorted_dic\n",
    "            try: \n",
    "                train_lda = lda.fit_transform(train_dummy_top, val_label[train_val_index])        \n",
    "                clf.fit(train_lda, val_label[train_val_index])\n",
    "                test_lda = lda.transform(test_dummy_top)\n",
    "                start = time.time()\n",
    "                now_score.append(accuracy_score(clf.predict(test_lda), val_label[test_val_index]))\n",
    "                val_time.append(time.time() - start)   \n",
    "            \n",
    "            except LinAlgError:\n",
    "                None\n",
    "        exe_time = np.sum(val_time)\n",
    "        #total_score.append(np.average(now_score))\n",
    "        #total_time.append(exe_time)\n",
    "\n",
    "        print \"combine_num\", combine_num\n",
    "        print \"score:\", np.average(now_score)\n",
    "        print \"time:\", exe_time\n",
    "        result.loc[exp_num] = [combine_num, threshold, np.average(now_score), exe_time]\n",
    "        exp_num = exp_num + 1\n",
    "        result.to_csv('dna_combine_lda_normal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combine_subset: 1770\n",
      "top:  100\n",
      "cv: 1\n",
      "Information gain process time: 427.385839939\n",
      "Feature selection process time: 3.09240698814\n",
      "cv: 2\n",
      "Information gain process time: 429.710958958\n",
      "Feature selection process time: 3.23030805588\n",
      "cv: 3\n",
      "Information gain process time: 425.141069889\n",
      "Feature selection process time: 2.90448904037\n",
      "cv: 4\n",
      "Information gain process time: 437.889420986\n",
      "Feature selection process time: 2.99455285072\n",
      "cv: 5\n",
      "Information gain process time: 425.141784191\n",
      "Feature selection process time: 2.9996650219\n",
      "cv: 6\n",
      "Information gain process time: 429.429824114\n",
      "Feature selection process time: 3.00812411308\n",
      "cv: 7\n",
      "Information gain process time: 423.960889101\n",
      "Feature selection process time: 2.91519188881\n",
      "cv: 8\n",
      "Information gain process time: 431.128167152\n",
      "Feature selection process time: 3.12298321724\n",
      "cv: 9\n",
      "Information gain process time: 433.847805977\n",
      "Feature selection process time: 3.17117619514\n",
      "cv: 10\n",
      "Information gain process time: 425.238775969\n",
      "Feature selection process time: 3.08852696419\n",
      "combine_num 2\n",
      "score: 0.946392314621\n",
      "time: 0.0232193470001\n",
      "top:  120\n",
      "cv: 1\n",
      "Information gain process time: 423.464564085\n",
      "Feature selection process time: 2.89751315117\n",
      "cv: 2\n",
      "Information gain process time: 414.211228848\n",
      "Feature selection process time: 2.95745301247\n",
      "cv: 3\n",
      "Information gain process time: 425.597709894\n",
      "Feature selection process time: 2.91266918182\n",
      "cv: 4\n",
      "Information gain process time: 425.263874054\n",
      "Feature selection process time: 2.90916490555\n",
      "cv: 5\n",
      "Information gain process time: 426.533177853\n",
      "Feature selection process time: 2.98069500923\n",
      "cv: 6\n",
      "Information gain process time: 428.13015604\n",
      "Feature selection process time: 2.98733496666\n",
      "cv: 7\n",
      "Information gain process time: 420.967886209\n",
      "Feature selection process time: 2.91283011436\n",
      "cv: 8\n",
      "Information gain process time: 424.523881912\n",
      "Feature selection process time: 2.99516701698\n",
      "cv: 9\n",
      "Information gain process time: 422.273360968\n",
      "Feature selection process time: 2.89085793495\n",
      "cv: 10\n",
      "Information gain process time: 424.624168873\n",
      "Feature selection process time: 2.97792100906\n",
      "combine_num 2\n",
      "score: 0.947649227613\n",
      "time: 0.0220139026642\n",
      "top:  140\n",
      "cv: 1\n",
      "Information gain process time: 426.361783981\n",
      "Feature selection process time: 2.99697804451\n",
      "cv: 2\n",
      "Information gain process time: 413.643522978\n",
      "Feature selection process time: 3.09326481819\n",
      "cv: 3\n",
      "Information gain process time: 425.738787889\n",
      "Feature selection process time: 3.02865600586\n",
      "cv: 4\n",
      "Information gain process time: 426.635948896\n",
      "Feature selection process time: 2.89096689224\n",
      "cv: 5\n",
      "Information gain process time: 426.518939972\n",
      "Feature selection process time: 2.99063396454\n",
      "cv: 6\n",
      "Information gain process time: 425.227582216\n",
      "Feature selection process time: 3.08453512192\n",
      "cv: 7\n",
      "Information gain process time: 423.906903028\n",
      "Feature selection process time: 2.90579104424\n",
      "cv: 8\n",
      "Information gain process time: 423.19712019\n",
      "Feature selection process time: 3.15317106247\n",
      "cv: 9\n",
      "Information gain process time: 419.605265856\n",
      "Feature selection process time: 2.87053894997\n",
      "cv: 10\n",
      "Information gain process time: 420.267874956\n",
      "Feature selection process time: 3.04628205299\n",
      "combine_num 2\n",
      "score: 0.946100528778\n",
      "time: 0.0204112529755\n",
      "top:  160\n",
      "cv: 1\n",
      "Information gain process time: 424.183174133\n",
      "Feature selection process time: 2.88078999519\n",
      "cv: 2\n",
      "Information gain process time: 411.307327032\n",
      "Feature selection process time: 2.85157108307\n",
      "cv: 3\n",
      "Information gain process time: 423.916194916\n",
      "Feature selection process time: 2.88921403885\n",
      "cv: 4\n",
      "Information gain process time: 424.253923178\n",
      "Feature selection process time: 3.23357415199\n",
      "cv: 5\n",
      "Information gain process time: 422.041928053\n",
      "Feature selection process time: 2.91631388664\n",
      "cv: 6\n",
      "Information gain process time: 420.980772018\n",
      "Feature selection process time: 2.89157295227\n",
      "cv: 7\n",
      "Information gain process time: 416.921830893\n",
      "Feature selection process time: 2.86581110954\n",
      "cv: 8\n",
      "Information gain process time: 420.374825001\n",
      "Feature selection process time: 3.02711009979\n",
      "cv: 9\n",
      "Information gain process time: 421.110864878\n",
      "Feature selection process time: 2.85923790932\n",
      "cv: 10\n",
      "Information gain process time: 422.562513828\n",
      "Feature selection process time: 2.9785399437\n",
      "combine_num 2\n",
      "score: 0.945461758536\n",
      "time: 0.020092010498\n",
      "top:  180\n",
      "cv: 1\n",
      "Information gain process time: 419.166825056\n",
      "Feature selection process time: 2.88962101936\n",
      "cv: 2\n",
      "Information gain process time: 414.202547073\n",
      "Feature selection process time: 2.98486280441\n",
      "cv: 3\n",
      "Information gain process time: 424.552373886\n",
      "Feature selection process time: 3.07872390747\n",
      "cv: 4\n",
      "Information gain process time: 422.439427137\n",
      "Feature selection process time: 3.01856017113\n",
      "cv: 5\n",
      "Information gain process time: 424.142935991\n",
      "Feature selection process time: 2.92721819878\n",
      "cv: 6\n",
      "Information gain process time: 420.871865034\n",
      "Feature selection process time: 3.31952404976\n",
      "cv: 7\n",
      "Information gain process time: 421.914216995\n",
      "Feature selection process time: 3.02002191544\n",
      "cv: 8\n",
      "Information gain process time: 422.259090185\n",
      "Feature selection process time: 3.06120204926\n",
      "cv: 9\n",
      "Information gain process time: 428.296875954\n",
      "Feature selection process time: 2.94215083122\n",
      "cv: 10\n",
      "Information gain process time: 427.077940941\n",
      "Feature selection process time: 3.02449703217\n",
      "combine_num 2\n",
      "score: 0.949217599195\n",
      "time: 0.0236701965332\n",
      "top:  200\n",
      "cv: 1\n",
      "Information gain process time: 427.880791903\n",
      "Feature selection process time: 2.92094802856\n",
      "cv: 2\n",
      "Information gain process time: 410.557544947\n",
      "Feature selection process time: 3.04126811028\n",
      "cv: 3\n",
      "Information gain process time: 421.93958497\n",
      "Feature selection process time: 2.9839091301\n",
      "cv: 4\n",
      "Information gain process time: 422.630839109\n",
      "Feature selection process time: 3.03058099747\n",
      "cv: 5\n",
      "Information gain process time: 420.540880919\n",
      "Feature selection process time: 3.10279798508\n",
      "cv: 6\n",
      "Information gain process time: 423.935642958\n",
      "Feature selection process time: 3.27970290184\n",
      "cv: 7\n",
      "Information gain process time: 417.12498498\n",
      "Feature selection process time: 3.09348392487\n",
      "cv: 8\n",
      "Information gain process time: 426.803715944\n",
      "Feature selection process time: 3.17767214775\n",
      "cv: 9\n",
      "Information gain process time: 421.644451857\n",
      "Feature selection process time: 2.95008802414\n",
      "cv: 10\n",
      "Information gain process time: 421.822178125\n",
      "Feature selection process time: 3.00171709061\n",
      "combine_num 2\n",
      "score: 0.951103436727\n",
      "time: 0.018830537796\n",
      "top:  220\n",
      "cv: 1\n",
      "Information gain process time: 427.988713026\n",
      "Feature selection process time: 2.9236779213\n",
      "cv: 2\n",
      "Information gain process time: 413.991653204\n",
      "Feature selection process time: 2.87631082535\n",
      "cv: 3\n",
      "Information gain process time: 424.394201994\n",
      "Feature selection process time: 3.28015089035\n",
      "cv: 4\n",
      "Information gain process time: 425.745435953\n",
      "Feature selection process time: 2.94381690025\n",
      "cv: 5\n",
      "Information gain process time: 424.938010216\n",
      "Feature selection process time: 3.03248310089\n",
      "cv: 6\n",
      "Information gain process time: 423.477465153\n",
      "Feature selection process time: 3.0328400135\n",
      "cv: 7\n",
      "Information gain process time: 418.40723896\n",
      "Feature selection process time: 3.08601808548\n",
      "cv: 8\n",
      "Information gain process time: 429.840862989\n",
      "Feature selection process time: 3.30760908127\n",
      "cv: 9\n",
      "Information gain process time: 420.513160944\n",
      "Feature selection process time: 2.89013600349\n",
      "cv: 10\n",
      "Information gain process time: 420.966769934\n",
      "Feature selection process time: 3.01444101334\n",
      "combine_num 2\n",
      "score: 0.952353418244\n",
      "time: 0.0183296203613\n",
      "top:  240\n",
      "cv: 1\n",
      "Information gain process time: 422.058082104\n",
      "Feature selection process time: 2.92587399483\n",
      "cv: 2\n",
      "Information gain process time: 409.627449036\n",
      "Feature selection process time: 2.86400699615\n",
      "cv: 3\n",
      "Information gain process time: 420.523381948\n",
      "Feature selection process time: 3.05295205116\n",
      "cv: 4\n",
      "Information gain process time: 421.317708969\n",
      "Feature selection process time: 2.93503189087\n",
      "cv: 5\n",
      "Information gain process time: 421.481317997\n",
      "Feature selection process time: 3.10454916954\n",
      "cv: 6\n",
      "Information gain process time: 419.181719065\n",
      "Feature selection process time: 2.98221087456\n",
      "cv: 7\n",
      "Information gain process time: 415.548747063\n",
      "Feature selection process time: 2.89209508896\n",
      "cv: 8\n",
      "Information gain process time: 419.068427086\n",
      "Feature selection process time: 2.98835802078\n",
      "cv: 9\n",
      "Information gain process time: 417.910377026\n",
      "Feature selection process time: 2.98840618134\n",
      "cv: 10\n",
      "Information gain process time: 420.140675068\n",
      "Feature selection process time: 3.01685094833\n",
      "combine_num 2\n",
      "score: 0.956423829401\n",
      "time: 0.0178978443146\n",
      "top:  260\n",
      "cv: 1\n",
      "Information gain process time: 422.253339052\n",
      "Feature selection process time: 3.06856203079\n",
      "cv: 2\n",
      "Information gain process time: 412.122649908\n",
      "Feature selection process time: 2.96088409424\n",
      "cv: 3\n",
      "Information gain process time: 422.68239212\n",
      "Feature selection process time: 2.86828804016\n",
      "cv: 4\n",
      "Information gain process time: 421.692400932\n",
      "Feature selection process time: 2.91864705086\n",
      "cv: 5\n",
      "Information gain process time: 422.364856005\n",
      "Feature selection process time: 2.92904496193\n",
      "cv: 6\n",
      "Information gain process time: 418.642743111\n",
      "Feature selection process time: 2.93780493736\n",
      "cv: 7\n",
      "Information gain process time: 416.97320509\n",
      "Feature selection process time: 3.03840208054\n",
      "cv: 8\n",
      "Information gain process time: 423.709387064\n",
      "Feature selection process time: 3.037525177\n",
      "cv: 9\n",
      "Information gain process time: 423.242032051\n",
      "Feature selection process time: 3.2066321373\n",
      "cv: 10\n",
      "Information gain process time: 429.938471079\n",
      "Feature selection process time: 3.05988812447\n",
      "combine_num 2\n",
      "score: 0.951420878208\n",
      "time: 0.0267400741577\n",
      "top:  280\n",
      "cv: 1\n",
      "Information gain process time: 430.412353992\n",
      "Feature selection process time: 3.03826284409\n",
      "cv: 2\n",
      "Information gain process time: 414.878576994\n",
      "Feature selection process time: 2.89415597916\n",
      "cv: 3\n",
      "Information gain process time: 423.233588934\n",
      "Feature selection process time: 2.93235111237\n",
      "cv: 4\n",
      "Information gain process time: 420.647938013\n",
      "Feature selection process time: 2.98031401634\n",
      "cv: 5\n",
      "Information gain process time: 422.939064026\n",
      "Feature selection process time: 2.96815013885\n",
      "cv: 6\n",
      "Information gain process time: 422.376585007\n",
      "Feature selection process time: 2.99512004852\n",
      "cv: 7\n",
      "Information gain process time: 413.127491951\n",
      "Feature selection process time: 3.08935809135\n",
      "cv: 8\n",
      "Information gain process time: 407.888878822\n",
      "Feature selection process time: 2.62525582314\n",
      "cv: 9\n",
      "Information gain process time: 403.616276979\n",
      "Feature selection process time: 3.0066409111\n",
      "cv: 10\n",
      "Information gain process time: 413.514271975\n",
      "Feature selection process time: 2.99711203575\n",
      "combine_num 2\n",
      "score: 0.952040006684\n",
      "time: 0.0170402526855\n",
      "top:  300\n",
      "cv: 1\n",
      "Information gain process time: 424.652635098\n",
      "Feature selection process time: 3.22539782524\n",
      "cv: 2\n",
      "Information gain process time: 410.678375959\n",
      "Feature selection process time: 2.94816398621\n",
      "cv: 3\n",
      "Information gain process time: 421.414921999\n",
      "Feature selection process time: 2.91871500015\n",
      "cv: 4\n",
      "Information gain process time: 421.779355049\n",
      "Feature selection process time: 3.05871200562\n",
      "cv: 5\n",
      "Information gain process time: 422.07926321\n",
      "Feature selection process time: 3.0364408493\n",
      "cv: 6\n",
      "Information gain process time: 420.804923058\n",
      "Feature selection process time: 3.071570158\n",
      "cv: 7\n",
      "Information gain process time: 415.414608955\n",
      "Feature selection process time: 2.96779108047\n",
      "cv: 8\n",
      "Information gain process time: 421.180063963\n",
      "Feature selection process time: 3.08658099174\n",
      "cv: 9\n",
      "Information gain process time: 418.892297029\n",
      "Feature selection process time: 3.071570158\n",
      "cv: 10\n",
      "Information gain process time: 420.002603054\n",
      "Feature selection process time: 2.99449110031\n",
      "combine_num 2\n",
      "score: 0.952341631894\n",
      "time: 0.0174210071564\n",
      "top:  320\n",
      "cv: 1\n",
      "Information gain process time: 420.955844879\n",
      "Feature selection process time: 3.04920101166\n",
      "cv: 2\n",
      "Information gain process time: 414.041204929\n",
      "Feature selection process time: 3.05740380287\n",
      "cv: 3\n",
      "Information gain process time: 420.541646957\n",
      "Feature selection process time: 3.0027718544\n",
      "cv: 4\n",
      "Information gain process time: 422.408849001\n",
      "Feature selection process time: 3.147149086\n",
      "cv: 5\n",
      "Information gain process time: 422.041931868\n",
      "Feature selection process time: 3.00900197029\n",
      "cv: 6\n",
      "Information gain process time: 423.097759008\n",
      "Feature selection process time: 3.12440991402\n",
      "cv: 7\n",
      "Information gain process time: 420.261399031\n",
      "Feature selection process time: 3.01212096214\n",
      "cv: 8\n",
      "Information gain process time: 423.236851931\n",
      "Feature selection process time: 3.26642584801\n",
      "cv: 9\n",
      "Information gain process time: 422.371551037\n",
      "Feature selection process time: 3.14714884758\n",
      "cv: 10\n",
      "Information gain process time: 424.552653074\n",
      "Feature selection process time: 3.04592585564\n",
      "combine_num 2\n",
      "score: 0.952970531789\n",
      "time: 0.0245320796967\n",
      "top:  340\n",
      "cv: 1\n",
      "Information gain process time: 427.550544977\n",
      "Feature selection process time: 3.24031615257\n",
      "cv: 2\n",
      "Information gain process time: 415.410094023\n",
      "Feature selection process time: 3.04433202744\n",
      "cv: 3\n",
      "Information gain process time: 424.158009052\n",
      "Feature selection process time: 3.02506089211\n",
      "cv: 4\n",
      "Information gain process time: 423.917110205\n",
      "Feature selection process time: 3.0339641571\n",
      "cv: 5\n",
      "Information gain process time: 424.988045931\n",
      "Feature selection process time: 3.20856308937\n",
      "cv: 6\n",
      "Information gain process time: 425.123295069\n",
      "Feature selection process time: 3.05113697052\n",
      "cv: 7\n",
      "Information gain process time: 419.196380854\n",
      "Feature selection process time: 3.09738707542\n",
      "cv: 8\n",
      "Information gain process time: 424.079612017\n",
      "Feature selection process time: 3.04505991936\n",
      "cv: 9\n",
      "Information gain process time: 423.251645803\n",
      "Feature selection process time: 3.18835496902\n",
      "cv: 10\n",
      "Information gain process time: 425.349445105\n",
      "Feature selection process time: 3.07868099213\n",
      "combine_num 2\n",
      "score: 0.955174784264\n",
      "time: 0.0271091461182\n",
      "top:  360\n",
      "cv: 1\n",
      "Information gain process time: 425.750077009\n",
      "Feature selection process time: 3.05062198639\n",
      "cv: 2\n",
      "Information gain process time: 413.444560051\n",
      "Feature selection process time: 3.00586509705\n",
      "cv: 3\n",
      "Information gain process time: 425.309412003\n",
      "Feature selection process time: 3.02159881592\n",
      "cv: 4\n",
      "Information gain process time: 423.518188\n",
      "Feature selection process time: 3.14635801315\n",
      "cv: 5\n",
      "Information gain process time: 426.318292856\n",
      "Feature selection process time: 3.23821401596\n",
      "cv: 6\n",
      "Information gain process time: 425.261609077\n",
      "Feature selection process time: 3.24810385704\n",
      "cv: 7\n",
      "Information gain process time: 420.890300989\n",
      "Feature selection process time: 3.10062289238\n",
      "cv: 8\n",
      "Information gain process time: 426.433133125\n",
      "Feature selection process time: 3.16842794418\n",
      "cv: 9\n",
      "Information gain process time: 423.473896027\n",
      "Feature selection process time: 3.11532402039\n",
      "cv: 10\n",
      "Information gain process time: 422.67352891\n",
      "Feature selection process time: 3.02296304703\n",
      "combine_num 2\n",
      "score: 0.953924815128\n",
      "time: 0.0249140262604\n",
      "top:  380\n",
      "cv: 1\n",
      "Information gain process time: 427.052156925\n",
      "Feature selection process time: 3.15101695061\n",
      "cv: 2\n",
      "Information gain process time: 414.532325983\n",
      "Feature selection process time: 3.00580096245\n",
      "cv: 3\n",
      "Information gain process time: 423.81493187\n",
      "Feature selection process time: 3.1270160675\n",
      "cv: 4\n",
      "Information gain process time: 425.230006933\n",
      "Feature selection process time: 3.05440688133\n",
      "cv: 5\n",
      "Information gain process time: 424.706581116\n",
      "Feature selection process time: 3.11666107178\n",
      "cv: 6\n",
      "Information gain process time: 425.074469805\n",
      "Feature selection process time: 3.0536570549\n",
      "cv: 7\n",
      "Information gain process time: 419.469033003\n",
      "Feature selection process time: 3.14078903198\n",
      "cv: 8\n",
      "Information gain process time: 422.391102076\n",
      "Feature selection process time: 3.11546802521\n",
      "cv: 9\n",
      "Information gain process time: 423.156258106\n",
      "Feature selection process time: 3.16477108002\n",
      "cv: 10\n",
      "Information gain process time: 424.295495987\n",
      "Feature selection process time: 3.14331007004\n",
      "combine_num 2\n",
      "score: 0.951429775209\n",
      "time: 0.0170469284058\n",
      "top:  400\n",
      "cv: 1\n",
      "Information gain process time: 425.401116848\n",
      "Feature selection process time: 3.00908303261\n",
      "cv: 2\n",
      "Information gain process time: 413.439136028\n",
      "Feature selection process time: 2.98927998543\n",
      "cv: 3\n",
      "Information gain process time: 425.041561127\n",
      "Feature selection process time: 3.03600001335\n",
      "cv: 4\n",
      "Information gain process time: 424.954400063\n",
      "Feature selection process time: 3.25958609581\n",
      "cv: 5\n",
      "Information gain process time: 427.562430143\n",
      "Feature selection process time: 3.03686285019\n",
      "cv: 6\n",
      "Information gain process time: 425.450181961\n",
      "Feature selection process time: 3.06492495537\n",
      "cv: 7\n",
      "Information gain process time: 421.800345898\n",
      "Feature selection process time: 3.02913999557\n",
      "cv: 8\n",
      "Information gain process time: 424.80233407\n",
      "Feature selection process time: 3.17696404457\n",
      "cv: 9\n",
      "Information gain process time: 422.261548042\n",
      "Feature selection process time: 3.03214502335\n",
      "cv: 10\n",
      "Information gain process time: 423.618946075\n",
      "Feature selection process time: 3.02637314796\n",
      "combine_num 2\n",
      "score: 0.951096579477\n",
      "time: 0.0183362960815\n",
      "top:  420\n",
      "cv: 1\n",
      "Information gain process time: 425.96309495\n",
      "Feature selection process time: 3.06349802017\n",
      "cv: 2\n",
      "Information gain process time: 414.107388973\n",
      "Feature selection process time: 3.03992676735\n",
      "cv: 3\n",
      "Information gain process time: 425.666699886\n",
      "Feature selection process time: 3.10337090492\n",
      "cv: 4\n",
      "Information gain process time: 424.669194937\n",
      "Feature selection process time: 2.99034714699\n",
      "cv: 5\n",
      "Information gain process time: 423.01709199\n",
      "Feature selection process time: 3.27749896049\n",
      "cv: 6\n",
      "Information gain process time: 423.39509201\n",
      "Feature selection process time: 3.08183503151\n",
      "cv: 7\n",
      "Information gain process time: 420.381435156\n",
      "Feature selection process time: 3.07540011406\n",
      "cv: 8\n",
      "Information gain process time: 424.257330894\n",
      "Feature selection process time: 3.08820104599\n",
      "cv: 9\n",
      "Information gain process time: 424.007425785\n",
      "Feature selection process time: 3.06636500359\n",
      "cv: 10\n",
      "Information gain process time: 424.913020849\n",
      "Feature selection process time: 3.03808403015\n",
      "combine_num 2\n",
      "score: 0.949218622064\n",
      "time: 0.0165898799896\n",
      "top:  440\n",
      "cv: 1\n",
      "Information gain process time: 425.816850901\n",
      "Feature selection process time: 3.06039500237\n",
      "cv: 2\n",
      "Information gain process time: 416.414005995\n",
      "Feature selection process time: 3.17225503922\n",
      "cv: 3\n",
      "Information gain process time: 424.973400116\n",
      "Feature selection process time: 3.07504415512\n",
      "cv: 4\n",
      "Information gain process time: 425.407387972\n",
      "Feature selection process time: 3.02380895615\n",
      "cv: 5\n",
      "Information gain process time: 423.66238904\n",
      "Feature selection process time: 3.15711903572\n",
      "cv: 6\n",
      "Information gain process time: 424.091346979\n",
      "Feature selection process time: 3.21316599846\n",
      "cv: 7\n",
      "Information gain process time: 420.091786861\n",
      "Feature selection process time: 3.04876995087\n",
      "cv: 8\n",
      "Information gain process time: 423.834518194\n",
      "Feature selection process time: 3.14645791054\n",
      "cv: 9\n",
      "Information gain process time: 423.408696175\n",
      "Feature selection process time: 3.20093107224\n",
      "cv: 10\n",
      "Information gain process time: 424.577647924\n",
      "Feature selection process time: 3.09510087967\n",
      "combine_num 2\n",
      "score: 0.948281159147\n",
      "time: 0.0163161754608\n",
      "top:  460\n",
      "cv: 1\n",
      "Information gain process time: 424.712198973\n",
      "Feature selection process time: 3.01508688927\n",
      "cv: 2\n",
      "Information gain process time: 410.9731462\n",
      "Feature selection process time: 3.02921390533\n",
      "cv: 3\n",
      "Information gain process time: 422.223708153\n",
      "Feature selection process time: 3.05757689476\n",
      "cv: 4\n",
      "Information gain process time: 421.022381067\n",
      "Feature selection process time: 3.08913516998\n",
      "cv: 5\n",
      "Information gain process time: 420.977926016\n",
      "Feature selection process time: 3.17412209511\n",
      "cv: 6\n",
      "Information gain process time: 419.669092894\n",
      "Feature selection process time: 3.08140993118\n",
      "cv: 7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-185-c46c666cd2c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[1;32mprint\u001b[0m \u001b[1;34m\"cv:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m             \u001b[1;33m(\u001b[0m\u001b[0mtrain_dummy_top\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dummy_top\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcombine_selection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_combine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_val_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_val_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_combine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_val_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m             \u001b[0mlda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLDA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-184-08719fc51f30>\u001b[0m in \u001b[0;36mcombine_selection\u001b[1;34m(train_dummy, label, test_dummy, threshold)\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0minitial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mwhole_train_dummy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwhole_train_dummy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meach_train_dummy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Information gain process time:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[0;32m   4367\u001b[0m         \u001b[1;31m# For SparseDataFrame's benefit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4368\u001b[0m         return self._join_compat(other, on=on, how=how, lsuffix=lsuffix,\n\u001b[1;32m-> 4369\u001b[1;33m                                  rsuffix=rsuffix, sort=sort)\n\u001b[0m\u001b[0;32m   4370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4371\u001b[0m     def _join_compat(self, other, on=None, how='left', lsuffix='', rsuffix='',\n",
      "\u001b[1;32m/usr/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_join_compat\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[0;32m   4381\u001b[0m             return merge(self, other, left_on=on, how=how,\n\u001b[0;32m   4382\u001b[0m                          \u001b[0mleft_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4383\u001b[1;33m                          suffixes=(lsuffix, rsuffix), sort=sort)\n\u001b[0m\u001b[0;32m   4384\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4385\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mon\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/anaconda2/lib/python2.7/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator)\u001b[0m\n\u001b[0;32m     33\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m                          copy=copy, indicator=indicator)\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mmerge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_merge_doc\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;34m'\\nleft : DataFrame'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/anaconda2/lib/python2.7/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    218\u001b[0m             \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mldata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlindexers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrindexers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mllabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjoin_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m             concat_axis=0, copy=self.copy)\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[0mtyp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/anaconda2/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m   4472\u001b[0m                                                 copy=copy),\n\u001b[0;32m   4473\u001b[0m                          placement=placement)\n\u001b[1;32m-> 4474\u001b[1;33m               for placement, join_units in concat_plan]\n\u001b[0m\u001b[0;32m   4475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4476\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/anaconda2/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mconcatenate_join_units\u001b[1;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[0;32m   4565\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Concatenating join units along axis0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4567\u001b[1;33m     \u001b[0mempty_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupcasted_na\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_empty_dtype_and_na\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4569\u001b[0m     to_concat = [ju.get_reindexed_values(empty_dtype=empty_dtype,\n",
      "\u001b[1;32m/usr/anaconda2/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget_empty_dtype_and_na\u001b[1;34m(join_units)\u001b[0m\n\u001b[0;32m   4508\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4510\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_categorical_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4511\u001b[0m             \u001b[0mupcast_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'category'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4512\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_datetimetz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/anaconda2/lib/python2.7/site-packages/pandas/core/common.pyc\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[1;34m(arr_or_dtype)\u001b[0m\n\u001b[0;32m   2456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2457\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2458\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mCategoricalDtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/anaconda2/lib/python2.7/site-packages/pandas/core/dtypes.pyc\u001b[0m in \u001b[0;36mis_dtype\u001b[1;34m(cls, dtype)\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mwe\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mmatch\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mvia\u001b[0m \u001b[0mstring\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \"\"\"\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'dtype'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Do not run yet\n",
    "train=pd.read_csv('splice.data.txt', header=None)\n",
    "train.columns=['label', 'name', 'dna']\n",
    "key_str = {}\n",
    "for (i,label_name) in zip(range(len(np.unique(train['label']))), np.unique(train['label'])):\n",
    "    key_str[label_name] = i\n",
    "    \n",
    "label_num = []\n",
    "map(lambda label: map(lambda key: label_num.append(key_str[key]) if key == label else None,key_str.keys()), train['label'])\n",
    "train_dummy = []\n",
    "    \n",
    "train['dna'] = train['dna'].map(lambda x: list(str(x).strip()))\n",
    "for idx in xrange(60):\n",
    "    train['dna_%d'% (idx,)] = train['dna'].map(lambda x: x[idx])\n",
    "\n",
    "train_column = train.columns[3:]\n",
    "train = train[train_column]\n",
    "\n",
    "result = pd.DataFrame(columns=['combine_num','top','score', 'time'])\n",
    "\n",
    "\n",
    "total_score = []\n",
    "total_time = []\n",
    "clf = SVC(kernel='linear', C=1.0)\n",
    "#clf = BernoulliNB()\n",
    "\n",
    "skf = StratifiedKFold(np.array(label_num), n_folds=10)\n",
    "val_label = np.array(label_num)\n",
    "\n",
    "exp_num = 0\n",
    "for combine_num in range(2,4):\n",
    "    \n",
    "    train_combine = pd.DataFrame(index=range(len(train)))\n",
    "    com_index = 0\n",
    "    for sub in Cb(train.columns,combine_num):\n",
    "        combine_list = []\n",
    "        map(lambda data: combine_list.append(combine_function(data)),train[list(sub)].values)\n",
    "        train_combine['combine%d' % com_index] = combine_list\n",
    "        com_index = com_index + 1\n",
    "    print \"combine_subset:\", com_index\n",
    "    #train_dummy_top = combine_selection(train_dummy)\n",
    "    #train_dummy = pd.get_dummies(train_combine)\n",
    "    total_score = []\n",
    "    total_time = []\n",
    "    for threshold in xrange(100,520,20):\n",
    "        print \"top: \", threshold\n",
    "        val_time = []\n",
    "        now_score = []\n",
    "        cv= 0 \n",
    "        for train_val_index, test_val_index in skf:    \n",
    "            print \"cv:\", cv+1\n",
    "            cv = cv+1\n",
    "            (train_dummy_top, test_dummy_top) = combine_selection(train_combine.iloc[train_val_index],val_label[train_val_index], train_combine.iloc[test_val_index], threshold = threshold)\n",
    "            lda = LDA()\n",
    "            try: \n",
    "                train_lda = lda.fit_transform(train_dummy_top, val_label[train_val_index])        \n",
    "                clf.fit(train_lda, val_label[train_val_index])\n",
    "                test_lda = lda.transform(test_dummy_top)\n",
    "                start = time.time()\n",
    "                now_score.append(accuracy_score(clf.predict(test_lda), val_label[test_val_index]))\n",
    "                val_time.append(time.time() - start)   \n",
    "            \n",
    "            except LinAlgError:\n",
    "                None\n",
    "        exe_time = np.sum(val_time)\n",
    "        #total_score.append(np.average(now_score))\n",
    "        #total_time.append(exe_time)\n",
    "\n",
    "        print \"combine_num\", combine_num\n",
    "        print \"score:\", np.average(now_score)\n",
    "        print \"time:\", exe_time\n",
    "        result.loc[exp_num] = [combine_num, threshold, np.average(now_score), exe_time]\n",
    "\n",
    "        result.to_csv('dna_combine_lda_normal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-192-a20a2ae85c49>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mskf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "skf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 320\n",
      "1 320\n",
      "2 320\n",
      "3 320\n",
      "4 320\n",
      "5 319\n",
      "6 319\n",
      "7 318\n",
      "8 317\n",
      "9 317\n"
     ]
    }
   ],
   "source": [
    "for num,(_,b) in zip(range(10),skf):\n",
    "    print num, len(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mushroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combine_subset: 231\n",
      "top:  100\n",
      "combine_num 2\n",
      "score: 0.983243016154\n",
      "time: 0.0170269012451\n",
      "top:  120\n",
      "combine_num 2\n",
      "score: 0.931156166062\n",
      "time: 0.0170269012451\n",
      "top:  140\n",
      "combine_num 2\n",
      "score: 0.945170722977\n",
      "time: 0.0170269012451\n",
      "top:  160\n",
      "combine_num 2\n",
      "score: 0.930658094497\n",
      "time: 0.0170269012451\n",
      "top:  180\n",
      "combine_num 2\n",
      "score: 0.927955707424\n",
      "time: 0.0170269012451\n",
      "top:  200\n",
      "combine_num 2\n",
      "score: 0.927091665491\n",
      "time: 0.0170269012451\n",
      "top:  220\n",
      "combine_num 2\n",
      "score: 0.949515502553\n",
      "time: 0.0170269012451\n",
      "top:  240\n",
      "combine_num 2\n",
      "score: 0.934113352231\n",
      "time: 0.0170269012451\n",
      "top:  260\n",
      "combine_num 2\n",
      "score: 0.93029485412\n",
      "time: 0.0170269012451\n",
      "top:  280\n",
      "combine_num 2\n",
      "score: 0.946291383999\n",
      "time: 0.0170269012451\n",
      "top:  300\n",
      "combine_num 2\n",
      "score: 0.952114604993\n",
      "time: 0.0170269012451\n",
      "top:  320\n",
      "combine_num 2\n",
      "score: 0.941509502641\n",
      "time: 0.0170269012451\n",
      "top:  340\n",
      "combine_num 2\n",
      "score: 0.954775132215\n",
      "time: 0.0170269012451\n",
      "top:  360\n",
      "combine_num 2\n",
      "score: 0.944099201781\n",
      "time: 0.0170269012451\n",
      "top:  380\n",
      "combine_num 2\n",
      "score: 0.969794325563\n",
      "time: 0.0170269012451\n",
      "top:  400\n",
      "combine_num 2\n",
      "score: 0.943482072305\n",
      "time: 0.0170269012451\n",
      "top:  420\n",
      "combine_num 2\n",
      "score: 0.958124678657\n",
      "time: 0.0170269012451\n",
      "top:  440\n",
      "combine_num 2\n",
      "score: 0.943727468101\n",
      "time: 0.0170269012451\n",
      "top:  460\n",
      "combine_num 2\n",
      "score: 0.949761808346\n",
      "time: 0.0170269012451\n",
      "top:  480\n",
      "combine_num 2\n",
      "score: 0.955312333641\n",
      "time: 0.0170269012451\n",
      "top:  500\n",
      "combine_num 2\n",
      "score: 0.949400691294\n",
      "time: 0.0170269012451\n",
      "combine_subset: 1540\n",
      "top:  100\n",
      "combine_num 3\n",
      "score: 0.958171088493\n",
      "time: 0.0170269012451\n",
      "top:  120\n",
      "combine_num 3\n",
      "score: 0.997289119624\n",
      "time: 0.0170269012451\n",
      "top:  140\n",
      "combine_num 3\n",
      "score: 0.997289119624\n",
      "time: 0.0170269012451\n",
      "top:  160\n",
      "combine_num 3\n",
      "score: 0.997166118394\n",
      "time: 0.0170269012451\n",
      "top:  180\n",
      "combine_num 3\n",
      "score: 0.997043117164\n",
      "time: 0.0170269012451\n",
      "top:  200\n",
      "combine_num 3\n",
      "score: 0.974623830085\n",
      "time: 0.0170269012451\n",
      "top:  220\n",
      "combine_num 3\n",
      "score: 0.97120739888\n",
      "time: 0.0170269012451\n",
      "top:  240\n",
      "combine_num 3\n",
      "score: 0.972439079695\n",
      "time: 0.0170269012451\n",
      "top:  260\n",
      "combine_num 3\n",
      "score: 0.958913949189\n",
      "time: 0.0170269012451\n",
      "top:  280\n",
      "combine_num 3\n",
      "score: 0.948310060166\n",
      "time: 0.0170269012451\n",
      "top:  300\n",
      "combine_num 3\n",
      "score: 0.940378224991\n",
      "time: 0.0170269012451\n",
      "top:  320\n",
      "combine_num 3\n",
      "score: 0.983639623079\n",
      "time: 0.0170269012451\n",
      "top:  340\n",
      "combine_num 3\n",
      "score: 0.930047638331\n",
      "time: 0.0170269012451\n",
      "top:  360\n",
      "combine_num 3\n",
      "score: 0.942375971232\n",
      "time: 0.0170269012451\n",
      "top:  380\n",
      "combine_num 3\n",
      "score: 0.93201778171\n",
      "time: 0.0170269012451\n",
      "top:  400\n",
      "combine_num 3\n",
      "score: 0.954583426229\n",
      "time: 0.0170269012451\n",
      "top:  420\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-171-dce45fcb4da8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtrain_val_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_val_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mskf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m             \u001b[1;33m(\u001b[0m\u001b[0mtrain_dummy_top\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dummy_top\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcombine_selection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_combine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_val_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_val_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_combine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_val_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m             \u001b[0mlda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLDA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-170-016ab8dcb167>\u001b[0m in \u001b[0;36mcombine_selection\u001b[1;34m(train_dummy, label, test_dummy, threshold)\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0minitial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mwhole_train_dummy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwhole_train_dummy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meach_train_dummy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m#print len(new_column)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[0;32m   4367\u001b[0m         \u001b[1;31m# For SparseDataFrame's benefit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4368\u001b[0m         return self._join_compat(other, on=on, how=how, lsuffix=lsuffix,\n\u001b[1;32m-> 4369\u001b[1;33m                                  rsuffix=rsuffix, sort=sort)\n\u001b[0m\u001b[0;32m   4370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4371\u001b[0m     def _join_compat(self, other, on=None, how='left', lsuffix='', rsuffix='',\n",
      "\u001b[1;32m/usr/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_join_compat\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[0;32m   4381\u001b[0m             return merge(self, other, left_on=on, how=how,\n\u001b[0;32m   4382\u001b[0m                          \u001b[0mleft_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4383\u001b[1;33m                          suffixes=(lsuffix, rsuffix), sort=sort)\n\u001b[0m\u001b[0;32m   4384\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4385\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mon\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/anaconda2/lib/python2.7/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator)\u001b[0m\n\u001b[0;32m     33\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m                          copy=copy, indicator=indicator)\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mmerge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_merge_doc\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;34m'\\nleft : DataFrame'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/anaconda2/lib/python2.7/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    218\u001b[0m             \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mldata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlindexers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrindexers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mllabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjoin_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m             concat_axis=0, copy=self.copy)\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[0mtyp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/anaconda2/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m   4472\u001b[0m                                                 copy=copy),\n\u001b[0;32m   4473\u001b[0m                          placement=placement)\n\u001b[1;32m-> 4474\u001b[1;33m               for placement, join_units in concat_plan]\n\u001b[0m\u001b[0;32m   4475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4476\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/anaconda2/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mconcatenate_join_units\u001b[1;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[0;32m   4575\u001b[0m         \u001b[0mconcat_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4576\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconcat_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4577\u001b[1;33m             \u001b[0mconcat_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcat_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4578\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4579\u001b[0m         \u001b[0mconcat_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_concat_compat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconcat_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mush_columns = ['label', 'cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor', 'gill-attachment', 'gill-spacing', 'gill-size',\\\n",
    "               'gill-color', 'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring',\\\n",
    "               'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number', 'ring-type',\\\n",
    "               'spore-print-color', 'population', 'habitat']\n",
    "train = pd.read_csv('agaricus-lepiota.data',header=None)\n",
    "train.columns = mush_columns\n",
    "key_str = {'e':0, 'p':1}\n",
    "label_num = []\n",
    "map(lambda label: map(lambda key: label_num.append(key_str[key]) if key == label else None,key_str.keys()), train['label'])\n",
    "del train['label']\n",
    "\n",
    "result = pd.DataFrame(columns=['combine_num','top','score', 'time'])\n",
    "\n",
    "\n",
    "total_score = []\n",
    "total_time = []\n",
    "clf = SVC(kernel='linear', C=1.0)\n",
    "#clf = BernoulliNB()\n",
    "\n",
    "skf = StratifiedKFold(np.array(label_num), n_folds=10)\n",
    "val_label = np.array(label_num)\n",
    "\n",
    "exp_num = 0\n",
    "for combine_num in range(2,4):\n",
    "    \n",
    "    train_combine = pd.DataFrame(index=range(len(train)))\n",
    "    com_index = 0\n",
    "    for sub in Cb(train.columns,combine_num):\n",
    "        combine_list = []\n",
    "        map(lambda data: combine_list.append(combine_function(data)),train[list(sub)].values)\n",
    "        train_combine['combine%d' % com_index] = combine_list\n",
    "        com_index = com_index + 1\n",
    "    print \"combine_subset:\", com_index\n",
    "    #train_dummy_top = combine_selection(train_dummy)\n",
    "    #train_dummy = pd.get_dummies(train_combine)\n",
    "    total_score = []\n",
    "    total_time = []\n",
    "    for threshold in xrange(100,520,20):\n",
    "        print \"top: \", threshold\n",
    "        val_time = []\n",
    "        now_score = []\n",
    "        for train_val_index, test_val_index in skf:    \n",
    "\n",
    "            (train_dummy_top, test_dummy_top) = combine_selection(train_combine.iloc[train_val_index],val_label[train_val_index], train_combine.iloc[test_val_index], threshold = threshold)\n",
    "            lda = LDA()\n",
    "            try: \n",
    "                train_lda = lda.fit_transform(train_dummy_top, val_label[train_val_index])        \n",
    "                clf.fit(train_lda, val_label[train_val_index])\n",
    "                test_lda = lda.transform(test_dummy_top)\n",
    "                start = time.time()\n",
    "                now_score.append(accuracy_score(clf.predict(test_lda), val_label[test_val_index]))\n",
    "                val_time.append(time.time() - start)   \n",
    "            \n",
    "            except LinAlgError:\n",
    "                None\n",
    "        exe_time = np.sum(val_time)\n",
    "        #total_score.append(np.average(now_score))\n",
    "        #total_time.append(exe_time)\n",
    "\n",
    "        print \"combine_num\", combine_num\n",
    "        print \"score:\", np.average(now_score)\n",
    "        print \"time:\", exe_time\n",
    "        result.loc[exp_num] = [combine_num, threshold, np.average(now_score), exe_time]\n",
    "        exp_num = exp_num + 1\n",
    "        result.to_csv('mush_combine_lda_normal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combine_subset: 231\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "combine_num 2\n",
      "n_cluster: 2\n",
      "score: 0.519078531668\n",
      "time: 0.0060375213623\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "combine_num 2\n",
      "n_cluster: 3\n",
      "score: 0.519078531668\n",
      "time: 0.00495452880859\n"
     ]
    }
   ],
   "source": [
    "mush_columns = ['label', 'cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor', 'gill-attachment', 'gill-spacing', 'gill-size',\\\n",
    "               'gill-color', 'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring',\\\n",
    "               'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number', 'ring-type',\\\n",
    "               'spore-print-color', 'population', 'habitat']\n",
    "train = pd.read_csv('agaricus-lepiota.data',header=None)\n",
    "train.columns = mush_columns\n",
    "key_str = {'e':0, 'p':1}\n",
    "label_num = []\n",
    "map(lambda label: map(lambda key: label_num.append(key_str[key]) if key == label else None,key_str.keys()), train['label'])\n",
    "del train['label']\n",
    "\n",
    "result = pd.DataFrame(columns=['combine_num','c_cluster','score', 'time'])\n",
    "\n",
    "\n",
    "total_score = []\n",
    "total_time = []\n",
    "#clf = SVC(kernel='linear', C=1.0)\n",
    "clf = BernoulliNB()\n",
    "\n",
    "skf = StratifiedKFold(np.array(label_num), n_folds=10)\n",
    "val_label = np.array(label_num)\n",
    "\n",
    "exp_num =0 \n",
    "for combine_num in range(2,3):\n",
    "    \n",
    "    train_combine = pd.DataFrame(index=range(len(train)))\n",
    "    com_index = 0\n",
    "    for sub in Cb(train.columns,combine_num):\n",
    "        combine_list = []\n",
    "        map(lambda data: combine_list.append(combine_function(data)),train[list(sub)].values)\n",
    "        train_combine['combine_%d' % com_index] = combine_list\n",
    "        com_index = com_index + 1\n",
    "    print \"combine_subset:\", com_index\n",
    "    train_dummy = pd.get_dummies(train_combine)\n",
    "    for cluster in range(2,4):\n",
    "        total_score = []\n",
    "        total_time = []\n",
    "        for iteration in range(5):\n",
    "            print iteration\n",
    "            val_time = []\n",
    "            now_score = []\n",
    "            for train_val_index, test_val_index in skf:    \n",
    "                lda = LDA()\n",
    "                try:    \n",
    "                    train_lda = lda.fit_transform(train_dummy.iloc[train_val_index], val_label[train_val_index])\n",
    "                    test_lda = lda.transform(train_dummy.iloc[test_val_index])\n",
    "                    (train_lda, test_lda) = normalization(train_lda, test_lda)\n",
    "                    clf.fit(train_lda, val_label[train_val_index])\n",
    "                    \n",
    "                    start = time.time()\n",
    "                    now_score.append(accuracy_score(clf.predict(test_lda), val_label[test_val_index]))\n",
    "                    val_time.append(time.time() - start)   \n",
    "                except LinAlgError:\n",
    "                    None\n",
    "            exe_time = np.sum(val_time)\n",
    "            total_score.append(np.average(now_score))\n",
    "            total_time.append(exe_time)\n",
    "            \n",
    "        print \"combine_num\", combine_num\n",
    "        print \"n_cluster:\", cluster\n",
    "        print \"score:\", np.average(total_score)\n",
    "        print \"time:\", np.average(total_time)\n",
    "        result.loc[exp_num] = [combine_num, cluster, np.average(total_score), np.average(total_time)]\n",
    "        exp_num = exp_num + 1\n",
    "        result.to_csv('mush_combine_lda_normal.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combine_subset: 15\n",
      "top:  100\n",
      "Information gain process time: 0.127707958221\n",
      "Feature selection process time: 0.0605630874634\n",
      "Information gain process time: 0.0708389282227\n",
      "Feature selection process time: 0.0496971607208\n",
      "Information gain process time: 0.0701961517334\n",
      "Feature selection process time: 0.0544741153717\n",
      "Information gain process time: 0.070013999939\n",
      "Feature selection process time: 0.0518810749054\n",
      "Information gain process time: 0.0708959102631\n",
      "Feature selection process time: 0.0513870716095\n",
      "Information gain process time: 0.0696289539337\n",
      "Feature selection process time: 0.0540490150452\n",
      "Information gain process time: 0.0718469619751\n",
      "Feature selection process time: 0.0490601062775\n",
      "Information gain process time: 0.0704591274261\n",
      "Feature selection process time: 0.0522990226746\n",
      "Information gain process time: 0.0699801445007\n",
      "Feature selection process time: 0.0527260303497\n",
      "Information gain process time: 0.0706050395966\n",
      "Feature selection process time: 0.0491740703583\n",
      "combine_num 2 score: 0.829522310802 time: 0.00795769691467\n",
      "top:  120\n",
      "Information gain process time: 0.0703358650208\n",
      "Feature selection process time: 0.0547690391541\n",
      "Information gain process time: 0.0735840797424\n",
      "Feature selection process time: 0.0531840324402\n",
      "Information gain process time: 0.069680929184\n",
      "Feature selection process time: 0.0595910549164\n",
      "Information gain process time: 0.0699939727783\n",
      "Feature selection process time: 0.332666873932\n",
      "Information gain process time: 0.124174833298\n",
      "Feature selection process time: 0.0550169944763\n",
      "Information gain process time: 0.0709400177002\n",
      "Feature selection process time: 0.0596568584442\n",
      "Information gain process time: 0.0720210075378\n",
      "Feature selection process time: 0.0560178756714\n",
      "Information gain process time: 0.0711259841919\n",
      "Feature selection process time: 0.0566890239716\n",
      "Information gain process time: 0.0699150562286\n",
      "Feature selection process time: 0.0549721717834\n",
      "Information gain process time: 0.0708091259003\n",
      "Feature selection process time: 0.0557930469513\n",
      "combine_num 2 score: 0.845822483171 time: 0.00819134712219\n",
      "top:  140\n",
      "Information gain process time: 0.0862460136414\n",
      "Feature selection process time: 0.0719718933105\n",
      "Information gain process time: 0.0724918842316\n",
      "Feature selection process time: 0.0591511726379\n",
      "Information gain process time: 0.0705780982971\n",
      "Feature selection process time: 0.0638360977173\n",
      "Information gain process time: 0.0709137916565\n",
      "Feature selection process time: 0.065505027771\n",
      "Information gain process time: 0.0713889598846\n",
      "Feature selection process time: 0.0606410503387\n",
      "Information gain process time: 0.0707631111145\n",
      "Feature selection process time: 0.0715570449829\n",
      "Information gain process time: 0.0707771778107\n",
      "Feature selection process time: 0.0716490745544\n",
      "Information gain process time: 0.0923249721527\n",
      "Feature selection process time: 0.0627498626709\n",
      "Information gain process time: 0.070405960083\n",
      "Feature selection process time: 0.0568890571594\n",
      "Information gain process time: 0.070897102356\n",
      "Feature selection process time: 0.0554571151733\n",
      "combine_num 2 score: 0.850964688236 time: 0.00731229782104\n",
      "top:  160\n",
      "Information gain process time: 0.0693249702454\n",
      "Feature selection process time: 0.067232131958\n",
      "Information gain process time: 0.0712478160858\n",
      "Feature selection process time: 0.0647079944611\n",
      "Information gain process time: 0.0705230236053\n",
      "Feature selection process time: 0.0675880908966\n",
      "Information gain process time: 0.0739660263062\n",
      "Feature selection process time: 0.0659539699554\n",
      "Information gain process time: 0.0712649822235\n",
      "Feature selection process time: 0.0681750774384\n",
      "Information gain process time: 0.0709149837494\n",
      "Feature selection process time: 0.0666780471802\n",
      "Information gain process time: 0.0716199874878\n",
      "Feature selection process time: 0.0628299713135\n",
      "Information gain process time: 0.0705950260162\n",
      "Feature selection process time: 0.0672869682312\n",
      "Information gain process time: 0.0699989795685\n",
      "Feature selection process time: 0.0601830482483\n",
      "Information gain process time: 0.0712668895721\n",
      "Feature selection process time: 0.0582540035248\n",
      "combine_num 2 score: 0.85735659915 time: 0.00738525390625\n",
      "top:  180\n",
      "Information gain process time: 0.0706148147583\n",
      "Feature selection process time: 0.0705149173737\n",
      "Information gain process time: 0.0717618465424\n",
      "Feature selection process time: 0.07275390625\n",
      "Information gain process time: 0.0708789825439\n",
      "Feature selection process time: 0.0771360397339\n",
      "Information gain process time: 0.0706970691681\n",
      "Feature selection process time: 0.0731480121613\n",
      "Information gain process time: 0.070515871048\n",
      "Feature selection process time: 0.0734329223633\n",
      "Information gain process time: 0.071320772171\n",
      "Feature selection process time: 0.0772271156311\n",
      "Information gain process time: 0.0713450908661\n",
      "Feature selection process time: 0.0735721588135\n",
      "Information gain process time: 0.0706689357758\n",
      "Feature selection process time: 0.0703320503235\n",
      "Information gain process time: 0.0709338188171\n",
      "Feature selection process time: 0.0678222179413\n",
      "Information gain process time: 0.0708391666412\n",
      "Feature selection process time: 0.0678429603577\n",
      "combine_num 2 score: 0.859080737081 time: 0.00693678855896\n",
      "top:  200\n",
      "Information gain process time: 0.070464849472\n",
      "Feature selection process time: 0.0694711208344\n",
      "Information gain process time: 0.070680141449\n",
      "Feature selection process time: 0.0728349685669\n",
      "Information gain process time: 0.0709929466248\n",
      "Feature selection process time: 0.079686164856\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-196-c4c05bba20ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtrain_val_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_val_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mskf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[1;33m(\u001b[0m\u001b[0mtrain_dummy_top\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dummy_top\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcombine_selection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_combine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_val_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_val_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_combine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_val_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m             \u001b[0mlda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLDA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-184-08719fc51f30>\u001b[0m in \u001b[0;36mcombine_selection\u001b[1;34m(train_dummy, label, test_dummy, threshold)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mnow_column\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0meach_train_dummy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dummy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mex_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/anaconda2/lib/python2.7/site-packages/pandas/core/reshape.pyc\u001b[0m in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first)\u001b[0m\n\u001b[0;32m   1093\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1094\u001b[0m         result = _get_dummies_1d(data, prefix, prefix_sep, dummy_na,\n\u001b[1;32m-> 1095\u001b[1;33m                                  sparse=sparse, drop_first=drop_first)\n\u001b[0m\u001b[0;32m   1096\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1097\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/anaconda2/lib/python2.7/site-packages/pandas/core/reshape.pyc\u001b[0m in \u001b[0;36m_get_dummies_1d\u001b[1;34m(data, prefix, prefix_sep, dummy_na, sparse, drop_first)\u001b[0m\n\u001b[0;32m   1100\u001b[0m                     sparse=False, drop_first=False):\n\u001b[0;32m   1101\u001b[0m     \u001b[1;31m# Series avoids inconsistent NaN handling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1102\u001b[1;33m     \u001b[0mcat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m     \u001b[0mlevels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/anaconda2/lib/python2.7/site-packages/pandas/core/categorical.pyc\u001b[0m in \u001b[0;36mfrom_array\u001b[1;34m(cls, data, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m             \u001b[0mthe\u001b[0m \u001b[0munique\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mof\u001b[0m \u001b[1;33m`\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m         \"\"\"\n\u001b[1;32m--> 379\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/anaconda2/lib/python2.7/site-packages/pandas/core/categorical.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, values, categories, ordered, name, fastpath, levels)\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcategories\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m                 \u001b[0mcodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategories\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfactorize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m                 \u001b[0mcodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategories\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfactorize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/anaconda2/lib/python2.7/site-packages/pandas/core/algorithms.pyc\u001b[0m in \u001b[0;36mfactorize\u001b[1;34m(values, sort, order, na_sentinel, size_hint)\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhash_klass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_hint\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvec_klass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_sentinel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_platform_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_labels (pandas/hashtable.c:14317)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/usr/anaconda2/lib/python2.7/site-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m     \"\"\"Convert the input to an array.\n\u001b[0;32m    416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "car_columns = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'label']\n",
    "train = pd.read_csv('car.data',header=None)\n",
    "train.columns = car_columns\n",
    "key_str = {'unacc':0, 'acc':1, 'good':2, 'vgood':3}\n",
    "label_num = []\n",
    "map(lambda label: map(lambda key: label_num.append(key_str[key]) if key == label else None,key_str.keys()), train['label'])\n",
    "del train['label']\n",
    "\n",
    "result = pd.DataFrame(columns=['combine_num','c_cluster','score', 'time'])\n",
    "\n",
    "\n",
    "\n",
    "total_score = []\n",
    "total_time = []\n",
    "clf = SVC(kernel='linear', C=1.0)\n",
    "#clf = BernoulliNB()\n",
    "\n",
    "skf = StratifiedKFold(np.array(label_num), n_folds=10)\n",
    "val_label = np.array(label_num)\n",
    "\n",
    "exp_num = 0\n",
    "highest_score = 0\n",
    "highest_idx = 0\n",
    "for combine_num in range(2,5):\n",
    "    \n",
    "    train_combine = pd.DataFrame(index=range(len(train)))\n",
    "    com_index = 0\n",
    "    for sub in Cb(train.columns,combine_num):\n",
    "        combine_list = []\n",
    "        map(lambda data: combine_list.append(combine_function(data)),train[list(sub)].values)\n",
    "        train_combine['combine%d' % com_index] = combine_list\n",
    "        com_index = com_index + 1\n",
    "    print \"combine_subset:\", com_index\n",
    "    #train_dummy_top = combine_selection(train_dummy)\n",
    "    #train_dummy = pd.get_dummies(train_combine)\n",
    "    total_score = []\n",
    "    total_time = []\n",
    "    for threshold in xrange(100,520,20):\n",
    "        print \"top: \", threshold\n",
    "        val_time = []\n",
    "        now_score = []\n",
    "        for train_val_index, test_val_index in skf:    \n",
    "\n",
    "            (train_dummy_top, test_dummy_top) = combine_selection(train_combine.iloc[train_val_index],val_label[train_val_index], train_combine.iloc[test_val_index], threshold = threshold)\n",
    "            lda = LDA()\n",
    "            try: \n",
    "                train_lda = lda.fit_transform(train_dummy_top, val_label[train_val_index])        \n",
    "                clf.fit(train_lda, val_label[train_val_index])\n",
    "                test_lda = lda.transform(test_dummy_top)\n",
    "                start = time.time()\n",
    "                now_score.append(accuracy_score(clf.predict(test_lda), val_label[test_val_index]))\n",
    "                val_time.append(time.time() - start)   \n",
    "            \n",
    "            except LinAlgError:\n",
    "                None\n",
    "        exe_time = np.sum(val_time)\n",
    "        #total_score.append(np.average(now_score))\n",
    "        #total_time.append(exe_time)\n",
    "        \n",
    "        if np.average(now_score) > highest_score:\n",
    "            highest_score = np.average(now_score)\n",
    "            highest_idx = exp_num\n",
    "        \n",
    "        print \"combine_num\", combine_num, \"score:\", np.average(now_score), \"time:\", exe_time\n",
    "        \n",
    "        result.loc[exp_num] = [combine_num, threshold, np.average(now_score), exe_time]\n",
    "        exp_num = exp_num + 1\n",
    "        #result.to_csv('car_combine_lda_normal.csv')\n",
    "print \"Highest:\", result.loc[highest_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combine_num 2\n",
      "n_cluster: 2\n",
      "score: 0.693977698049\n",
      "time: 0.0135494947433\n",
      "combine_num 2\n",
      "n_cluster: 3\n",
      "score: 0.693977698049\n",
      "time: 0.00973460674286\n",
      "combine_num 2\n",
      "n_cluster: 4\n",
      "score: 0.693977698049\n",
      "time: 0.0112968921661\n",
      "combine_num 3\n",
      "n_cluster: 2\n",
      "score: 0.691818751238\n",
      "time: 0.00888221263885\n",
      "combine_num 3\n",
      "n_cluster: 3\n",
      "score: 0.691818751238\n",
      "time: 0.00874812602997\n",
      "combine_num 3\n",
      "n_cluster: 4\n",
      "score: 0.691818751238\n",
      "time: 0.00826539993286\n",
      "combine_num 4\n",
      "n_cluster: 2\n",
      "score: 0.675885464194\n",
      "time: 0.00815374851227\n",
      "combine_num 4\n",
      "n_cluster: 3\n",
      "score: 0.675885464194\n",
      "time: 0.00594704151154\n",
      "combine_num 4\n",
      "n_cluster: 4\n",
      "score: 0.675885464194\n",
      "time: 0.00691163539886\n"
     ]
    }
   ],
   "source": [
    "car_columns = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'label']\n",
    "train = pd.read_csv('car.data',header=None)\n",
    "train.columns = car_columns\n",
    "key_str = {'unacc':0, 'acc':1, 'good':2, 'vgood':3}\n",
    "label_num = []\n",
    "map(lambda label: map(lambda key: label_num.append(key_str[key]) if key == label else None,key_str.keys()), train['label'])\n",
    "del train['label']\n",
    "\n",
    "result = pd.DataFrame(columns=['combine_num','c_cluster','score', 'time'])\n",
    "\n",
    "\n",
    "\n",
    "total_score = []\n",
    "total_time = []\n",
    "#clf = SVC(kernel='linear', C=1.0)\n",
    "clf = BernoulliNB()\n",
    "\n",
    "skf = StratifiedKFold(np.array(label_num), n_folds=10)\n",
    "val_label = np.array(label_num)\n",
    "\n",
    "exp_num = 0\n",
    "for combine_num in range(2,5):\n",
    "    \n",
    "    train_combine = pd.DataFrame(index=range(len(train)))\n",
    "    com_index = 0\n",
    "    for sub in Cb(train.columns,combine_num):\n",
    "        combine_list = []\n",
    "        map(lambda data: combine_list.append(combine_function(data)),train[list(sub)].values)\n",
    "        train_combine['combine%d' % com_index] = combine_list\n",
    "        com_index = com_index + 1\n",
    "    #print \"combine_subset:\", com_index\n",
    "    train_dummy = pd.get_dummies(train_combine)\n",
    "    for cluster in range(2,5):\n",
    "        total_score = []\n",
    "        total_time = []\n",
    "        for iteration in range(10):\n",
    "            val_time = []\n",
    "            now_score = []\n",
    "            for train_val_index, test_val_index in skf:    \n",
    "                lda = LDA()\n",
    "                train_lda = lda.fit_transform(train_dummy.iloc[train_val_index], val_label[train_val_index])        \n",
    "                clf.fit(train_lda, val_label[train_val_index])\n",
    "                test_lda = lda.transform(train_dummy.iloc[test_val_index])\n",
    "                start = time.time()\n",
    "                now_score.append(accuracy_score(clf.predict(test_lda), val_label[test_val_index]))\n",
    "                val_time.append(time.time() - start)         \n",
    "            exe_time = np.sum(val_time)\n",
    "            total_score.append(np.average(now_score))\n",
    "            total_time.append(exe_time)\n",
    "            \n",
    "        print \"combine_num\", combine_num\n",
    "        print \"n_cluster:\", cluster\n",
    "        print \"score:\", np.average(total_score)\n",
    "        print \"time:\", np.average(total_time)\n",
    "        result.loc[exp_num] = [combine_num, cluster, np.average(total_score), np.average(total_time)]\n",
    "        exp_num = exp_num + 1\n",
    "        result.to_csv('car_combine_lda_normal.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combine_num 2\n",
      "n_cluster: 2\n",
      "score: 0.00864941510103\n",
      "time: 0.011870598793\n",
      "combine_num 2\n",
      "n_cluster: 3\n",
      "score: 0.00864941510103\n",
      "time: 0.0109653234482\n",
      "combine_num 3\n",
      "n_cluster: 2\n",
      "score: 0.00864941510103\n",
      "time: 0.0115445613861\n",
      "combine_num 3\n",
      "n_cluster: 3\n",
      "score: 0.00864941510103\n",
      "time: 0.0123892307281\n"
     ]
    }
   ],
   "source": [
    "column_str = ['Proto', 'State','Dir','Dport']\n",
    "column_numeric = ['Dur', 'sTos', 'dTos', 'TotPkts', 'TotBytes','SrcBytes']\n",
    "train = pd.read_csv('botnet_5.binetflow')\n",
    "\n",
    "key_str = {'Normal':0, 'Botnet':1, 'Background':2}\n",
    "label_num = []\n",
    "map(lambda label: map(lambda key: label_num.append(key_str[key]) if key in label else None,key_str.keys()), train['Label'])\n",
    "\n",
    "train_index = np.array(np.where(np.array(label_num) == 0)[0].tolist() + np.where(np.array(label_num) == 1)[0].tolist())\n",
    "train = train.iloc[train_index]\n",
    "train = train.fillna(0)\n",
    "label_num = np.array(label_num)[train_index]\n",
    "train_numeric = train[column_numeric]\n",
    "train = train[column_str]\n",
    "\n",
    "result = pd.DataFrame(columns=['combine_num','c_cluster','score', 'time'])\n",
    "\n",
    "\n",
    "\n",
    "total_score = []\n",
    "total_time = []\n",
    "#clf = SVC(kernel='linear', C=1.0)\n",
    "clf = BernoulliNB()\n",
    "\n",
    "skf = StratifiedKFold(np.array(label_num), n_folds=10)\n",
    "val_label = np.array(label_num)\n",
    "\n",
    "exp_num=0\n",
    "for combine_num in range(2,4):\n",
    "    \n",
    "    train_combine = pd.DataFrame(index=range(len(train)))\n",
    "    com_index = 0\n",
    "    for sub in Cb(train.columns,combine_num):\n",
    "        combine_list = []\n",
    "        map(lambda data: combine_list.append(combine_function(data)),train[list(sub)].values)\n",
    "        train_combine['combine_%d' % com_index] = combine_list\n",
    "        com_index = com_index + 1\n",
    "    #print \"combine_subset:\", com_index\n",
    "    train_dummy = pd.get_dummies(train_combine)\n",
    "    for cluster in range(2,4):\n",
    "        total_score = []\n",
    "        total_time = []\n",
    "        for iteration in range(10):\n",
    "            val_time = []\n",
    "            now_score = []\n",
    "            for train_val_index, test_val_index in skf:  \n",
    "                lda = LDA()\n",
    "                train_lda = lda.fit_transform(train_dummy.iloc[train_val_index], val_label[train_val_index]) \n",
    "                train_lda = np.append(train_lda, train_numeric.iloc[train_val_index].values, axis=1)\n",
    "                test_lda = lda.transform(train_dummy.iloc[test_val_index])\n",
    "                test_lda = np.append(test_lda, train_numeric.iloc[test_val_index].values, axis=1)        \n",
    "                (train_lda, test_lda) = normalization(train_lda, test_lda)\n",
    "\n",
    "                clf.fit(train_lda, val_label[train_val_index])\n",
    "                start = time.time()\n",
    "                now_score.append(f1_score(clf.predict(test_lda), val_label[test_val_index]))\n",
    "                val_time.append(time.time() - start)         \n",
    "            exe_time = np.sum(val_time)\n",
    "            total_score.append(np.average(now_score))\n",
    "            total_time.append(exe_time)\n",
    "            \n",
    "        print \"combine_num\", combine_num\n",
    "        print \"n_cluster:\", cluster\n",
    "        print \"score:\", np.average(total_score)\n",
    "        print \"time:\", np.average(total_time)\n",
    "        result.loc[exp_num] = [combine_num, cluster, np.average(total_score), np.average(total_time)]\n",
    "        exp_num = exp_num + 1\n",
    "        result.to_csv('bot5_combine_lda_normal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combine_num 2\n",
      "n_cluster: 2\n",
      "score: 0.54816706972\n",
      "time: 0.0186123132706\n",
      "combine_num 2\n",
      "n_cluster: 3\n",
      "score: 0.54816706972\n",
      "time: 0.0222583293915\n",
      "combine_num 3\n",
      "n_cluster: 2\n",
      "score: 0.54816706972\n",
      "time: 0.0243029356003\n",
      "combine_num 3\n",
      "n_cluster: 3\n",
      "score: 0.54816706972\n",
      "time: 0.021257853508\n"
     ]
    }
   ],
   "source": [
    "column_str = ['Proto', 'State','Dir','Dport']\n",
    "column_numeric = ['Dur', 'sTos', 'dTos', 'TotPkts', 'TotBytes','SrcBytes']\n",
    "train = pd.read_csv('botnet_6.binetflow')\n",
    "\n",
    "key_str = {'Normal':0, 'Botnet':1, 'Background':2}\n",
    "label_num = []\n",
    "map(lambda label: map(lambda key: label_num.append(key_str[key]) if key in label else None,key_str.keys()), train['Label'])\n",
    "\n",
    "train_index = np.array(np.where(np.array(label_num) == 0)[0].tolist() + np.where(np.array(label_num) == 1)[0].tolist())\n",
    "train = train.iloc[train_index]\n",
    "train = train.fillna(0)\n",
    "label_num = np.array(label_num)[train_index]\n",
    "train_numeric = train[column_numeric]\n",
    "train = train[column_str]\n",
    "\n",
    "result = pd.DataFrame(columns=['combine_num','c_cluster','score', 'time'])\n",
    "\n",
    "\n",
    "\n",
    "total_score = []\n",
    "total_time = []\n",
    "#clf = SVC(kernel='linear', C=1.0)\n",
    "clf = BernoulliNB()\n",
    "\n",
    "skf = StratifiedKFold(np.array(label_num), n_folds=10)\n",
    "val_label = np.array(label_num)\n",
    "\n",
    "exp_num=0\n",
    "for combine_num in range(2,4):\n",
    "    \n",
    "    train_combine = pd.DataFrame(index=range(len(train)))\n",
    "    com_index = 0\n",
    "    for sub in Cb(train.columns,combine_num):\n",
    "        combine_list = []\n",
    "        map(lambda data: combine_list.append(combine_function(data)),train[list(sub)].values)\n",
    "        train_combine['combine_%d' % com_index] = combine_list\n",
    "        com_index = com_index + 1\n",
    "    #print \"combine_subset:\", com_index\n",
    "    train_dummy = pd.get_dummies(train_combine)\n",
    "    for cluster in range(2,4):\n",
    "        total_score = []\n",
    "        total_time = []\n",
    "        for iteration in range(10):\n",
    "            val_time = []\n",
    "            now_score = []\n",
    "            for train_val_index, test_val_index in skf:  \n",
    "                lda = LDA()\n",
    "                train_lda = lda.fit_transform(train_dummy.iloc[train_val_index], val_label[train_val_index]) \n",
    "                train_lda = np.append(train_lda, train_numeric.iloc[train_val_index].values, axis=1)\n",
    "                test_lda = lda.transform(train_dummy.iloc[test_val_index])\n",
    "                test_lda = np.append(test_lda, train_numeric.iloc[test_val_index].values, axis=1)        \n",
    "                (train_lda, test_lda) = normalization(train_lda, test_lda)\n",
    "\n",
    "                clf.fit(train_lda, val_label[train_val_index])\n",
    "                start = time.time()\n",
    "                now_score.append(f1_score(clf.predict(test_lda), val_label[test_val_index]))\n",
    "                val_time.append(time.time() - start)         \n",
    "            exe_time = np.sum(val_time)\n",
    "            total_score.append(np.average(now_score))\n",
    "            total_time.append(exe_time)\n",
    "            \n",
    "        print \"combine_num\", combine_num\n",
    "        print \"n_cluster:\", cluster\n",
    "        print \"score:\", np.average(total_score)\n",
    "        print \"time:\", np.average(total_time)\n",
    "        result.loc[exp_num] = [combine_num, cluster, np.average(total_score), np.average(total_time)]\n",
    "        exp_num = exp_num + 1\n",
    "        result.to_csv('bot6_combine_lda_normal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combine_num 2\n",
      "n_cluster: 2\n",
      "score: 0.025\n",
      "time: 0.010089468956\n",
      "combine_num 2\n",
      "n_cluster: 3\n",
      "score: 0.025\n",
      "time: 0.0104130268097\n",
      "combine_num 3\n",
      "n_cluster: 2\n",
      "score: 0.025\n",
      "time: 0.0105338096619\n",
      "combine_num 3\n",
      "n_cluster: 3\n",
      "score: 0.025\n",
      "time: 0.0101867198944\n"
     ]
    }
   ],
   "source": [
    "column_str = ['Proto', 'State','Dir','Dport']\n",
    "column_numeric = ['Dur', 'sTos', 'dTos', 'TotPkts', 'TotBytes','SrcBytes']\n",
    "train = pd.read_csv('botnet_7.binetflow')\n",
    "\n",
    "key_str = {'Normal':0, 'Botnet':1, 'Background':2}\n",
    "label_num = []\n",
    "map(lambda label: map(lambda key: label_num.append(key_str[key]) if key in label else None,key_str.keys()), train['Label'])\n",
    "\n",
    "train_index = np.array(np.where(np.array(label_num) == 0)[0].tolist() + np.where(np.array(label_num) == 1)[0].tolist())\n",
    "train = train.iloc[train_index]\n",
    "train = train.fillna(0)\n",
    "label_num = np.array(label_num)[train_index]\n",
    "train_numeric = train[column_numeric]\n",
    "train = train[column_str]\n",
    "\n",
    "result = pd.DataFrame(columns=['combine_num','c_cluster','score', 'time'])\n",
    "\n",
    "\n",
    "\n",
    "total_score = []\n",
    "total_time = []\n",
    "#clf = SVC(kernel='linear', C=1.0)\n",
    "clf = BernoulliNB()\n",
    "\n",
    "skf = StratifiedKFold(np.array(label_num), n_folds=10)\n",
    "val_label = np.array(label_num)\n",
    "\n",
    "exp_num=0\n",
    "for combine_num in range(2,4):\n",
    "    \n",
    "    train_combine = pd.DataFrame(index=range(len(train)))\n",
    "    com_index = 0\n",
    "    for sub in Cb(train.columns,combine_num):\n",
    "        combine_list = []\n",
    "        map(lambda data: combine_list.append(combine_function(data)),train[list(sub)].values)\n",
    "        train_combine['combine_%d' % com_index] = combine_list\n",
    "        com_index = com_index + 1\n",
    "    #print \"combine_subset:\", com_index\n",
    "    train_dummy = pd.get_dummies(train_combine)\n",
    "    for cluster in range(2,4):\n",
    "        total_score = []\n",
    "        total_time = []\n",
    "        for iteration in range(10):\n",
    "            val_time = []\n",
    "            now_score = []\n",
    "            for train_val_index, test_val_index in skf:  \n",
    "                lda = LDA()\n",
    "                train_lda = lda.fit_transform(train_dummy.iloc[train_val_index], val_label[train_val_index]) \n",
    "                train_lda = np.append(train_lda, train_numeric.iloc[train_val_index].values, axis=1)\n",
    "                test_lda = lda.transform(train_dummy.iloc[test_val_index])\n",
    "                test_lda = np.append(test_lda, train_numeric.iloc[test_val_index].values, axis=1)        \n",
    "                (train_lda, test_lda) = normalization(train_lda, test_lda)\n",
    "\n",
    "                clf.fit(train_lda, val_label[train_val_index])\n",
    "                start = time.time()\n",
    "                now_score.append(f1_score(clf.predict(test_lda), val_label[test_val_index]))\n",
    "                val_time.append(time.time() - start)         \n",
    "            exe_time = np.sum(val_time)\n",
    "            total_score.append(np.average(now_score))\n",
    "            total_time.append(exe_time)\n",
    "            \n",
    "        print \"combine_num\", combine_num\n",
    "        print \"n_cluster:\", cluster\n",
    "        print \"score:\", np.average(total_score)\n",
    "        print \"time:\", np.average(total_time)\n",
    "        result.loc[exp_num] = [combine_num, cluster, np.average(total_score), np.average(total_time)]\n",
    "        exp_num = exp_num + 1\n",
    "        result.to_csv('bot7_combine_lda_normal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
