{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('capture20110815-2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key_str = {'Normal':0, 'Botnet':1, 'Background':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.loc[(train['Label_num'] == 0) &(train['Proto'] == 'arp')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill 0 to missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for column in train.columns:\n",
    "    print column\n",
    "    train = train[train[column].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop unuse columns and row with missing value"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_origin: 129832 train_del_missing: 122148"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_origin = train.copy()\n",
    "column_unuse = ['StartTime', 'SrcAddr', 'Sport', 'DstAddr', 'Dport']\n",
    "column_str = ['Proto', 'State', 'Dir']\n",
    "missing_state = []\n",
    "map(lambda word: missing_state.append(word) if word[-1]=='_' else None, np.unique(train['State']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for column in column_unuse:\n",
    "    del train[column]\n",
    "for state in missing_state:\n",
    "    train = train[train['State'] != state]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer str label to int lable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_num = []\n",
    "map(lambda label: map(lambda key: label_num.append(key_str[key]) if key in label else None,key_str.keys()), train['Label'])\n",
    "train['Label'] = label_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# each protocol index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.unique(train['Proto'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tcp_index = np.where(train['Proto'] == 'tcp')[0].tolist()\n",
    "train_index = np.where(train['Proto'] == 'udp')[0].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "str_combination = []\n",
    "map(lambda x: str_combination.append((x[0]+'_'+x[1])) if (x[0]+'_'+x[1]) not in str_combination else None,train.iloc[train_index][column_str].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pro_ser_flag_count = {}\n",
    "for x in str_combination:\n",
    "    pro_ser_flag_count[x] = 0\n",
    "for line in train.iloc[train_index][column_str].values:\n",
    "    key = line[0]+'_'+line[1]\n",
    "    pro_ser_flag_count[key] = pro_ser_flag_count[key] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_dic = sorted(pro_ser_flag_count.iteritems(), key=lambda (k,v): (v,k),reverse=True)\n",
    "new_string_columns = []\n",
    "new_string_columns_dic = {}\n",
    "loc_value = 1\n",
    "new_string_columns.append('others')\n",
    "new_string_columns_dic['others'] = 0\n",
    "for string in sorted_dic:\n",
    "    print string\n",
    "    if  (string[1] > 1) & (len(new_string_columns) < 100):\n",
    "        new_string_columns.append(string[0])\n",
    "        new_string_columns_dic[string[0]] = loc_value\n",
    "        loc_value = loc_value+1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_copy = train.copy()\n",
    "for column_name in new_string_columns:\n",
    "    train_copy[column_name] = np.zeros(len(train))\n",
    "    \n",
    "string_vector = np.zeros([len(train_copy),len(new_string_columns)])\n",
    "string_vector_loc = []\n",
    "\n",
    "map(lambda x: string_vector_loc.append(new_string_columns_dic[(x[0]+'_'+x[1])]) if (x[0]+'_'+x[1]) in new_string_columns \\\n",
    "    else string_vector_loc.append(new_string_columns_dic['others']) ,train_copy[column_str].values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_copy = train.copy()\n",
    "string_column = []\n",
    "for column_name in column_str[1:]: \n",
    "    for each_column in np.unique(train.iloc[train_index][column_name]):\n",
    "            #print each_column\n",
    "        now_column = np.zeros(len(train))\n",
    "        index = np.where(train_copy[column_name] == each_column)[0].tolist()\n",
    "        now_column[index] = 1\n",
    "        train_copy[each_column] = now_column\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_copy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_copy = train.copy()\n",
    "train_copy['AverRate'] = train_copy['TotBytes'] / train_copy['Dur']\n",
    "train_copy['AverPkts'] = train_copy['TotPkts'] / train_copy['Dur']\n",
    "train_copy['AverSrcRate'] = train_copy['SrcBytes'] / train_copy['Dur']\n",
    "train_copy = train_copy.replace([np.inf, -np.inf], 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def replace_value(training_normal_numpy, key, loc):  \n",
    "    training_normal_numpy[loc][key+6] = 1\n",
    "    \n",
    "def pca_transform(training_numpy, testing_numpy, pca_dim, training_copy):\n",
    "    '''\n",
    "    min_max = preprocessing.MinMaxScaler()\n",
    "    min_max.fit(training_numpy)\n",
    "    x_scaled = min_max.fit_transform(training_numpy)\n",
    "    testting_x_scaled = min_max.transform(testing_numpy)\n",
    "    training_norm = pd.DataFrame(x_scaled, columns = training_copy.columns)\n",
    "    testing_norm = pd.DataFrame(testting_x_scaled, columns = training_copy.columns)\n",
    "    '''\n",
    "    pca_model = PCA(n_components=pca_dim)\n",
    "    training_pca_value = pca_model.fit_transform(training_numpy)\n",
    "    testing_pca_value = pca_model.transform(testing_numpy)\n",
    "    return (training_pca_value, testing_pca_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for column in column_str:   \n",
    "    del(train_copy[column])\n",
    "del train_copy['Label']\n",
    "train_numpy = train_copy.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6.32765381e+02,   0.00000000e+00,   0.00000000e+00,\n",
       "         3.20550000e+04,   8.57719700e+06,   8.57524400e+06,\n",
       "         1.35550984e+04,   5.06585868e+01,   1.35520119e+04])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_numpy[train_index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map(lambda i: replace_value(train_numpy, string_vector_loc[i], i),train_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combination 0.562297798363, 0.575878962913\n",
    "# combination feat. rate 0.423463199942\n",
    "# rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc = SVC(C=pow(10,1), decision_function_shape='ovo')\n",
    "(training_pca_value, testing_pca_value) = pca_transform(train_numpy[index], train_numpy[:10], 10, train_copy)\n",
    "np.average(cross_val_score(clf, training_pca_value, np.array(label_num)[tcp_index], cv=5, n_jobs=-1, scoring='f1_macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "start scoring\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "n_estimators = 5\n",
    "start = time.time()\n",
    "for i in range(1,4,1):\n",
    "    svc = SVC(C=pow(10,i), decision_function_shape='ovo')    \n",
    "    clf = BaggingClassifier(svc, n_estimators=n_estimators, n_jobs=-1)\n",
    "    for j in range(5,len(train_numpy[0]),5):\n",
    "        print j\n",
    "        (training_pca_value, testing_pca_value) = pca_transform(train_numpy[train_index], train_numpy[:10], j, train_copy.iloc[train_index])\n",
    "        #score = cross_val_score(training_pca_value, train_label, cv=10, n_jobs=-1)\n",
    "        \n",
    "        try: \n",
    "            print \"start scoring\"\n",
    "            score = np.average(cross_val_score(clf, training_pca_value, np.array(label_num)[train_index], cv=5, n_jobs=-1, scoring='f1_macro'))\n",
    "            print  i, j, score\n",
    "            if score > best_score:\n",
    "                print  \"best:\",i, j, score\n",
    "                best_param = (i, j, score, svc)\n",
    "                best_score = score\n",
    "                best_model = clf\n",
    "            #print score\n",
    "    \n",
    "        except ValueError:\n",
    "            print 'broke'\n",
    "print time.time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc = SVC(C=pow(10,2), decision_function_shape='ovo')    \n",
    "clf = BaggingClassifier(svc, n_estimators=n_estimators, n_jobs=-1)\n",
    "(training_pca_value, testing_pca_value) = pca_transform(train_numpy[tcp_index], train_numpy[:10], 15, train_copy)\n",
    "score = np.average(cross_val_score(clf, training_pca_value, np.array(label_num)[tcp_index], cv=5, n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(np.array(label_num)[tcp_index] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
